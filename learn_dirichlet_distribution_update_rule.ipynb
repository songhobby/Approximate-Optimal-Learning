{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GV1B_vXjk0RW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKaKWfnsk0RZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MDP:\n",
    "    '''A simple MDP class.  It includes the following members'''\n",
    "\n",
    "    def __init__(self,T,R,discount):\n",
    "        '''Constructor for the MDP class\n",
    "\n",
    "        Inputs:\n",
    "        T -- Transition function: |A| x |S| x |S'| array\n",
    "        R -- Reward function: |A| x |S| array\n",
    "        discount -- discount factor: scalar in [0,1)\n",
    "\n",
    "        The constructor verifies that the inputs are valid and sets\n",
    "        corresponding variables in a MDP object'''\n",
    "\n",
    "        assert T.ndim == 3, \"Invalid transition function: it should have 3 dimensions\"\n",
    "        self.nActions = T.shape[0]\n",
    "        self.nStates = T.shape[1]\n",
    "        assert T.shape == (self.nActions,self.nStates,self.nStates), \"Invalid transition function: it has dimensionality \" + repr(T.shape) + \", but it should be (nActions,nStates,nStates)\"\n",
    "        assert (abs(T.sum(2)-1) < 1e-5).all(), \"Invalid transition function: some transition probability does not equal 1\"\n",
    "        self.T = T\n",
    "        assert R.ndim == 2, \"Invalid reward function: it should have 2 dimensions\" \n",
    "        assert R.shape == (self.nActions,self.nStates), \"Invalid reward function: it has dimensionality \" + repr(R.shape) + \", but it should be (nActions,nStates)\"\n",
    "        self.R = R\n",
    "        assert 0 <= discount < 1, \"Invalid discount factor: it should be in [0,1)\"\n",
    "        self.discount = discount\n",
    "        \n",
    "    def valueIteration(self,initialV,nIterations=np.inf,tolerance=0.01):\n",
    "        '''Value iteration procedure\n",
    "        V <-- max_a R^a + gamma T^a V\n",
    "\n",
    "        Inputs:\n",
    "        initialV -- Initial value function: array of |S| entries\n",
    "        nIterations -- limit on the # of iterations: scalar (default: infinity)\n",
    "        tolerance -- threshold on ||V^n-V^n+1||_inf: scalar (default: 0.01)\n",
    "\n",
    "        Outputs: \n",
    "        V -- Value function: array of |S| entries\n",
    "        iterId -- # of iterations performed: scalar\n",
    "        epsilon -- ||V^n-V^n+1||_inf: scalar'''\n",
    "        \n",
    "        # temporary values to ensure that the code compiles until this\n",
    "        # function is coded\n",
    "        V = initialV\n",
    "        iterId = 0\n",
    "        epsilon = np.inf\n",
    "        \n",
    "        while (iterId < nIterations and epsilon > tolerance):\n",
    "          iterId += 1\n",
    "          V_matrix = []\n",
    "          for i in range(self.nActions):\n",
    "            V_matrix.append(self.R[i]+self.discount*self.T[i] @ V)\n",
    "          V_next = np.amax(np.array(V_matrix), 0)\n",
    "          epsilon = np.max(np.abs(V_next - V))\n",
    "          V = V_next\n",
    "          \n",
    "        return [V,iterId,epsilon]\n",
    "          \n",
    "\n",
    "    def extractPolicy(self,V):\n",
    "        '''Procedure to extract a policy from a value function\n",
    "        pi <-- argmax_a R^a + gamma T^a V\n",
    "\n",
    "        Inputs:\n",
    "        V -- Value function: array of |S| entries\n",
    "\n",
    "        Output:\n",
    "        policy -- Policy: array of |S| entries'''\n",
    "\n",
    "        # temporary values to ensure that the code compiles until this\n",
    "        # function is coded\n",
    "        policy = np.zeros(self.nStates)\n",
    "        \n",
    "        V_matrix = []\n",
    "        for i in range(self.nActions):\n",
    "          V_matrix.append(self.R[i]+self.discount*self.T[i] @ V)\n",
    "        policy = np.array(V_matrix).argmax(0)\n",
    "\n",
    "        return policy \n",
    "\n",
    "    def evaluatePolicy(self,policy):\n",
    "        '''Evaluate a policy by solving a system of linear equations\n",
    "        V^pi = R^pi + gamma T^pi V^pi\n",
    "\n",
    "        Input:\n",
    "        policy -- Policy: array of |S| entries\n",
    "\n",
    "        Ouput:\n",
    "        V -- Value function: array of |S| entries'''\n",
    "\n",
    "        # temporary values to ensure that the code compiles until this\n",
    "        # function is coded\n",
    "        V = np.zeros(self.nStates)\n",
    "        \n",
    "        R_pi = np.zeros(self.nStates)\n",
    "        for i in range(self.nStates):\n",
    "          R_pi[i] = self.R[policy[i]][i]\n",
    "        \n",
    "        T_pi = np.zeros([self.nStates,self.nStates])\n",
    "        for i in range(self.nStates):\n",
    "          T_pi[i] = self.T[policy[i]][i]\n",
    "        \n",
    "        V = np.linalg.pinv(np.identity(self.nStates) - self.discount*T_pi) @ R_pi\n",
    "\n",
    "        return V\n",
    "        \n",
    "    def policyIteration(self,initialPolicy,nIterations=np.inf):\n",
    "        '''Policy iteration procedure: alternate between policy\n",
    "        evaluation (solve V^pi = R^pi + gamma T^pi V^pi) and policy\n",
    "        improvement (pi <-- argmax_a R^a + gamma T^a V^pi).\n",
    "\n",
    "        Inputs:\n",
    "        initialPolicy -- Initial policy: array of |S| entries\n",
    "        nIterations -- limit on # of iterations: scalar (default: inf)\n",
    "\n",
    "        Outputs: \n",
    "        policy -- Policy: array of |S| entries\n",
    "        V -- Value function: array of |S| entries\n",
    "        iterId -- # of iterations peformed by modified policy iteration: scalar\n",
    "        epsilon -- ||V^n-V^n+1||_inf: scalar'''\n",
    "\n",
    "        # temporary values to ensure that the code compiles until this\n",
    "        # function is coded\n",
    "        policy = initialPolicy\n",
    "        V = np.zeros(self.nStates)\n",
    "        iterId = 0\n",
    "        \n",
    "        while(iterId < nIterations):\n",
    "          iterId += 1\n",
    "          V = self.evaluatePolicy(policy)\n",
    "          policy_next = self.extractPolicy(V)\n",
    "          if np.array_equal(policy, policy_next):\n",
    "            return [policy,V,iterId]\n",
    "          policy = policy_next\n",
    "          \n",
    "        return [policy, V, iterId]\n",
    "          \n",
    "    def evaluatePolicyPartially(self,policy,initialV,nIterations=np.inf,tolerance=0.01):\n",
    "        '''Partial policy evaluation:\n",
    "        Repeat V^pi <-- R^pi + gamma T^pi V^pi\n",
    "\n",
    "        Inputs:\n",
    "        policy -- Policy: array of |S| entries\n",
    "        initialV -- Initial value function: array of |S| entries\n",
    "        nIterations -- limit on the # of iterations: scalar (default: infinity)\n",
    "        tolerance -- threshold on ||V^n-V^n+1||_inf: scalar (default: 0.01)\n",
    "\n",
    "        Outputs: \n",
    "        V -- Value function: array of |S| entries\n",
    "        iterId -- # of iterations performed: scalar\n",
    "        epsilon -- ||V^n-V^n+1||_inf: scalar'''\n",
    "\n",
    "        # temporary values to ensure that the code compiles until this\n",
    "        # function is coded\n",
    "        V = initialV\n",
    "        iterId = 0\n",
    "        epsilon = np.inf\n",
    "        \n",
    "        R_pi = np.zeros(self.nStates)\n",
    "        for i in range(self.nStates):\n",
    "          R_pi[i] = self.R[policy[i]][i]\n",
    "        \n",
    "        T_pi = np.zeros([self.nStates,self.nStates])\n",
    "        for i in range(self.nStates):\n",
    "          T_pi[i] = self.T[policy[i]][i]\n",
    "          \n",
    "        while(iterId < nIterations and epsilon > tolerance):\n",
    "          iterId += 1\n",
    "          V_next = R_pi + self.discount*T_pi @ V\n",
    "          epsilon = np.max(np.abs(V_next - V))\n",
    "          V = V_next\n",
    "\n",
    "        return [V,iterId,epsilon]\n",
    "\n",
    "    def modifiedPolicyIteration(self,initialPolicy,initialV,nEvalIterations=5,nIterations=np.inf,tolerance=0.01):\n",
    "        '''Modified policy iteration procedure: alternate between\n",
    "        partial policy evaluation (repeat a few times V^pi <-- R^pi + gamma T^pi V^pi)\n",
    "        and policy improvement (pi <-- argmax_a R^a + gamma T^a V^pi)\n",
    "\n",
    "        Inputs:\n",
    "        initialPolicy -- Initial policy: array of |S| entries\n",
    "        initialV -- Initial value function: array of |S| entries\n",
    "        nEvalIterations -- limit on # of iterations to be performed in each partial policy evaluation: scalar (default: 5)\n",
    "        nIterations -- limit on # of iterations to be performed in modified policy iteration: scalar (default: inf)\n",
    "        tolerance -- threshold on ||V^n-V^n+1||_inf: scalar (default: 0.01)\n",
    "\n",
    "        Outputs: \n",
    "        policy -- Policy: array of |S| entries\n",
    "        V -- Value function: array of |S| entries\n",
    "        iterId -- # of iterations peformed by modified policy iteration: scalar\n",
    "        epsilon -- ||V^n-V^n+1||_inf: scalar'''\n",
    "\n",
    "        # temporary values to ensure that the code compiles until this\n",
    "        # function is coded\n",
    "        policy = initialPolicy\n",
    "        V = initialV\n",
    "        iterId = 0\n",
    "        epsilon = np.inf\n",
    "        \n",
    "        while(iterId < nIterations and epsilon > tolerance):\n",
    "          iterId += 1\n",
    "          [V, _, _] = self.evaluatePolicyPartially(policy,V,nEvalIterations,tolerance=0.01)\n",
    "          policy = self.extractPolicy(V)\n",
    "          [V_next, _, _] = self.valueIteration(V,1)\n",
    "          epsilon = np.max(np.abs(V_next - V))\n",
    "          \n",
    "\n",
    "        return [policy,V,iterId,epsilon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbpV_FZ8k0Rb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RL2:\n",
    "    def __init__(self,mdp,sampleReward):\n",
    "        '''Constructor for the RL class\n",
    "\n",
    "        Inputs:\n",
    "        mdp -- Markov decision process (T, R, discount)\n",
    "        sampleReward -- Function to sample rewards (e.g., bernoulli, Gaussian).\n",
    "        This function takes one argument: the mean of the distributon and \n",
    "        returns a sample from the distribution.\n",
    "        '''\n",
    "\n",
    "        self.mdp = mdp\n",
    "        self.sampleReward = sampleReward\n",
    "\n",
    "    def sampleRewardAndNextState(self,state,action):\n",
    "        '''Procedure to sample a reward and the next state\n",
    "        reward ~ Pr(r)\n",
    "        nextState ~ Pr(s'|s,a)\n",
    "\n",
    "        Inputs:\n",
    "        state -- current state\n",
    "        action -- action to be executed\n",
    "\n",
    "        Outputs: \n",
    "        reward -- sampled reward\n",
    "        nextState -- sampled next state\n",
    "        '''\n",
    "\n",
    "        reward = self.sampleReward(self.mdp.R[action,state])\n",
    "        cumProb = np.cumsum(self.mdp.T[action,state,:])\n",
    "        nextState = np.where(cumProb >= np.random.rand(1))[0][0]\n",
    "        return [reward,nextState]\n",
    "\n",
    "    def sampleAction(self,q):\n",
    "        a = q - np.max(q)\n",
    "        a = np.exp(a) / np.sum(np.exp(a))\n",
    "        return np.where(np.cumsum(a) >= np.random.rand(1))[0][0]\n",
    "\n",
    "    def sampleSoftmaxPolicy(self,policyParams,state):\n",
    "        '''Procedure to sample an action from stochastic policy\n",
    "        pi(a|s) = exp(policyParams(a,s))/[sum_a' exp(policyParams(a',s))])\n",
    "        This function should be called by reinforce() to selection actions\n",
    "\n",
    "        Inputs:\n",
    "        policyParams -- parameters of a softmax policy (|A|x|S| array)\n",
    "        state -- current state\n",
    "\n",
    "        Outputs: \n",
    "        action -- sampled action\n",
    "        '''\n",
    "\n",
    "        # temporary value to ensure that the code compiles until this\n",
    "        # function is coded\n",
    "        pi = policyParams[:,state]\n",
    "        pi = pi - np.max(pi)\n",
    "        pi = np.exp(pi) / np.sum(np.exp(pi))\n",
    "        action = np.where(np.cumsum(pi) >= np.random.rand(1))[0][0]\n",
    "                          \n",
    "        return action\n",
    "\n",
    "    def modelBasedRL(self,s0,defaultT,initialR,nEpisodes,nSteps,epsilon=0):\n",
    "        '''Model-based Reinforcement Learning with epsilon greedy \n",
    "        exploration.  This function should use value iteration,\n",
    "        policy iteration or modified policy iteration to update the policy at each step\n",
    "\n",
    "        Inputs:\n",
    "        s0 -- initial state\n",
    "        defaultT -- default transition function when a state-action pair has not been vsited\n",
    "        initialR -- initial estimate of the reward function\n",
    "        nEpisodes -- # of episodes (one episode consists of a trajectory of nSteps that starts in s0\n",
    "        nSteps -- # of steps per episode\n",
    "        epsilon -- probability with which an action is chosen at random\n",
    "\n",
    "        Outputs: \n",
    "        V -- final value function\n",
    "        policy -- final policy\n",
    "        '''\n",
    "\n",
    "        # temporary values to ensure that the code compiles until this\n",
    "        # function is coded\n",
    "        count_triple = np.ones([self.mdp.nActions, self.mdp.nStates, self.mdp.nStates])\n",
    "        cumu_reward_lst = np.zeros(nEpisodes)\n",
    "        V = np.zeros(self.mdp.nStates)\n",
    "        policy = np.zeros(self.mdp.nStates,int)\n",
    "        mdp_tmp = MDP(defaultT, initialR, self.mdp.discount)\n",
    "        \n",
    "        for iterEp in range(nEpisodes):\n",
    "            state = s0\n",
    "            for iterSt in range(nSteps):\n",
    "                action = 0\n",
    "                if np.random.rand(1) < epsilon:\n",
    "                    action = np.random.randint(self.mdp.nActions)\n",
    "                else:\n",
    "                    action = policy[state]\n",
    "                [reward, nextState] = self.sampleRewardAndNextState(state,action)\n",
    "                cumu_reward_lst[iterEp] += self.mdp.discount**iterSt * reward\n",
    "                count_triple[action,state,nextState] += 1\n",
    "                count_double = np.sum(count_triple[action,state,:])\n",
    "                mdp_tmp.T[action,state,:] = count_triple[action,state,:] /  count_double\n",
    "                mdp_tmp.R[action, state] = (reward + (count_double-1) * mdp_tmp.R[action,state]) / count_double\n",
    "                [policy, V, iterId] = mdp_tmp.policyIteration(policy)\n",
    "                state = nextState\n",
    "        return [V,policy,cumu_reward_lst]\n",
    "    \n",
    "    def BayesQIteration(self,\n",
    "                        sim_initialQ,\n",
    "                        beliefT,beliefR,beliefRC,\n",
    "                        sampleSize,\n",
    "                        sim_nEpisodes,\n",
    "                        sim_nSteps,\n",
    "                        sim_s0,\n",
    "                        Sigma,\n",
    "                        temp=0):\n",
    "        def DirichletSample(params):\n",
    "            sample = np.vectorize(np.random.gamma)(params)\n",
    "            return sample / np.sum(sample)\n",
    "        simQ_lst=[]\n",
    "        sim_reward_history=[]\n",
    "        for iterSam in range(sampleSize):\n",
    "            simQ=sim_initialQ.copy()\n",
    "            sim_n_table=np.zeros(simQ.shape,dtype=int)\n",
    "            sim_learning_rate=1\n",
    "            sim_episodeId=0\n",
    "            sim_reward_episodes=[] # list of rewards of each episodes\n",
    "            # Sample the transition dynamics\n",
    "            sampleT = np.apply_along_axis(DirichletSample,2,beliefT)\n",
    "            sampleR = np.vectorize(np.random.normal)(beliefR,1.0/(1+beliefRC))\n",
    "            while(sim_episodeId < sim_nEpisodes):\n",
    "                sim_episodeId+=1\n",
    "                sim_s=sim_s0\n",
    "                sim_reward_cumu=0\n",
    "                sim_stepId=0\n",
    "                sim_discount_factor=1\n",
    "                while(sim_stepId < sim_nSteps):\n",
    "                    sim_stepId+=1\n",
    "                    sim_action=0\n",
    "                    if(temp != 0):\n",
    "                        boltz_state = np.exp(simQ[:,s].ravel() / temp)\n",
    "                        boltz_state = boltz_state / boltz_state.sum()\n",
    "                        boltz_state = np.cumsum(boltz_state)\n",
    "                        sim_action = np.where(boltz_state >= np.random.rand(1))[0][0]\n",
    "                    else:\n",
    "                        sim_action = simQ[:,sim_s].argmax()\n",
    "                    sim_reward=sampleR[sim_action][sim_s]\n",
    "                    sim_s_next=self.sampleAction(sampleT[sim_action][sim_s])\n",
    "                    sim_reward_cumu+=sim_discount_factor*sim_reward\n",
    "                    sim_n_table[sim_action,sim_s]+=1\n",
    "                    sim_learning_rate=1./sim_n_table[sim_action,sim_s]\n",
    "                    simQ[sim_action,sim_s]+=sim_learning_rate*(sim_reward+self.mdp.discount*np.max(simQ[:,sim_s_next].ravel())-simQ[sim_action,sim_s])\n",
    "                    sim_discount_factor*=self.mdp.discount\n",
    "                    sim_s=sim_s_next\n",
    "                sim_reward_episodes.append(sim_reward_cumu)\n",
    "            simQ_lst.append(simQ)\n",
    "            sim_reward_history.append(sim_reward_episodes)\n",
    "        return [np.array(simQ_lst).mean(0),sim_reward_history]\n",
    "    \n",
    "    def BayesModelBasedRL(self,s0,initialQ,nEpisodes,nSteps,sim_nEpisodes,sim_nSteps,\n",
    "                          Sigma=1):\n",
    "        '''\n",
    "        Inputs:\n",
    "        initialQ is Quality function of size |A| x |S|\n",
    "        beliefT is a |A| x |S| x |S'| array which is the Bayesian belief of the transition\n",
    "        dynamics in a family of Dirichlet distribution\n",
    "        beliefR is a |A| x |S| array which is the Bayesian belief of the mean of rewards\n",
    "        \n",
    "        '''\n",
    "        beliefT=np.ones([self.mdp.nActions, self.mdp.nStates, self.mdp.nStates]) # intial Dirichlet ditribution parameters\n",
    "        beliefR=np.zeros([self.mdp.nActions, self.mdp.nStates]) # initial weight given to action-state pairs\n",
    "        beliefRC=np.full([self.mdp.nActions, self.mdp.nStates],0) # count of the time the action-state pair is visited\n",
    "\n",
    "        episodeId=0\n",
    "        reward_episodes=[]\n",
    "        Q=initialQ\n",
    "        while(episodeId < nEpisodes):\n",
    "            episodeId+=1\n",
    "            print(\"-\",end='')\n",
    "            s=s0       \n",
    "            stepId=0\n",
    "            reward_cumu=0\n",
    "            discount_factor=1\n",
    "            while(stepId < nSteps):\n",
    "                stepId+=1\n",
    "                action=0\n",
    "                [Q,simH] = self.BayesQIteration(Q,beliefT,beliefR,beliefRC,\n",
    "                                                sampleSize=10,\n",
    "                                                sim_nEpisodes=sim_nEpisodes,\n",
    "                                                sim_nSteps=sim_nSteps,\n",
    "                                                sim_s0=s0,\n",
    "                                                Sigma=Sigma,\n",
    "                                                temp=0)\n",
    "                \n",
    "                action = self.sampleAction(Q[:,s].ravel())\n",
    "                \n",
    "                [reward,s_next] = self.sampleRewardAndNextState(s,action)\n",
    "                beliefT[action,s,s_next]+=1\n",
    "                if(beliefRC[action,s] == 0):\n",
    "                    beliefR[action,s]=reward\n",
    "                else:\n",
    "                    beliefR[action,s]=(beliefRC[action,s]*beliefR[action,s]+reward)/(beliefRC[action,s]+1)\n",
    "                beliefRC[action,s]+=1\n",
    "                s=s_next\n",
    "                reward_cumu+=discount_factor*reward\n",
    "                discount_factor*=self.mdp.discount\n",
    "            reward_episodes.append(reward_cumu)\n",
    "        print()\n",
    "        policy = Q.argmax(0)\n",
    "        return [Q,policy,reward_episodes]\n",
    "\n",
    "    def qLearning(self,s0,initialQ,nEpisodes,nSteps,epsilon=0,temperature=1):\n",
    "        '''qLearning algorithm.  Epsilon exploration and Boltzmann exploration\n",
    "        are combined in one procedure by sampling a random action with \n",
    "        probabilty epsilon and performing Boltzmann exploration otherwise.  \n",
    "        When epsilon and temperature are set to 0, there is no exploration.\n",
    "\n",
    "        Inputs:\n",
    "        s0 -- initial state\n",
    "        initialQ -- initial Q function (|A|x|S| array)\n",
    "        nEpisodes -- # of episodes (one episode consists of a trajectory of nSteps that starts in s0\n",
    "        nSteps -- # of steps per episode\n",
    "        epsilon -- probability with which an action is chosen at random\n",
    "        temperature -- parameter that regulates Boltzmann exploration\n",
    "\n",
    "        Outputs: \n",
    "        Q -- final Q function (|A|x|S| array)\n",
    "        policy -- final policy\n",
    "        '''\n",
    "\n",
    "        # temporary values to ensure that the code compiles until this\n",
    "        # function is coded\n",
    "        Q = initialQ\n",
    "        n_table = np.zeros(Q.shape,dtype=int)\n",
    "        learning_rate = 0\n",
    "        episodeId = 0\n",
    "        reward_episodes = []\n",
    "        while (episodeId < nEpisodes):\n",
    "            episodeId += 1\n",
    "            s=s0\n",
    "            reward_cum=0\n",
    "            stepId = 0\n",
    "            discount_factor = 1\n",
    "            while (stepId < nSteps):\n",
    "                stepId += 1\n",
    "                action = 0\n",
    "                discount_factor *= self.mdp.discount\n",
    "                if (np.random.rand(1) < epsilon):\n",
    "                    action = np.random.randint(self.mdp.nActions)\n",
    "                elif (temperature != 0):\n",
    "                    boltz_state = np.exp(Q[:,s].flatten() / temperature)\n",
    "                    boltz_state = boltz_state / boltz_state.sum()\n",
    "                    boltz_state = np.cumsum(boltz_state)\n",
    "                    action = np.where(boltz_state >= np.random.rand(1))[0][0]\n",
    "                else:\n",
    "                    action = Q[:,s].argmax()\n",
    "                [reward, s_next] = self.sampleRewardAndNextState(s,action)\n",
    "                n_table[action,s] += 1\n",
    "                learning_rate = 1 / n_table[action,s]\n",
    "                Q[action,s] = Q[action,s] + learning_rate*(reward + self.mdp.discount*np.max(Q[:,s_next].flatten())-Q[action,s])\n",
    "                s = s_next\n",
    "                reward_cum += discount_factor * reward\n",
    "            reward_episodes.append(reward_cum)\n",
    "        \n",
    "        policy = Q.argmax(0).flatten()\n",
    "\n",
    "        return [Q,policy, reward_episodes]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-dqgptFqk0Re"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7uBa2-9k0Rg"
   },
   "outputs": [],
   "source": [
    "# ''' Construct simple MDP as described in Lecture 2a Slides 13-14'''\n",
    "# T = np.array([[[0.5,0.5,0,0],[0,1,0,0],[0.5,0.5,0,0],[0,1,0,0]],[[1,0,0,0],[0.5,0,0,0.5],[0.5,0,0.5,0],[0,0,0.5,0.5]]])\n",
    "# R = np.array([[0,0,10,10],[0,0,10,10]])\n",
    "# discount = 0.9        \n",
    "# mdp = MDP(T,R,discount)\n",
    "# rlProblem = RL2(mdp,np.random.normal)\n",
    "# # # Test REINFORCE \n",
    "# # policy,cumu_reward = rlProblem.reinforce(s0=0,initialPolicyParams=np.random.rand(mdp.nActions,mdp.nStates),nEpisodes=100,nSteps=100)\n",
    "# # print (\"\\nREINFORCE results\")\n",
    "# # print (policy)\n",
    "# # plt.plot(list(range(100)), cumu_reward)\n",
    "\n",
    "# # Test model-based RL\n",
    "# [V,policy,cumu_reward] = rlProblem.modelBasedRL(s0=0,defaultT=np.ones([mdp.nActions,mdp.nStates,mdp.nStates])/mdp.nStates,initialR=np.zeros([mdp.nActions,mdp.nStates]),nEpisodes=100,nSteps=100,epsilon=0.3)\n",
    "# print (\"\\nmodel-based RL results\")\n",
    "# print (V)\n",
    "# print (policy)\n",
    "# plt.plot(list(range(100)), cumu_reward,'o-')\n",
    "\n",
    "# [Q,policy,cumu_reward] = rlProblem.qLearning(s0=0,initialQ=np.zeros([mdp.nActions,mdp.nStates]),nEpisodes=100,nSteps=100,epsilon=0.05,temperature=1)\n",
    "# print (\"\\nqLearning results\")\n",
    "# print (policy)\n",
    "# print(Q)\n",
    "# plt.plot(list(range(100)), cumu_reward,'*-')\n",
    "\n",
    "# [Q,policy,cumu_reward] = rlProblem.BayesModelBasedRL(s0=0,initialQ=np.zeros([mdp.nActions,mdp.nStates]),nEpisodes=10,nSteps=100,sim_nEpisodes=10,sim_nSteps=10,Sigma=1)\n",
    "# print (\"\\nBayesModelBasedRL results\")\n",
    "# print (policy)\n",
    "# print(Q)\n",
    "# plt.plot(list(range(10)), cumu_reward,'+-')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sIV5aHYgk0Ri"
   },
   "outputs": [],
   "source": [
    "# %load \"TestRL2Maze.py\"\n",
    "\n",
    "\n",
    "''' Construct a simple maze MDP\n",
    "\n",
    "  Grid world layout:\n",
    "\n",
    "  ---------------------\n",
    "  |  0 |  1 |  2 |  3 |\n",
    "  ---------------------\n",
    "  |  4 |  5 |  6 |  7 |\n",
    "  ---------------------\n",
    "  |  8 |  9 | 10 | 11 |\n",
    "  ---------------------\n",
    "  | 12 | 13 | 14 | 15 |\n",
    "  ---------------------\n",
    "\n",
    "  Goal state: 15 \n",
    "  Bad state: 9\n",
    "  End state: 16\n",
    "\n",
    "  The end state is an absorbing state that the agent transitions \n",
    "  to after visiting the goal state.\n",
    "\n",
    "  There are 17 states in total (including the end state) \n",
    "  and 4 actions (up, down, left, right).'''\n",
    "\n",
    "# Transition function: |A| x |S| x |S'| array\n",
    "T = np.zeros([4,17,17])\n",
    "a = 0.8;  # intended move\n",
    "b = 0.1;  # lateral move\n",
    "\n",
    "# up (a = 0)\n",
    "\n",
    "T[0,0,0] = a+b;\n",
    "T[0,0,1] = b;\n",
    "\n",
    "T[0,1,0] = b;\n",
    "T[0,1,1] = a;\n",
    "T[0,1,2] = b;\n",
    "\n",
    "T[0,2,1] = b;\n",
    "T[0,2,2] = a;\n",
    "T[0,2,3] = b;\n",
    "\n",
    "T[0,3,2] = b;\n",
    "T[0,3,3] = a+b;\n",
    "\n",
    "T[0,4,4] = b;\n",
    "T[0,4,0] = a;\n",
    "T[0,4,5] = b;\n",
    "\n",
    "T[0,5,4] = b;\n",
    "T[0,5,1] = a;\n",
    "T[0,5,6] = b;\n",
    "\n",
    "T[0,6,5] = b;\n",
    "T[0,6,2] = a;\n",
    "T[0,6,7] = b;\n",
    "\n",
    "T[0,7,6] = b;\n",
    "T[0,7,3] = a;\n",
    "T[0,7,7] = b;\n",
    "\n",
    "T[0,8,8] = b;\n",
    "T[0,8,4] = a;\n",
    "T[0,8,9] = b;\n",
    "\n",
    "T[0,9,8] = b;\n",
    "T[0,9,5] = a;\n",
    "T[0,9,10] = b;\n",
    "\n",
    "T[0,10,9] = b;\n",
    "T[0,10,6] = a;\n",
    "T[0,10,11] = b;\n",
    "\n",
    "T[0,11,10] = b;\n",
    "T[0,11,7] = a;\n",
    "T[0,11,11] = b;\n",
    "\n",
    "T[0,12,12] = b;\n",
    "T[0,12,8] = a;\n",
    "T[0,12,13] = b;\n",
    "\n",
    "T[0,13,12] = b;\n",
    "T[0,13,9] = a;\n",
    "T[0,13,14] = b;\n",
    "\n",
    "T[0,14,13] = b;\n",
    "T[0,14,10] = a;\n",
    "T[0,14,15] = b;\n",
    "\n",
    "T[0,15,16] = 1;\n",
    "T[0,16,16] = 1;\n",
    "\n",
    "# down (a = 1)\n",
    "\n",
    "T[1,0,0] = b;\n",
    "T[1,0,4] = a;\n",
    "T[1,0,1] = b;\n",
    "\n",
    "T[1,1,0] = b;\n",
    "T[1,1,5] = a;\n",
    "T[1,1,2] = b;\n",
    "\n",
    "T[1,2,1] = b;\n",
    "T[1,2,6] = a;\n",
    "T[1,2,3] = b;\n",
    "\n",
    "T[1,3,2] = b;\n",
    "T[1,3,7] = a;\n",
    "T[1,3,3] = b;\n",
    "\n",
    "T[1,4,4] = b;\n",
    "T[1,4,8] = a;\n",
    "T[1,4,5] = b;\n",
    "\n",
    "T[1,5,4] = b;\n",
    "T[1,5,9] = a;\n",
    "T[1,5,6] = b;\n",
    "\n",
    "T[1,6,5] = b;\n",
    "T[1,6,10] = a;\n",
    "T[1,6,7] = b;\n",
    "\n",
    "T[1,7,6] = b;\n",
    "T[1,7,11] = a;\n",
    "T[1,7,7] = b;\n",
    "\n",
    "T[1,8,8] = b;\n",
    "T[1,8,12] = a;\n",
    "T[1,8,9] = b;\n",
    "\n",
    "T[1,9,8] = b;\n",
    "T[1,9,13] = a;\n",
    "T[1,9,10] = b;\n",
    "\n",
    "T[1,10,9] = b;\n",
    "T[1,10,14] = a;\n",
    "T[1,10,11] = b;\n",
    "\n",
    "T[1,11,10] = b;\n",
    "T[1,11,15] = a;\n",
    "T[1,11,11] = b;\n",
    "\n",
    "T[1,12,12] = a+b;\n",
    "T[1,12,13] = b;\n",
    "\n",
    "T[1,13,12] = b;\n",
    "T[1,13,13] = a;\n",
    "T[1,13,14] = b;\n",
    "\n",
    "T[1,14,13] = b;\n",
    "T[1,14,14] = a;\n",
    "T[1,14,15] = b;\n",
    "\n",
    "T[1,15,16] = 1;\n",
    "T[1,16,16] = 1;\n",
    "\n",
    "# left (a = 2)\n",
    "\n",
    "T[2,0,0] = a+b;\n",
    "T[2,0,4] = b;\n",
    "\n",
    "T[2,1,1] = b;\n",
    "T[2,1,0] = a;\n",
    "T[2,1,5] = b;\n",
    "\n",
    "T[2,2,2] = b;\n",
    "T[2,2,1] = a;\n",
    "T[2,2,6] = b;\n",
    "\n",
    "T[2,3,3] = b;\n",
    "T[2,3,2] = a;\n",
    "T[2,3,7] = b;\n",
    "\n",
    "T[2,4,0] = b;\n",
    "T[2,4,4] = a;\n",
    "T[2,4,8] = b;\n",
    "\n",
    "T[2,5,1] = b;\n",
    "T[2,5,4] = a;\n",
    "T[2,5,9] = b;\n",
    "\n",
    "T[2,6,2] = b;\n",
    "T[2,6,5] = a;\n",
    "T[2,6,10] = b;\n",
    "\n",
    "T[2,7,3] = b;\n",
    "T[2,7,6] = a;\n",
    "T[2,7,11] = b;\n",
    "\n",
    "T[2,8,4] = b;\n",
    "T[2,8,8] = a;\n",
    "T[2,8,12] = b;\n",
    "\n",
    "T[2,9,5] = b;\n",
    "T[2,9,8] = a;\n",
    "T[2,9,13] = b;\n",
    "\n",
    "T[2,10,6] = b;\n",
    "T[2,10,9] = a;\n",
    "T[2,10,14] = b;\n",
    "\n",
    "T[2,11,7] = b;\n",
    "T[2,11,10] = a;\n",
    "T[2,11,15] = b;\n",
    "\n",
    "T[2,12,8] = b;\n",
    "T[2,12,12] = a+b;\n",
    "\n",
    "T[2,13,9] = b;\n",
    "T[2,13,12] = a;\n",
    "T[2,13,13] = b;\n",
    "\n",
    "T[2,14,10] = b;\n",
    "T[2,14,13] = a;\n",
    "T[2,14,14] = b;\n",
    "\n",
    "T[2,15,16] = 1;\n",
    "T[2,16,16] = 1;\n",
    "\n",
    "# right (a = 3)\n",
    "\n",
    "T[3,0,0] = b;\n",
    "T[3,0,1] = a;\n",
    "T[3,0,4] = b;\n",
    "\n",
    "T[3,1,1] = b;\n",
    "T[3,1,2] = a;\n",
    "T[3,1,5] = b;\n",
    "\n",
    "T[3,2,2] = b;\n",
    "T[3,2,3] = a;\n",
    "T[3,2,6] = b;\n",
    "\n",
    "T[3,3,3] = a+b;\n",
    "T[3,3,7] = b;\n",
    "\n",
    "T[3,4,0] = b;\n",
    "T[3,4,5] = a;\n",
    "T[3,4,8] = b;\n",
    "\n",
    "T[3,5,1] = b;\n",
    "T[3,5,6] = a;\n",
    "T[3,5,9] = b;\n",
    "\n",
    "T[3,6,2] = b;\n",
    "T[3,6,7] = a;\n",
    "T[3,6,10] = b;\n",
    "\n",
    "T[3,7,3] = b;\n",
    "T[3,7,7] = a;\n",
    "T[3,7,11] = b;\n",
    "\n",
    "T[3,8,4] = b;\n",
    "T[3,8,9] = a;\n",
    "T[3,8,12] = b;\n",
    "\n",
    "T[3,9,5] = b;\n",
    "T[3,9,10] = a;\n",
    "T[3,9,13] = b;\n",
    "\n",
    "T[3,10,6] = b;\n",
    "T[3,10,11] = a;\n",
    "T[3,10,14] = b;\n",
    "\n",
    "T[3,11,7] = b;\n",
    "T[3,11,11] = a;\n",
    "T[3,11,15] = b;\n",
    "\n",
    "T[3,12,8] = b;\n",
    "T[3,12,13] = a;\n",
    "T[3,12,12] = b;\n",
    "\n",
    "T[3,13,9] = b;\n",
    "T[3,13,14] = a;\n",
    "T[3,13,13] = b;\n",
    "\n",
    "T[3,14,10] = b;\n",
    "T[3,14,15] = a;\n",
    "T[3,14,14] = b;\n",
    "\n",
    "T[3,15,16] = 1;\n",
    "T[3,16,16] = 1;\n",
    "\n",
    "# Reward function: |A| x |S| array\n",
    "R = -1 * np.ones([4,17]);\n",
    "\n",
    "# set rewards\n",
    "R[:,15] = 100;  # goal state\n",
    "R[:,9] = -70;   # bad state\n",
    "R[:,16] = 0;    # end state\n",
    "\n",
    "# Discount factor: scalar in [0,1)\n",
    "discount = 0.95\n",
    "        \n",
    "# MDP object\n",
    "mdp = MDP(T,R,discount)\n",
    "\n",
    "# RL problem\n",
    "rlProblem = RL2(mdp,np.random.normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JAv02Yxvk0Rl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model-based RL results\n",
      "V:  [53.02094102 56.71541273 61.07769213 63.5211003  55.05781556 58.50467864\n",
      " 66.94696611 72.25955788 56.95305096 23.51403826 73.82302675 83.72957818\n",
      " 62.63987632 70.93468181 87.18418227 99.40838739  4.22172023]\n",
      "Policy:  [3 3 1 1 1 3 1 1 1 3 1 1 3 3 3 0 2]\n",
      "Time taken for each trial:  2.1293763160705566\n",
      "\n",
      "Q-learning results\n",
      "Q:  [[  0.4272683    7.89100625  -1.95483657  -0.47325427  -0.84109711\n",
      "   20.25542167  24.5010321   -0.15050098 -17.96734389 -71.14180671\n",
      "   31.17712669  73.50028377  -2.58295056   5.43287864  41.81798577\n",
      "  102.29154521   2.1995058 ]\n",
      " [ -2.56970611   5.04571549  53.62507347  44.14877579  -3.84400275\n",
      "   -6.20102163  70.00892438  81.16745001  -3.48822681 -71.6586331\n",
      "   56.1922032   92.76025899   5.72341879  -2.22054536  18.36121309\n",
      "  102.202066     2.19348103]\n",
      " [ -1.19121841   3.39736469  14.69834197  -1.68004691  -2.43226696\n",
      "   -2.07874099   4.68645565  -1.72101168  -3.5812027  -71.52699414\n",
      "  -35.37468851  77.72799446  -2.10578476  -3.05342045  11.62447526\n",
      "  102.0289197    2.19466394]\n",
      " [ 16.92791558  34.37183683  10.16911386   1.51611686   7.2976833\n",
      "   28.52519677  53.93401499  -0.62568659 -34.64482912   1.88330167\n",
      "   83.44442711  72.214222    -2.99344233  41.01282295  90.09627559\n",
      "    0.           2.17389162]]\n",
      "Policy:  [3 3 1 1 3 3 1 1 1 3 3 1 1 3 3 0 0]\n",
      "Time taken for each trial:  0.25503860831260683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f86eec949e8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "Trials = 100\n",
    "\n",
    "ax=plt.figure(figsize=(15,10))\n",
    "plt.grid()\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Rewards\")\n",
    "\n",
    "# Test model-based RL\n",
    "cumu_ma_1 = []\n",
    "start_time = time.time()\n",
    "for iterTr in range(Trials):\n",
    "    [V_1,policy_1,cumu_reward_1] = rlProblem.modelBasedRL(s0=0,defaultT=np.ones([mdp.nActions,mdp.nStates,mdp.nStates])/mdp.nStates,initialR=np.zeros([mdp.nActions,mdp.nStates]),nEpisodes=200,nSteps=100,epsilon=0.3)\n",
    "    cumu_ma_1.append(cumu_reward_1)\n",
    "print (\"\\nmodel-based RL results\")\n",
    "print (\"V: \", V_1)\n",
    "print (\"Policy: \", policy_1)\n",
    "print (\"Time taken for each trial: \", (time.time() - start_time)/200)\n",
    "plt.plot(list(range(200)), np.mean(cumu_ma_1,axis=0), label=\"Model-based RL\")\n",
    "\n",
    "# Test Q-learning\n",
    "cumu_ma_2 = []\n",
    "start_time = time.time()\n",
    "for iterTr in range(Trials):\n",
    "    [Q_2,policy_2,cumu_reward_2] = rlProblem.qLearning(s0=0,initialQ=np.zeros([mdp.nActions,mdp.nStates]),nEpisodes=200,nSteps=100,epsilon=0.05,temperature=1)\n",
    "    cumu_ma_2.append(cumu_reward_2)\n",
    "print (\"\\nQ-learning results\")\n",
    "print (\"Q: \", Q_2)\n",
    "print (\"Policy: \", policy_2)\n",
    "print (\"Time taken for each trial: \", (time.time() - start_time)/200)\n",
    "plt.plot(list(range(200)), np.mean(cumu_ma_2,axis=0), label=\"Q-learning\")\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMNarU8uk0Ro"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "BayesModelBasedRL results\n",
      "Q:  [[ -57.62809702   37.46772292  -44.82654079   48.14933621   48.84683948\n",
      "   -47.91057231   21.147497     46.00856267   26.52268234 -121.44040293\n",
      "    41.60115912  -56.84645445   27.34327053    5.77684165   31.12730514\n",
      "   -47.84822808   30.55824026]\n",
      " [  33.35750948   35.50801976   39.92495581   36.01711612  -59.17243073\n",
      "    29.75934871  -53.58039134   21.89142308   41.76716977  -34.43124462\n",
      "    21.33336015  -60.52922749  -48.8338349    24.86740012    0.29528447\n",
      "   -55.92268583  -62.1182569 ]\n",
      " [  43.34306242  -55.52626353   49.48875478  -42.96006375  -59.17881079\n",
      "   -56.51835048   30.9262423   -48.68307197  -49.87299069  -35.41568748\n",
      "   -52.46121922   35.8945595   -50.05821181   38.43836745   35.00409891\n",
      "   -55.22090189   31.83474096]\n",
      " [ -60.41257151  -55.81900469  -55.71653039  -54.46014253   32.72187668\n",
      "    38.93370418   42.26846026  -56.56166457   19.67049162  -49.4729526\n",
      "    37.35922327   45.02676787   45.38235999  -53.57016953  -54.06703559\n",
      "   151.96806805  -52.85722146]]\n",
      "Policy:  [2 0 2 0 0 3 3 0 1 1 0 3 3 2 2 3 2]\n",
      "Time taken for each trial:  298.6707491874695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f86eeb866a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=plt.figure(figsize=(15,10))\n",
    "plt.grid()\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Rewards\")\n",
    "\n",
    "cumu_ma_3 = []\n",
    "start_time = time.time()\n",
    "for iterTr in range(1):\n",
    "    [Q_3,policy_3,cumu_reward_3] = rlProblem.BayesModelBasedRL(s0=0,initialQ=np.zeros([mdp.nActions,mdp.nStates]),nEpisodes=50,nSteps=100,sim_nEpisodes=10,sim_nSteps=10,Sigma=1)\n",
    "    cumu_ma_3.append(cumu_reward_3)\n",
    "print (\"\\nBayesModelBasedRL results\")\n",
    "print (\"Q: \", Q_3)\n",
    "print (\"Policy: \", policy_3)\n",
    "print (\"Time taken for each trial: \", (time.time() - start_time)/1)\n",
    "plt.plot(list(range(50)), np.mean(cumu_ma_3,axis=0), label=\"BayesModelBasedRL\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_hDwudCk0Rr"
   },
   "outputs": [],
   "source": [
    "# with open('MazeRL.pkl','wb') as f:\n",
    "#     pickle.dump(ax, f)\n",
    "# plt.savefig(\"MazeRL.jpg\")\n",
    "# plt.show()\n",
    "\n",
    "# with open(\"MazeRL.pkl\",'rb') as f:\n",
    "#     handle=pickle.load(f)\n",
    "#     plt.plot(x,[z**2 for z in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4IQaK_Lk0Rv",
    "outputId": "b213e186-38a3-4b68-d9c1-19f487e7dd1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "from keras.layers import Input, LSTM, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical as to_cat\n",
    "tf.reset_default_graph()\n",
    "gc.collect()\n",
    "gpu_fraction = 0.5\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "class memory:\n",
    "    def __init__(self,memory_size,belief_size,state_size,action_size):\n",
    "        self.size=0\n",
    "        self.memory_size=memory_size\n",
    "        self.belief_size=belief_size\n",
    "        self.state_size=state_size\n",
    "        self.action_size=action_size\n",
    "        self.mem_belief=np.empty([memory_size,self.belief_size])\n",
    "        self.mem_state=np.empty([memory_size,self.state_size])\n",
    "        self.mem_action=np.empty([memory_size,self.action_size])\n",
    "        self.mem_reward=np.empty([memory_size,1])\n",
    "\n",
    "    def push(self,belief,state,action,reward):\n",
    "        if(self.size < self.memory_size):\n",
    "            self.mem_belief[self.size]=belief\n",
    "            self.mem_state[self.size]=state\n",
    "            self.mem_action[self.size]=action\n",
    "            self.mem_reward[self.size]=reward\n",
    "            self.size+=1\n",
    "        else:\n",
    "            self.size=0\n",
    "            self.mem_belief[self.size]=self.mem_belief[-1]\n",
    "            self.mem_state[self.size]=self.mem_state[-1]\n",
    "            self.mem_action[self.size]=self.mem_action[-1]\n",
    "            self.mem_reward[self.size]=self.mem_reward[-1]\n",
    "            self.size+=1\n",
    "          \n",
    "class SRL:\n",
    "\n",
    "    def __init__(self,\n",
    "                 belief_size,\n",
    "                 state_size,\n",
    "                 action_size,\n",
    "                 mdp,\n",
    "                 sampleReward):\n",
    "        self.belief_size=belief_size\n",
    "        self.state_size=state_size\n",
    "        self.action_size=action_size\n",
    "        self.mdp = mdp\n",
    "        self.sampleReward = sampleReward\n",
    "        \n",
    "    def sampleRewardAndNextState(self,state,action):\n",
    "        '''Procedure to sample a reward and the next state\n",
    "        reward ~ Pr(r)\n",
    "        nextState ~ Pr(s'|s,a)\n",
    "\n",
    "        Inputs:\n",
    "        state -- current state\n",
    "        action -- action to be executed\n",
    "\n",
    "        Outputs: \n",
    "        reward -- sampled reward\n",
    "        nextState -- sampled next state\n",
    "        '''\n",
    "\n",
    "        reward = self.sampleReward(self.mdp.R[action,state])\n",
    "        cumProb = np.cumsum(self.mdp.T[action,state,:])\n",
    "        nextState = np.where(cumProb >= np.random.rand(1))[0][0]\n",
    "        return [reward,nextState]\n",
    "\n",
    "    def sampleAction(self,q):\n",
    "        a = q - np.max(q)\n",
    "        a = np.exp(a) / np.sum(np.exp(a))\n",
    "        return np.where(np.cumsum(a) >= np.random.rand(1))[0][0]\n",
    "        \n",
    "    def sampleSoftmaxPolicy(self,policyParams,state):\n",
    "        '''Procedure to sample an action from stochastic policy\n",
    "        pi(a|s) = exp(policyParams(a,s))/[sum_a' exp(policyParams(a',s))])\n",
    "        This function should be called by reinforce() to selection actions\n",
    "\n",
    "        Inputs:\n",
    "        policyParams -- parameters of a softmax policy (|A|x|S| array)\n",
    "        state -- current state\n",
    "\n",
    "        Outputs: \n",
    "        action -- sampled action\n",
    "        '''\n",
    "\n",
    "        # temporary value to ensure that the code compiles until this\n",
    "        # function is coded\n",
    "        pi = policyParams[:,state]\n",
    "        pi = pi - np.max(pi)\n",
    "        pi = np.exp(pi) / np.sum(np.exp(pi))\n",
    "        action = np.where(np.cumsum(pi) >= np.random.rand(1))[0][0]\n",
    "                          \n",
    "        return action\n",
    "    def build_model(self,\n",
    "                    prefix,\n",
    "                    batch_size,\n",
    "                    RNN_type,\n",
    "                    Dense_num_units,\n",
    "                    Dropout_rate,\n",
    "                    weight_state,\n",
    "                    weight_reward,\n",
    "                    Dense_num_units2,\n",
    "                    Dropout_rate2,\n",
    "                    weight_real):\n",
    "        \n",
    "        # build_Bayes_model\n",
    "        Bayes_input_state = Input(shape=(1,self.state_size),\n",
    "                                  batch_shape=(batch_size,1,self.state_size),\n",
    "                                  dtype='float32',name=prefix+'Bayes_input_state')\n",
    "        Bayes_input_action = Input(shape=(1,self.action_size),\n",
    "                                   batch_shape=(batch_size,1,self.action_size),\n",
    "                                   dtype='float32',name=prefix+'Bayes_input_action')\n",
    "        Bayes_input = keras.layers.concatenate([Bayes_input_state,\n",
    "                                                Bayes_input_action],axis=-1)\n",
    "        if(RNN_type is LSTM):\n",
    "            rnn = RNN_type(self.belief_size,\n",
    "                           activity_regularizer=keras.regularizers.l2(-0.000001),\n",
    "                           return_state=True,\n",
    "                           stateful=True,\n",
    "                           name=prefix+'LSTM')\n",
    "            nnreset = getattr(rnn,'reset_states')\n",
    "            [state_reward,_,belief]=rnn(Bayes_input)\n",
    "            x_state = Dense(Dense_num_units,activation='tanh',\n",
    "                            name=prefix+'LstmDenseState1B')(state_reward)\n",
    "            x_state = Dropout(Dropout_rate,\n",
    "                              name=prefix+'LstmDropoutState1B')(x_state)\n",
    "            x_state = Dense(Dense_num_units,activation='tanh',\n",
    "                            name=prefix+'LstmDenseState2B')(x_state)\n",
    "            Bayes_output_state = Dense(self.state_size,activation='softmax',\n",
    "                                       name=prefix+'Bayes_output_state')(x_state)\n",
    "            \n",
    "            x_reward = Dense(Dense_num_units,activation='tanh',\n",
    "                             name=prefix+'LstmDenseReward1B')(state_reward)\n",
    "            x_reward = Dropout(Dropout_rate,\n",
    "                               name=prefix+'LstmDropoutReward1B')(x_reward)\n",
    "            x_reward = Dense(Dense_num_units,activation='tanh',\n",
    "                             name=prefix+'LstmDenseReward2B')(x_reward)\n",
    "            Bayes_output_reward = Dense(1,activation='linear',\n",
    "                                        name=prefix+'Bayes_output_reward')(x_reward)\n",
    "\n",
    "        Bayes_model = Model(inputs=[Bayes_input_state,\n",
    "                                    Bayes_input_action],\n",
    "                            outputs=[belief,\n",
    "                                     state_reward,\n",
    "                                     Bayes_output_state,\n",
    "                                     Bayes_output_reward])\n",
    "        Bayes_model.compile(optimizer='rmsprop',\n",
    "                           loss={prefix+'Bayes_output_state' : 'categorical_crossentropy',\n",
    "                                 prefix+'Bayes_output_reward' : 'mean_squared_error'},\n",
    "                           loss_weights={prefix+'Bayes_output_state' : weight_state,\n",
    "                                         prefix+'Bayes_output_reward' : weight_reward},\n",
    "                           metrics={prefix+'Bayes_output_state' : 'categorical_accuracy',\n",
    "                                   prefix+'Bayes_output_reward' : 'mae'}\n",
    "                           )\n",
    "    \n",
    "        # build_RL_model\n",
    "        RL_input_belief = Input(shape=(self.belief_size,),\n",
    "                                batch_shape=(batch_size,self.belief_size),\n",
    "                                dtype='float32',name=prefix+'RL_input_belief')\n",
    "        RL_input_state = Input(shape=(self.state_size,),\n",
    "                               batch_shape=(batch_size,self.state_size),\n",
    "                               dtype='float32',name=prefix+'RL_input_state')\n",
    "        RL_input = keras.layers.concatenate([RL_input_belief,RL_input_state],axis=-1)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense1')(RL_input)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense2')(x)\n",
    "        x = Dropout(Dropout_rate2,\n",
    "                    name=prefix+'RL_Dropout1')(x)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense3')(x)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense4')(x)\n",
    "        x = Dropout(Dropout_rate2,\n",
    "                    name=prefix+'RL_Dropout2')(x)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense5')(x)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense6')(x)\n",
    "        x = Dropout(Dropout_rate2,\n",
    "                    name=prefix+'RL_Dropout3')(x)\n",
    "        RL_Output = Dense(self.action_size,activation='softmax',\n",
    "                          name=prefix+'RL_output_action')(x)\n",
    "        RL_Model = Model(inputs=[RL_input_belief,RL_input_state],\n",
    "                         outputs=RL_Output,name=prefix+\"RL_Output\")\n",
    "        \n",
    "        RL_model = Model(inputs=[RL_input_belief,\n",
    "                                 RL_input_state],\n",
    "                         outputs=RL_Model([RL_input_belief,RL_input_state]))\n",
    "        RL_model.compile(optimizer='Adam',\n",
    "                         loss=lambda y_true,y_pred : y_true)\n",
    "        \n",
    "        SRL_output = RL_Model([belief,RL_input_state])\n",
    "        SRL_model = Model(inputs=[Bayes_input_state,\n",
    "                                  Bayes_input_action,\n",
    "                                  RL_input_state],\n",
    "                         outputs=[SRL_output,\n",
    "                                  belief,\n",
    "                                  Bayes_output_state,\n",
    "                                  Bayes_output_reward])\n",
    "        SRL_model.compile(optimizer='rmsprop',\n",
    "                          loss={prefix+'RL_Output' :\n",
    "                                lambda y_true,y_pred : y_true,\n",
    "                                prefix+'Bayes_output_state' : 'categorical_crossentropy',\n",
    "                                prefix+'Bayes_output_reward' : 'mean_squared_error'},\n",
    "                          loss_weights={\n",
    "                              prefix+'RL_Output' : \n",
    "                              weight_real,\n",
    "                              prefix+'Bayes_output_state' : \n",
    "                              weight_state/(1-weight_real),\n",
    "                              prefix+'Bayes_output_reward' : \n",
    "                              weight_reward/(1-weight_real)},\n",
    "                          )\n",
    "        \n",
    "        return [Bayes_model,RL_model,SRL_model,nnreset]\n",
    "    \n",
    "    # shuffle = False\n",
    "        \n",
    "    def SRLearn(self,memory_size,nEpisodes,nSteps,\n",
    "                boot_epochs,boot_steps,update_steps):\n",
    "        assert(boot_steps>=update_steps)\n",
    "        args=[1,LSTM,50,0.1,0.999,0.001,100,0.1,0.8]\n",
    "        real_mem=memory(memory_size,self.belief_size,self.state_size,self.action_size)\n",
    "        [bayes,rl,srl,nnreset]=self.build_model('main_',*args)\n",
    "        [bayes_t,rl_t,srl_t,nnreset_t]=self.build_model('target_',*args)\n",
    "        iterEp=0\n",
    "        # bootstrap\n",
    "        init_belief=np.zeros([1,self.belief_size])\n",
    "        init_state_reward=np.zeros([1,self.belief_size])\n",
    "        init_h = [init_belief,init_state_reward]\n",
    "        boot_mem=memory(boot_steps,self.belief_size,self.state_size,self.action_size)\n",
    "        for it in range(boot_steps):\n",
    "            s=np.random.randint(self.state_size)\n",
    "            action=np.random.randint(self.action_size)\n",
    "            [reward,s_next]=self.sampleRewardAndNextState(s,action)\n",
    "            s=to_cat(s,self.state_size)\n",
    "            action=to_cat(action,self.action_size)\n",
    "            reward=np.array([reward])\n",
    "            boot_mem.push(np.zeros(self.belief_size),s,action,reward)\n",
    "            s=s_next\n",
    "        for itEp in range(boot_epochs):\n",
    "            print('Boot_Epochs:\\t',itEp,'/',boot_epochs)\n",
    "            nnreset(init_h)\n",
    "            bayes.fit([boot_mem.mem_state[:-1].reshape([boot_steps-1,1,-1]),\n",
    "                      boot_mem.mem_action[:-1].reshape([boot_steps-1,1,-1])],\n",
    "                     [boot_mem.mem_state[1:].reshape([boot_steps-1,-1]),\n",
    "                      boot_mem.mem_reward[:-1].reshape([boot_steps-1,-1])],\n",
    "                      epochs=1,\n",
    "                      batch_size=1)\n",
    "        [boot_belief,boot_state_reward,_,_]=bayes.predict([boot_mem.mem_state[-1].reshape([1,1,-1]),\n",
    "                                                          boot_mem.mem_action[-1].reshape([1,1,-1])])\n",
    "        # Testing Bayes Model\n",
    "        nnreset([boot_belief,boot_state_reward])\n",
    "        print(boot_belief,boot_state_reward)\n",
    "        count1=0\n",
    "        for i in range(99):\n",
    "            s=boot_mem.mem_state[i].reshape([1,1,-1])\n",
    "            action=boot_mem.mem_action[i].reshape([1,1,-1])\n",
    "            [_,__,s_n,reward]=bayes.predict([s,action])\n",
    "            print(_)\n",
    "            print('T',boot_mem.mem_state[i+1].argmax())\n",
    "            print('P',s_n.argmax())\n",
    "            if(boot_mem.mem_state[i+1].argmax()==s_n.argmax()):\n",
    "                count1+=1\n",
    "            print('T',boot_mem.mem_reward[i])\n",
    "            print('P',reward)\n",
    "        print('--------------------------------------------')\n",
    "        nnreset(init_h)\n",
    "        count2=0\n",
    "        for i in range(99):\n",
    "            s=boot_mem.mem_state[i].reshape([1,1,-1])\n",
    "            action=boot_mem.mem_action[i].reshape([1,1,-1])\n",
    "            [_,__,s_n,reward]=bayes.predict([s,action])\n",
    "            print(_)\n",
    "            print('T',boot_mem.mem_state[i+1].argmax())\n",
    "            print('P',s_n.argmax())\n",
    "            if(boot_mem.mem_state[i+1].argmax()==s_n.argmax()):\n",
    "                count2+=1\n",
    "            print('T',boot_mem.mem_reward[i])\n",
    "            print('P',reward)\n",
    "            \n",
    "        print(count1,count2)\n",
    "        \n",
    "        while(iterEp < nEpisodes):\n",
    "            iterEp+=1\n",
    "            iterSt=0\n",
    "            while(iterSt < nSteps):\n",
    "                iterSt+=1\n",
    "                pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKi438MHk0R0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haobei/Program/anaconda3/envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:154: UserWarning: Output \"main_LSTM\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"main_LSTM\" during training.\n",
      "/home/haobei/Program/anaconda3/envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:213: UserWarning: Output \"main_LSTM\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"main_LSTM\" during training.\n",
      "/home/haobei/Program/anaconda3/envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:154: UserWarning: Output \"target_LSTM\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"target_LSTM\" during training.\n",
      "/home/haobei/Program/anaconda3/envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:213: UserWarning: Output \"target_LSTM\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"target_LSTM\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boot_Epochs:\t 0 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 3.5524 - main_Bayes_output_state_loss: 2.8373 - main_Bayes_output_reward_loss: 718.0199 - main_Bayes_output_state_categorical_accuracy: 0.0505 - main_Bayes_output_reward_mean_absolute_error: 8.3594\n",
      "Boot_Epochs:\t 1 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 3.4970 - main_Bayes_output_state_loss: 2.7865 - main_Bayes_output_reward_loss: 713.2342 - main_Bayes_output_state_categorical_accuracy: 0.1212 - main_Bayes_output_reward_mean_absolute_error: 8.5090\n",
      "Boot_Epochs:\t 2 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.4634 - main_Bayes_output_state_loss: 2.7561 - main_Bayes_output_reward_loss: 710.0772 - main_Bayes_output_state_categorical_accuracy: 0.1414 - main_Bayes_output_reward_mean_absolute_error: 8.6457\n",
      "Boot_Epochs:\t 3 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.4436 - main_Bayes_output_state_loss: 2.7439 - main_Bayes_output_reward_loss: 702.4798 - main_Bayes_output_state_categorical_accuracy: 0.1010 - main_Bayes_output_reward_mean_absolute_error: 9.0663\n",
      "Boot_Epochs:\t 4 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3860 - main_Bayes_output_state_loss: 2.6934 - main_Bayes_output_reward_loss: 695.2484 - main_Bayes_output_state_categorical_accuracy: 0.0909 - main_Bayes_output_reward_mean_absolute_error: 9.1811\n",
      "Boot_Epochs:\t 5 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.4303 - main_Bayes_output_state_loss: 2.7516 - main_Bayes_output_reward_loss: 681.5214 - main_Bayes_output_state_categorical_accuracy: 0.1111 - main_Bayes_output_reward_mean_absolute_error: 10.0545\n",
      "Boot_Epochs:\t 6 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3821 - main_Bayes_output_state_loss: 2.7174 - main_Bayes_output_reward_loss: 667.3987 - main_Bayes_output_state_categorical_accuracy: 0.1414 - main_Bayes_output_reward_mean_absolute_error: 10.7207\n",
      "Boot_Epochs:\t 7 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.4231 - main_Bayes_output_state_loss: 2.7482 - main_Bayes_output_reward_loss: 677.6754 - main_Bayes_output_state_categorical_accuracy: 0.0808 - main_Bayes_output_reward_mean_absolute_error: 11.2943\n",
      "Boot_Epochs:\t 8 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3413 - main_Bayes_output_state_loss: 2.6800 - main_Bayes_output_reward_loss: 664.0141 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 11.4719\n",
      "Boot_Epochs:\t 9 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2755 - main_Bayes_output_state_loss: 2.6024 - main_Bayes_output_reward_loss: 675.7211 - main_Bayes_output_state_categorical_accuracy: 0.1515 - main_Bayes_output_reward_mean_absolute_error: 9.8152\n",
      "Boot_Epochs:\t 10 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.4815 - main_Bayes_output_state_loss: 2.7909 - main_Bayes_output_reward_loss: 693.3613 - main_Bayes_output_state_categorical_accuracy: 0.1414 - main_Bayes_output_reward_mean_absolute_error: 11.4217\n",
      "Boot_Epochs:\t 11 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.4252 - main_Bayes_output_state_loss: 2.7521 - main_Bayes_output_reward_loss: 675.9258 - main_Bayes_output_state_categorical_accuracy: 0.1212 - main_Bayes_output_reward_mean_absolute_error: 10.3544\n",
      "Boot_Epochs:\t 12 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3718 - main_Bayes_output_state_loss: 2.7096 - main_Bayes_output_reward_loss: 664.9124 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 10.5838\n",
      "Boot_Epochs:\t 13 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3258 - main_Bayes_output_state_loss: 2.6528 - main_Bayes_output_reward_loss: 675.6524 - main_Bayes_output_state_categorical_accuracy: 0.1515 - main_Bayes_output_reward_mean_absolute_error: 11.2654\n",
      "Boot_Epochs:\t 14 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3863 - main_Bayes_output_state_loss: 2.6966 - main_Bayes_output_reward_loss: 692.4323 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 10.7813\n",
      "Boot_Epochs:\t 15 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2290 - main_Bayes_output_state_loss: 2.5914 - main_Bayes_output_reward_loss: 640.1586 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 10.5395\n",
      "Boot_Epochs:\t 16 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2936 - main_Bayes_output_state_loss: 2.6461 - main_Bayes_output_reward_loss: 650.1916 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 11.2896\n",
      "Boot_Epochs:\t 17 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3321 - main_Bayes_output_state_loss: 2.6516 - main_Bayes_output_reward_loss: 683.1502 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 11.1728\n",
      "Boot_Epochs:\t 18 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2722 - main_Bayes_output_state_loss: 2.6398 - main_Bayes_output_reward_loss: 635.1439 - main_Bayes_output_state_categorical_accuracy: 0.1515 - main_Bayes_output_reward_mean_absolute_error: 10.4027\n",
      "Boot_Epochs:\t 19 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2215 - main_Bayes_output_state_loss: 2.5638 - main_Bayes_output_reward_loss: 660.3173 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 10.6263\n",
      "Boot_Epochs:\t 20 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2860 - main_Bayes_output_state_loss: 2.6194 - main_Bayes_output_reward_loss: 669.2619 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 11.8542\n",
      "Boot_Epochs:\t 21 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2305 - main_Bayes_output_state_loss: 2.5613 - main_Bayes_output_reward_loss: 671.7995 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 10.5605\n",
      "Boot_Epochs:\t 22 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2529 - main_Bayes_output_state_loss: 2.6004 - main_Bayes_output_reward_loss: 655.1984 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 10.5482\n",
      "Boot_Epochs:\t 23 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2765 - main_Bayes_output_state_loss: 2.6052 - main_Bayes_output_reward_loss: 673.9557 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 10.1495\n",
      "Boot_Epochs:\t 24 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3349 - main_Bayes_output_state_loss: 2.6685 - main_Bayes_output_reward_loss: 669.1590 - main_Bayes_output_state_categorical_accuracy: 0.1414 - main_Bayes_output_reward_mean_absolute_error: 10.0965\n",
      "Boot_Epochs:\t 25 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3387 - main_Bayes_output_state_loss: 2.6656 - main_Bayes_output_reward_loss: 675.8001 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 10.3911\n",
      "Boot_Epochs:\t 26 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3487 - main_Bayes_output_state_loss: 2.6777 - main_Bayes_output_reward_loss: 673.7010 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 10.4680\n",
      "Boot_Epochs:\t 27 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3049 - main_Bayes_output_state_loss: 2.6232 - main_Bayes_output_reward_loss: 684.4598 - main_Bayes_output_state_categorical_accuracy: 0.1313 - main_Bayes_output_reward_mean_absolute_error: 10.4428\n",
      "Boot_Epochs:\t 28 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1972 - main_Bayes_output_state_loss: 2.5428 - main_Bayes_output_reward_loss: 657.1000 - main_Bayes_output_state_categorical_accuracy: 0.2222 - main_Bayes_output_reward_mean_absolute_error: 10.5545\n",
      "Boot_Epochs:\t 29 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2042 - main_Bayes_output_state_loss: 2.5414 - main_Bayes_output_reward_loss: 665.4242 - main_Bayes_output_state_categorical_accuracy: 0.1414 - main_Bayes_output_reward_mean_absolute_error: 9.7675\n",
      "Boot_Epochs:\t 30 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2794 - main_Bayes_output_state_loss: 2.6276 - main_Bayes_output_reward_loss: 654.5462 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 11.0636\n",
      "Boot_Epochs:\t 31 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2355 - main_Bayes_output_state_loss: 2.5820 - main_Bayes_output_reward_loss: 656.1285 - main_Bayes_output_state_categorical_accuracy: 0.1515 - main_Bayes_output_reward_mean_absolute_error: 10.4311\n",
      "Boot_Epochs:\t 32 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2328 - main_Bayes_output_state_loss: 2.5821 - main_Bayes_output_reward_loss: 653.2879 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 10.7143\n",
      "Boot_Epochs:\t 33 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1473 - main_Bayes_output_state_loss: 2.4893 - main_Bayes_output_reward_loss: 660.5657 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 10.6904\n",
      "Boot_Epochs:\t 34 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2745 - main_Bayes_output_state_loss: 2.6075 - main_Bayes_output_reward_loss: 669.6508 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 11.3566\n",
      "Boot_Epochs:\t 35 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2995 - main_Bayes_output_state_loss: 2.6480 - main_Bayes_output_reward_loss: 654.2598 - main_Bayes_output_state_categorical_accuracy: 0.1515 - main_Bayes_output_reward_mean_absolute_error: 10.2731\n",
      "Boot_Epochs:\t 36 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1985 - main_Bayes_output_state_loss: 2.5460 - main_Bayes_output_reward_loss: 655.1625 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 10.8167\n",
      "Boot_Epochs:\t 37 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2854 - main_Bayes_output_state_loss: 2.6192 - main_Bayes_output_reward_loss: 668.9986 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 10.4187\n",
      "Boot_Epochs:\t 38 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1474 - main_Bayes_output_state_loss: 2.4798 - main_Bayes_output_reward_loss: 670.1798 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 10.3322\n",
      "Boot_Epochs:\t 39 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2319 - main_Bayes_output_state_loss: 2.5783 - main_Bayes_output_reward_loss: 656.2488 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 10.6038\n",
      "Boot_Epochs:\t 40 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.4016 - main_Bayes_output_state_loss: 2.7418 - main_Bayes_output_reward_loss: 662.6110 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 10.6457\n",
      "Boot_Epochs:\t 41 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2373 - main_Bayes_output_state_loss: 2.5818 - main_Bayes_output_reward_loss: 658.2103 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 10.2789\n",
      "Boot_Epochs:\t 42 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3060 - main_Bayes_output_state_loss: 2.6585 - main_Bayes_output_reward_loss: 650.2450 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 10.5491\n",
      "Boot_Epochs:\t 43 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2860 - main_Bayes_output_state_loss: 2.6105 - main_Bayes_output_reward_loss: 678.1899 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 9.8757\n",
      "Boot_Epochs:\t 44 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1524 - main_Bayes_output_state_loss: 2.5290 - main_Bayes_output_reward_loss: 626.0824 - main_Bayes_output_state_categorical_accuracy: 0.2222 - main_Bayes_output_reward_mean_absolute_error: 10.0562\n",
      "Boot_Epochs:\t 45 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1870 - main_Bayes_output_state_loss: 2.5512 - main_Bayes_output_reward_loss: 638.4596 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 10.6699\n",
      "Boot_Epochs:\t 46 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2452 - main_Bayes_output_state_loss: 2.5748 - main_Bayes_output_reward_loss: 673.1527 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 10.1287\n",
      "Boot_Epochs:\t 47 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2585 - main_Bayes_output_state_loss: 2.5803 - main_Bayes_output_reward_loss: 681.1799 - main_Bayes_output_state_categorical_accuracy: 0.1313 - main_Bayes_output_reward_mean_absolute_error: 11.1795\n",
      "Boot_Epochs:\t 48 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2856 - main_Bayes_output_state_loss: 2.6363 - main_Bayes_output_reward_loss: 652.1478 - main_Bayes_output_state_categorical_accuracy: 0.0808 - main_Bayes_output_reward_mean_absolute_error: 9.9408\n",
      "Boot_Epochs:\t 49 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2189 - main_Bayes_output_state_loss: 2.5746 - main_Bayes_output_reward_loss: 647.2606 - main_Bayes_output_state_categorical_accuracy: 0.1515 - main_Bayes_output_reward_mean_absolute_error: 9.5998\n",
      "Boot_Epochs:\t 50 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2686 - main_Bayes_output_state_loss: 2.6412 - main_Bayes_output_reward_loss: 631.1232 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 9.9629\n",
      "Boot_Epochs:\t 51 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1673 - main_Bayes_output_state_loss: 2.5327 - main_Bayes_output_reward_loss: 637.8414 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 10.1778\n",
      "Boot_Epochs:\t 52 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1975 - main_Bayes_output_state_loss: 2.5331 - main_Bayes_output_reward_loss: 667.8497 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 10.7886\n",
      "Boot_Epochs:\t 53 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2731 - main_Bayes_output_state_loss: 2.6075 - main_Bayes_output_reward_loss: 669.5528 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 10.9400\n",
      "Boot_Epochs:\t 54 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2778 - main_Bayes_output_state_loss: 2.5976 - main_Bayes_output_reward_loss: 683.8228 - main_Bayes_output_state_categorical_accuracy: 0.1414 - main_Bayes_output_reward_mean_absolute_error: 10.7264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boot_Epochs:\t 55 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1720 - main_Bayes_output_state_loss: 2.5024 - main_Bayes_output_reward_loss: 673.7655 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 10.1912\n",
      "Boot_Epochs:\t 56 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2478 - main_Bayes_output_state_loss: 2.5786 - main_Bayes_output_reward_loss: 673.7986 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 10.3329\n",
      "Boot_Epochs:\t 57 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1819 - main_Bayes_output_state_loss: 2.5347 - main_Bayes_output_reward_loss: 652.3153 - main_Bayes_output_state_categorical_accuracy: 0.2222 - main_Bayes_output_reward_mean_absolute_error: 9.6807\n",
      "Boot_Epochs:\t 58 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1686 - main_Bayes_output_state_loss: 2.5064 - main_Bayes_output_reward_loss: 666.8106 - main_Bayes_output_state_categorical_accuracy: 0.1515 - main_Bayes_output_reward_mean_absolute_error: 10.2313\n",
      "Boot_Epochs:\t 59 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1473 - main_Bayes_output_state_loss: 2.4771 - main_Bayes_output_reward_loss: 675.0530 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 9.8830\n",
      "Boot_Epochs:\t 60 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1913 - main_Bayes_output_state_loss: 2.5463 - main_Bayes_output_reward_loss: 650.3891 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 9.9885\n",
      "Boot_Epochs:\t 61 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1554 - main_Bayes_output_state_loss: 2.5249 - main_Bayes_output_reward_loss: 636.1819 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 10.7925\n",
      "Boot_Epochs:\t 62 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1372 - main_Bayes_output_state_loss: 2.4686 - main_Bayes_output_reward_loss: 673.8184 - main_Bayes_output_state_categorical_accuracy: 0.2525 - main_Bayes_output_reward_mean_absolute_error: 11.0792\n",
      "Boot_Epochs:\t 63 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2397 - main_Bayes_output_state_loss: 2.5738 - main_Bayes_output_reward_loss: 670.8210 - main_Bayes_output_state_categorical_accuracy: 0.1717 - main_Bayes_output_reward_mean_absolute_error: 10.1425\n",
      "Boot_Epochs:\t 64 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1425 - main_Bayes_output_state_loss: 2.4681 - main_Bayes_output_reward_loss: 679.0332 - main_Bayes_output_state_categorical_accuracy: 0.2222 - main_Bayes_output_reward_mean_absolute_error: 10.8106\n",
      "Boot_Epochs:\t 65 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2979 - main_Bayes_output_state_loss: 2.6260 - main_Bayes_output_reward_loss: 677.0619 - main_Bayes_output_state_categorical_accuracy: 0.1515 - main_Bayes_output_reward_mean_absolute_error: 10.0021\n",
      "Boot_Epochs:\t 66 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2433 - main_Bayes_output_state_loss: 2.5859 - main_Bayes_output_reward_loss: 663.2236 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 10.1694\n",
      "Boot_Epochs:\t 67 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1088 - main_Bayes_output_state_loss: 2.4613 - main_Bayes_output_reward_loss: 653.1856 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 9.8214\n",
      "Boot_Epochs:\t 68 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2419 - main_Bayes_output_state_loss: 2.6173 - main_Bayes_output_reward_loss: 629.2198 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 9.5601\n",
      "Boot_Epochs:\t 69 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1367 - main_Bayes_output_state_loss: 2.5106 - main_Bayes_output_reward_loss: 631.9447 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 10.7191\n",
      "Boot_Epochs:\t 70 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1918 - main_Bayes_output_state_loss: 2.5354 - main_Bayes_output_reward_loss: 662.1187 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 9.9435\n",
      "Boot_Epochs:\t 71 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0847 - main_Bayes_output_state_loss: 2.4615 - main_Bayes_output_reward_loss: 629.1136 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 10.1532\n",
      "Boot_Epochs:\t 72 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2027 - main_Bayes_output_state_loss: 2.5629 - main_Bayes_output_reward_loss: 645.8334 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 10.1106\n",
      "Boot_Epochs:\t 73 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0665 - main_Bayes_output_state_loss: 2.4410 - main_Bayes_output_reward_loss: 631.0027 - main_Bayes_output_state_categorical_accuracy: 0.2222 - main_Bayes_output_reward_mean_absolute_error: 10.6223\n",
      "Boot_Epochs:\t 74 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1210 - main_Bayes_output_state_loss: 2.4922 - main_Bayes_output_reward_loss: 634.7372 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 10.5800\n",
      "Boot_Epochs:\t 75 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1419 - main_Bayes_output_state_loss: 2.5053 - main_Bayes_output_reward_loss: 642.1785 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 9.8636\n",
      "Boot_Epochs:\t 76 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1108 - main_Bayes_output_state_loss: 2.4799 - main_Bayes_output_reward_loss: 636.1798 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 10.1817\n",
      "Boot_Epochs:\t 77 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2237 - main_Bayes_output_state_loss: 2.5748 - main_Bayes_output_reward_loss: 655.1714 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 9.8403\n",
      "Boot_Epochs:\t 78 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2064 - main_Bayes_output_state_loss: 2.5731 - main_Bayes_output_reward_loss: 639.3882 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 10.2869\n",
      "Boot_Epochs:\t 79 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1657 - main_Bayes_output_state_loss: 2.5577 - main_Bayes_output_reward_loss: 613.9920 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 10.2592\n",
      "Boot_Epochs:\t 80 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1744 - main_Bayes_output_state_loss: 2.5496 - main_Bayes_output_reward_loss: 630.7128 - main_Bayes_output_state_categorical_accuracy: 0.1414 - main_Bayes_output_reward_mean_absolute_error: 9.3558\n",
      "Boot_Epochs:\t 81 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1788 - main_Bayes_output_state_loss: 2.5294 - main_Bayes_output_reward_loss: 655.4851 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 9.9406\n",
      "Boot_Epochs:\t 82 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1228 - main_Bayes_output_state_loss: 2.4953 - main_Bayes_output_reward_loss: 633.6508 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 9.3541\n",
      "Boot_Epochs:\t 83 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.2115 - main_Bayes_output_state_loss: 2.5855 - main_Bayes_output_reward_loss: 632.5417 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 9.9291\n",
      "Boot_Epochs:\t 84 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0520 - main_Bayes_output_state_loss: 2.4480 - main_Bayes_output_reward_loss: 610.8146 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 9.6480\n",
      "Boot_Epochs:\t 85 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1579 - main_Bayes_output_state_loss: 2.5181 - main_Bayes_output_reward_loss: 646.5121 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 8.9100\n",
      "Boot_Epochs:\t 86 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0922 - main_Bayes_output_state_loss: 2.4957 - main_Bayes_output_reward_loss: 603.6420 - main_Bayes_output_state_categorical_accuracy: 0.1515 - main_Bayes_output_reward_mean_absolute_error: 9.7786\n",
      "Boot_Epochs:\t 87 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1390 - main_Bayes_output_state_loss: 2.5231 - main_Bayes_output_reward_loss: 622.9980 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 9.5273\n",
      "Boot_Epochs:\t 88 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1044 - main_Bayes_output_state_loss: 2.4693 - main_Bayes_output_reward_loss: 642.1288 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 10.1047\n",
      "Boot_Epochs:\t 89 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0820 - main_Bayes_output_state_loss: 2.5012 - main_Bayes_output_reward_loss: 588.2919 - main_Bayes_output_state_categorical_accuracy: 0.2323 - main_Bayes_output_reward_mean_absolute_error: 10.0037\n",
      "Boot_Epochs:\t 90 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0815 - main_Bayes_output_state_loss: 2.4562 - main_Bayes_output_reward_loss: 633.1326 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 10.5569\n",
      "Boot_Epochs:\t 91 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0522 - main_Bayes_output_state_loss: 2.5101 - main_Bayes_output_reward_loss: 549.8758 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 9.4994\n",
      "Boot_Epochs:\t 92 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0214 - main_Bayes_output_state_loss: 2.4612 - main_Bayes_output_reward_loss: 568.3937 - main_Bayes_output_state_categorical_accuracy: 0.2222 - main_Bayes_output_reward_mean_absolute_error: 9.9127\n",
      "Boot_Epochs:\t 93 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0626 - main_Bayes_output_state_loss: 2.4293 - main_Bayes_output_reward_loss: 641.0964 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 10.4296\n",
      "Boot_Epochs:\t 94 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0397 - main_Bayes_output_state_loss: 2.4435 - main_Bayes_output_reward_loss: 604.0134 - main_Bayes_output_state_categorical_accuracy: 0.2525 - main_Bayes_output_reward_mean_absolute_error: 9.7073\n",
      "Boot_Epochs:\t 95 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9674 - main_Bayes_output_state_loss: 2.3623 - main_Bayes_output_reward_loss: 613.2735 - main_Bayes_output_state_categorical_accuracy: 0.2525 - main_Bayes_output_reward_mean_absolute_error: 10.1341\n",
      "Boot_Epochs:\t 96 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9449 - main_Bayes_output_state_loss: 2.3956 - main_Bayes_output_reward_loss: 557.4963 - main_Bayes_output_state_categorical_accuracy: 0.2525 - main_Bayes_output_reward_mean_absolute_error: 9.7630\n",
      "Boot_Epochs:\t 97 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0614 - main_Bayes_output_state_loss: 2.4258 - main_Bayes_output_reward_loss: 643.4739 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 10.1710\n",
      "Boot_Epochs:\t 98 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9920 - main_Bayes_output_state_loss: 2.4369 - main_Bayes_output_reward_loss: 563.2965 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 9.4981\n",
      "Boot_Epochs:\t 99 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0007 - main_Bayes_output_state_loss: 2.4704 - main_Bayes_output_reward_loss: 539.1156 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 8.9709\n",
      "Boot_Epochs:\t 100 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9935 - main_Bayes_output_state_loss: 2.4207 - main_Bayes_output_reward_loss: 581.6708 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 9.0390\n",
      "Boot_Epochs:\t 101 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9764 - main_Bayes_output_state_loss: 2.4190 - main_Bayes_output_reward_loss: 566.8516 - main_Bayes_output_state_categorical_accuracy: 0.2222 - main_Bayes_output_reward_mean_absolute_error: 9.4900\n",
      "Boot_Epochs:\t 102 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9912 - main_Bayes_output_state_loss: 2.4490 - main_Bayes_output_reward_loss: 551.2812 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 10.1822\n",
      "Boot_Epochs:\t 103 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9124 - main_Bayes_output_state_loss: 2.3650 - main_Bayes_output_reward_loss: 557.2470 - main_Bayes_output_state_categorical_accuracy: 0.2525 - main_Bayes_output_reward_mean_absolute_error: 9.5550\n",
      "Boot_Epochs:\t 104 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9572 - main_Bayes_output_state_loss: 2.4039 - main_Bayes_output_reward_loss: 563.6750 - main_Bayes_output_state_categorical_accuracy: 0.2323 - main_Bayes_output_reward_mean_absolute_error: 9.5447\n",
      "Boot_Epochs:\t 105 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0046 - main_Bayes_output_state_loss: 2.4396 - main_Bayes_output_reward_loss: 575.2510 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 10.3992\n",
      "Boot_Epochs:\t 106 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0335 - main_Bayes_output_state_loss: 2.4613 - main_Bayes_output_reward_loss: 583.6506 - main_Bayes_output_state_categorical_accuracy: 0.2323 - main_Bayes_output_reward_mean_absolute_error: 8.8775\n",
      "Boot_Epochs:\t 107 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0000 - main_Bayes_output_state_loss: 2.4612 - main_Bayes_output_reward_loss: 550.7679 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 9.2935\n",
      "Boot_Epochs:\t 108 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9614 - main_Bayes_output_state_loss: 2.4327 - main_Bayes_output_reward_loss: 540.7299 - main_Bayes_output_state_categorical_accuracy: 0.2222 - main_Bayes_output_reward_mean_absolute_error: 9.2192\n",
      "Boot_Epochs:\t 109 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0038 - main_Bayes_output_state_loss: 2.4450 - main_Bayes_output_reward_loss: 571.1649 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 10.0219\n",
      "Boot_Epochs:\t 110 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8650 - main_Bayes_output_state_loss: 2.3965 - main_Bayes_output_reward_loss: 481.7427 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 9.3511\n",
      "Boot_Epochs:\t 111 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8769 - main_Bayes_output_state_loss: 2.3904 - main_Bayes_output_reward_loss: 500.0656 - main_Bayes_output_state_categorical_accuracy: 0.2222 - main_Bayes_output_reward_mean_absolute_error: 8.0108\n",
      "Boot_Epochs:\t 112 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9364 - main_Bayes_output_state_loss: 2.4681 - main_Bayes_output_reward_loss: 482.5996 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 9.0513\n",
      "Boot_Epochs:\t 113 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8647 - main_Bayes_output_state_loss: 2.3636 - main_Bayes_output_reward_loss: 515.7654 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 8.8342\n",
      "Boot_Epochs:\t 114 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7931 - main_Bayes_output_state_loss: 2.3422 - main_Bayes_output_reward_loss: 465.0351 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 8.0650\n",
      "Boot_Epochs:\t 115 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8193 - main_Bayes_output_state_loss: 2.2966 - main_Bayes_output_reward_loss: 537.1562 - main_Bayes_output_state_categorical_accuracy: 0.2323 - main_Bayes_output_reward_mean_absolute_error: 9.6973\n",
      "Boot_Epochs:\t 116 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8751 - main_Bayes_output_state_loss: 2.4155 - main_Bayes_output_reward_loss: 474.7338 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 8.6082\n",
      "Boot_Epochs:\t 117 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8714 - main_Bayes_output_state_loss: 2.3875 - main_Bayes_output_reward_loss: 498.6912 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 9.1360\n",
      "Boot_Epochs:\t 118 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8925 - main_Bayes_output_state_loss: 2.4075 - main_Bayes_output_reward_loss: 499.8045 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 9.2228\n",
      "Boot_Epochs:\t 119 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.0073 - main_Bayes_output_state_loss: 2.5225 - main_Bayes_output_reward_loss: 499.9304 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 9.4008\n",
      "Boot_Epochs:\t 120 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9466 - main_Bayes_output_state_loss: 2.4525 - main_Bayes_output_reward_loss: 509.6146 - main_Bayes_output_state_categorical_accuracy: 0.1616 - main_Bayes_output_reward_mean_absolute_error: 9.1260\n",
      "Boot_Epochs:\t 121 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8298 - main_Bayes_output_state_loss: 2.3729 - main_Bayes_output_reward_loss: 471.8618 - main_Bayes_output_state_categorical_accuracy: 0.2323 - main_Bayes_output_reward_mean_absolute_error: 8.8171\n",
      "Boot_Epochs:\t 122 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9176 - main_Bayes_output_state_loss: 2.4254 - main_Bayes_output_reward_loss: 505.9043 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 8.5461\n",
      "Boot_Epochs:\t 123 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7379 - main_Bayes_output_state_loss: 2.3080 - main_Bayes_output_reward_loss: 445.2689 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 8.3137\n",
      "Boot_Epochs:\t 124 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9425 - main_Bayes_output_state_loss: 2.4793 - main_Bayes_output_reward_loss: 478.3433 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 8.2246\n",
      "Boot_Epochs:\t 125 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8734 - main_Bayes_output_state_loss: 2.3662 - main_Bayes_output_reward_loss: 522.7969 - main_Bayes_output_state_categorical_accuracy: 0.2222 - main_Bayes_output_reward_mean_absolute_error: 8.5830\n",
      "Boot_Epochs:\t 126 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7980 - main_Bayes_output_state_loss: 2.3502 - main_Bayes_output_reward_loss: 463.2683 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 8.0511\n",
      "Boot_Epochs:\t 127 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8630 - main_Bayes_output_state_loss: 2.4141 - main_Bayes_output_reward_loss: 464.7415 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 8.6707\n",
      "Boot_Epochs:\t 128 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 2.9547 - main_Bayes_output_state_loss: 2.4428 - main_Bayes_output_reward_loss: 529.2934 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 8.2551\n",
      "Boot_Epochs:\t 129 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8643 - main_Bayes_output_state_loss: 2.3732 - main_Bayes_output_reward_loss: 510.2471 - main_Bayes_output_state_categorical_accuracy: 0.2323 - main_Bayes_output_reward_mean_absolute_error: 8.5017\n",
      "Boot_Epochs:\t 130 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7732 - main_Bayes_output_state_loss: 2.3632 - main_Bayes_output_reward_loss: 428.6934 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 8.4322\n",
      "Boot_Epochs:\t 131 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7492 - main_Bayes_output_state_loss: 2.3709 - main_Bayes_output_reward_loss: 396.0412 - main_Bayes_output_state_categorical_accuracy: 0.2525 - main_Bayes_output_reward_mean_absolute_error: 8.1583\n",
      "Boot_Epochs:\t 132 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.9563 - main_Bayes_output_state_loss: 2.4668 - main_Bayes_output_reward_loss: 508.4081 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 8.4660\n",
      "Boot_Epochs:\t 133 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.6447 - main_Bayes_output_state_loss: 2.3249 - main_Bayes_output_reward_loss: 340.5500 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 7.0029\n",
      "Boot_Epochs:\t 134 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7609 - main_Bayes_output_state_loss: 2.3832 - main_Bayes_output_reward_loss: 398.4169 - main_Bayes_output_state_categorical_accuracy: 0.1818 - main_Bayes_output_reward_mean_absolute_error: 7.4797\n",
      "Boot_Epochs:\t 135 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7854 - main_Bayes_output_state_loss: 2.4365 - main_Bayes_output_reward_loss: 371.5493 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 7.7021\n",
      "Boot_Epochs:\t 136 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7993 - main_Bayes_output_state_loss: 2.3744 - main_Bayes_output_reward_loss: 448.7895 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 7.0155\n",
      "Boot_Epochs:\t 137 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7886 - main_Bayes_output_state_loss: 2.3386 - main_Bayes_output_reward_loss: 472.9171 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 8.2648\n",
      "Boot_Epochs:\t 138 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.8546 - main_Bayes_output_state_loss: 2.4498 - main_Bayes_output_reward_loss: 429.2149 - main_Bayes_output_state_categorical_accuracy: 0.1212 - main_Bayes_output_reward_mean_absolute_error: 7.5594\n",
      "Boot_Epochs:\t 139 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7305 - main_Bayes_output_state_loss: 2.3590 - main_Bayes_output_reward_loss: 396.4529 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 7.4870\n",
      "Boot_Epochs:\t 140 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.6532 - main_Bayes_output_state_loss: 2.3001 - main_Bayes_output_reward_loss: 375.8318 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 8.2299\n",
      "Boot_Epochs:\t 141 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.6898 - main_Bayes_output_state_loss: 2.2777 - main_Bayes_output_reward_loss: 437.1832 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 7.5752\n",
      "Boot_Epochs:\t 142 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7112 - main_Bayes_output_state_loss: 2.3532 - main_Bayes_output_reward_loss: 384.0006 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 7.8465\n",
      "Boot_Epochs:\t 143 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7315 - main_Bayes_output_state_loss: 2.3410 - main_Bayes_output_reward_loss: 417.3384 - main_Bayes_output_state_categorical_accuracy: 0.2020 - main_Bayes_output_reward_mean_absolute_error: 7.3553\n",
      "Boot_Epochs:\t 144 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7066 - main_Bayes_output_state_loss: 2.3881 - main_Bayes_output_reward_loss: 344.6865 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 7.0615\n",
      "Boot_Epochs:\t 145 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5993 - main_Bayes_output_state_loss: 2.2891 - main_Bayes_output_reward_loss: 338.9483 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 7.0093\n",
      "Boot_Epochs:\t 146 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.6813 - main_Bayes_output_state_loss: 2.2694 - main_Bayes_output_reward_loss: 439.6344 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 7.3425\n",
      "Boot_Epochs:\t 147 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.6791 - main_Bayes_output_state_loss: 2.3520 - main_Bayes_output_reward_loss: 356.0870 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 7.6299\n",
      "Boot_Epochs:\t 148 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.6570 - main_Bayes_output_state_loss: 2.3030 - main_Bayes_output_reward_loss: 386.2722 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 7.7973\n",
      "Boot_Epochs:\t 149 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5760 - main_Bayes_output_state_loss: 2.2776 - main_Bayes_output_reward_loss: 331.0089 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 6.8527\n",
      "Boot_Epochs:\t 150 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7007 - main_Bayes_output_state_loss: 2.3046 - main_Bayes_output_reward_loss: 431.2139 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 7.0795\n",
      "Boot_Epochs:\t 151 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.6796 - main_Bayes_output_state_loss: 2.3767 - main_Bayes_output_reward_loss: 338.6639 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 6.6773\n",
      "Boot_Epochs:\t 152 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5244 - main_Bayes_output_state_loss: 2.2705 - main_Bayes_output_reward_loss: 289.5139 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 5.9821\n",
      "Boot_Epochs:\t 153 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5482 - main_Bayes_output_state_loss: 2.2904 - main_Bayes_output_reward_loss: 296.3877 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 6.2301\n",
      "Boot_Epochs:\t 154 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5860 - main_Bayes_output_state_loss: 2.3363 - main_Bayes_output_reward_loss: 288.6273 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 5.8062\n",
      "Boot_Epochs:\t 155 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.7318 - main_Bayes_output_state_loss: 2.3372 - main_Bayes_output_reward_loss: 435.9760 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 7.0297\n",
      "Boot_Epochs:\t 156 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.6328 - main_Bayes_output_state_loss: 2.3190 - main_Bayes_output_reward_loss: 356.5025 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 6.6812\n",
      "Boot_Epochs:\t 157 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.6250 - main_Bayes_output_state_loss: 2.3537 - main_Bayes_output_reward_loss: 312.0763 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 6.8462\n",
      "Boot_Epochs:\t 158 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.6038 - main_Bayes_output_state_loss: 2.3094 - main_Bayes_output_reward_loss: 332.9819 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 7.6683\n",
      "Boot_Epochs:\t 159 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4941 - main_Bayes_output_state_loss: 2.2549 - main_Bayes_output_reward_loss: 280.9503 - main_Bayes_output_state_categorical_accuracy: 0.2525 - main_Bayes_output_reward_mean_absolute_error: 6.3538\n",
      "Boot_Epochs:\t 160 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5225 - main_Bayes_output_state_loss: 2.2526 - main_Bayes_output_reward_loss: 311.8606 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 6.5976\n",
      "Boot_Epochs:\t 161 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.6278 - main_Bayes_output_state_loss: 2.2166 - main_Bayes_output_reward_loss: 451.6147 - main_Bayes_output_state_categorical_accuracy: 0.2525 - main_Bayes_output_reward_mean_absolute_error: 9.0859\n",
      "Boot_Epochs:\t 162 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5503 - main_Bayes_output_state_loss: 2.2632 - main_Bayes_output_reward_loss: 332.3179 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 6.8174\n",
      "Boot_Epochs:\t 163 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5074 - main_Bayes_output_state_loss: 2.2779 - main_Bayes_output_reward_loss: 276.3485 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 6.2461\n",
      "Boot_Epochs:\t 164 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4966 - main_Bayes_output_state_loss: 2.2445 - main_Bayes_output_reward_loss: 299.8200 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 6.5101\n",
      "Boot_Epochs:\t 165 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5894 - main_Bayes_output_state_loss: 2.2874 - main_Bayes_output_reward_loss: 349.8444 - main_Bayes_output_state_categorical_accuracy: 0.2929 - main_Bayes_output_reward_mean_absolute_error: 6.2913\n",
      "Boot_Epochs:\t 166 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4057 - main_Bayes_output_state_loss: 2.1718 - main_Bayes_output_reward_loss: 280.5126 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 6.4727\n",
      "Boot_Epochs:\t 167 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3963 - main_Bayes_output_state_loss: 2.2033 - main_Bayes_output_reward_loss: 242.7532 - main_Bayes_output_state_categorical_accuracy: 0.3030 - main_Bayes_output_reward_mean_absolute_error: 5.8566\n",
      "Boot_Epochs:\t 168 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4941 - main_Bayes_output_state_loss: 2.2596 - main_Bayes_output_reward_loss: 285.4621 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 6.8672\n",
      "Boot_Epochs:\t 169 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4681 - main_Bayes_output_state_loss: 2.2064 - main_Bayes_output_reward_loss: 312.3325 - main_Bayes_output_state_categorical_accuracy: 0.2929 - main_Bayes_output_reward_mean_absolute_error: 6.2616\n",
      "Boot_Epochs:\t 170 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4728 - main_Bayes_output_state_loss: 2.2775 - main_Bayes_output_reward_loss: 249.4376 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 5.9915\n",
      "Boot_Epochs:\t 171 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5208 - main_Bayes_output_state_loss: 2.2627 - main_Bayes_output_reward_loss: 315.5095 - main_Bayes_output_state_categorical_accuracy: 0.2929 - main_Bayes_output_reward_mean_absolute_error: 6.3252\n",
      "Boot_Epochs:\t 172 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5103 - main_Bayes_output_state_loss: 2.2609 - main_Bayes_output_reward_loss: 307.6448 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 6.5146\n",
      "Boot_Epochs:\t 173 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4102 - main_Bayes_output_state_loss: 2.2843 - main_Bayes_output_reward_loss: 185.2465 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 4.9746\n",
      "Boot_Epochs:\t 174 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.5609 - main_Bayes_output_state_loss: 2.2573 - main_Bayes_output_reward_loss: 362.2803 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 7.3955\n",
      "Boot_Epochs:\t 175 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4072 - main_Bayes_output_state_loss: 2.2294 - main_Bayes_output_reward_loss: 237.9173 - main_Bayes_output_state_categorical_accuracy: 0.3131 - main_Bayes_output_reward_mean_absolute_error: 5.5259\n",
      "Boot_Epochs:\t 176 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4083 - main_Bayes_output_state_loss: 2.2189 - main_Bayes_output_reward_loss: 251.1359 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 5.8176\n",
      "Boot_Epochs:\t 177 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4097 - main_Bayes_output_state_loss: 2.2291 - main_Bayes_output_reward_loss: 243.0388 - main_Bayes_output_state_categorical_accuracy: 0.2121 - main_Bayes_output_reward_mean_absolute_error: 5.7648\n",
      "Boot_Epochs:\t 178 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3650 - main_Bayes_output_state_loss: 2.1729 - main_Bayes_output_reward_loss: 254.9389 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 6.0755\n",
      "Boot_Epochs:\t 179 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3199 - main_Bayes_output_state_loss: 2.1472 - main_Bayes_output_reward_loss: 235.8589 - main_Bayes_output_state_categorical_accuracy: 0.3030 - main_Bayes_output_reward_mean_absolute_error: 5.9482\n",
      "Boot_Epochs:\t 180 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3479 - main_Bayes_output_state_loss: 2.1445 - main_Bayes_output_reward_loss: 269.1625 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 6.0218\n",
      "Boot_Epochs:\t 181 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4852 - main_Bayes_output_state_loss: 2.2286 - main_Bayes_output_reward_loss: 325.0236 - main_Bayes_output_state_categorical_accuracy: 0.3030 - main_Bayes_output_reward_mean_absolute_error: 6.6267\n",
      "Boot_Epochs:\t 182 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2603 - main_Bayes_output_state_loss: 2.1435 - main_Bayes_output_reward_loss: 184.7039 - main_Bayes_output_state_categorical_accuracy: 0.2929 - main_Bayes_output_reward_mean_absolute_error: 4.8658\n",
      "Boot_Epochs:\t 183 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4228 - main_Bayes_output_state_loss: 2.2096 - main_Bayes_output_reward_loss: 282.6358 - main_Bayes_output_state_categorical_accuracy: 0.1919 - main_Bayes_output_reward_mean_absolute_error: 5.4119\n",
      "Boot_Epochs:\t 184 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2877 - main_Bayes_output_state_loss: 2.1049 - main_Bayes_output_reward_loss: 252.6372 - main_Bayes_output_state_categorical_accuracy: 0.3636 - main_Bayes_output_reward_mean_absolute_error: 4.9915\n",
      "Boot_Epochs:\t 185 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3487 - main_Bayes_output_state_loss: 2.1593 - main_Bayes_output_reward_loss: 256.3532 - main_Bayes_output_state_categorical_accuracy: 0.2929 - main_Bayes_output_reward_mean_absolute_error: 5.9407\n",
      "Boot_Epochs:\t 186 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2959 - main_Bayes_output_state_loss: 2.1802 - main_Bayes_output_reward_loss: 181.0892 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 5.5622\n",
      "Boot_Epochs:\t 187 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3607 - main_Bayes_output_state_loss: 2.0815 - main_Bayes_output_reward_loss: 348.1061 - main_Bayes_output_state_categorical_accuracy: 0.3333 - main_Bayes_output_reward_mean_absolute_error: 6.0803\n",
      "Boot_Epochs:\t 188 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3629 - main_Bayes_output_state_loss: 2.1634 - main_Bayes_output_reward_loss: 268.6583 - main_Bayes_output_state_categorical_accuracy: 0.3131 - main_Bayes_output_reward_mean_absolute_error: 5.5103\n",
      "Boot_Epochs:\t 189 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2574 - main_Bayes_output_state_loss: 2.1348 - main_Bayes_output_reward_loss: 193.3469 - main_Bayes_output_state_categorical_accuracy: 0.3131 - main_Bayes_output_reward_mean_absolute_error: 4.9754\n",
      "Boot_Epochs:\t 190 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2874 - main_Bayes_output_state_loss: 2.2148 - main_Bayes_output_reward_loss: 137.8748 - main_Bayes_output_state_categorical_accuracy: 0.2929 - main_Bayes_output_reward_mean_absolute_error: 4.1528\n",
      "Boot_Epochs:\t 191 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3697 - main_Bayes_output_state_loss: 2.1816 - main_Bayes_output_reward_loss: 258.4805 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 5.3869\n",
      "Boot_Epochs:\t 192 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3711 - main_Bayes_output_state_loss: 2.2149 - main_Bayes_output_reward_loss: 230.0235 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 5.3662\n",
      "Boot_Epochs:\t 193 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3131 - main_Bayes_output_state_loss: 2.2280 - main_Bayes_output_reward_loss: 159.0466 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 4.4402\n",
      "Boot_Epochs:\t 194 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2843 - main_Bayes_output_state_loss: 2.1680 - main_Bayes_output_reward_loss: 190.8892 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 5.0262\n",
      "Boot_Epochs:\t 195 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2378 - main_Bayes_output_state_loss: 2.1873 - main_Bayes_output_reward_loss: 125.2042 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 4.2145\n",
      "Boot_Epochs:\t 196 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2154 - main_Bayes_output_state_loss: 2.1777 - main_Bayes_output_reward_loss: 112.8691 - main_Bayes_output_state_categorical_accuracy: 0.2929 - main_Bayes_output_reward_mean_absolute_error: 3.7768\n",
      "Boot_Epochs:\t 197 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2919 - main_Bayes_output_state_loss: 2.2097 - main_Bayes_output_reward_loss: 158.0120 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 4.4889\n",
      "Boot_Epochs:\t 198 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2364 - main_Bayes_output_state_loss: 2.2159 - main_Bayes_output_reward_loss: 94.4705 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 3.8728\n",
      "Boot_Epochs:\t 199 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2093 - main_Bayes_output_state_loss: 2.1040 - main_Bayes_output_reward_loss: 181.3240 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 5.2230\n",
      "Boot_Epochs:\t 200 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2056 - main_Bayes_output_state_loss: 2.1167 - main_Bayes_output_reward_loss: 165.5372 - main_Bayes_output_state_categorical_accuracy: 0.2929 - main_Bayes_output_reward_mean_absolute_error: 4.1948\n",
      "Boot_Epochs:\t 201 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2150 - main_Bayes_output_state_loss: 2.1406 - main_Bayes_output_reward_loss: 151.5567 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 4.0627\n",
      "Boot_Epochs:\t 202 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.1808 - main_Bayes_output_state_loss: 2.1275 - main_Bayes_output_reward_loss: 130.8237 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 3.8017\n",
      "Boot_Epochs:\t 203 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2466 - main_Bayes_output_state_loss: 2.1784 - main_Bayes_output_reward_loss: 147.0337 - main_Bayes_output_state_categorical_accuracy: 0.2525 - main_Bayes_output_reward_mean_absolute_error: 4.2344\n",
      "Boot_Epochs:\t 204 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3184 - main_Bayes_output_state_loss: 2.2142 - main_Bayes_output_reward_loss: 182.4501 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 4.2429\n",
      "Boot_Epochs:\t 205 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3487 - main_Bayes_output_state_loss: 2.1784 - main_Bayes_output_reward_loss: 248.5581 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 5.3218\n",
      "Boot_Epochs:\t 206 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2257 - main_Bayes_output_state_loss: 2.1563 - main_Bayes_output_reward_loss: 148.8089 - main_Bayes_output_state_categorical_accuracy: 0.3030 - main_Bayes_output_reward_mean_absolute_error: 4.0367\n",
      "Boot_Epochs:\t 207 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2050 - main_Bayes_output_state_loss: 2.1760 - main_Bayes_output_reward_loss: 110.2309 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 3.7558\n",
      "Boot_Epochs:\t 208 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2732 - main_Bayes_output_state_loss: 2.1990 - main_Bayes_output_reward_loss: 155.4812 - main_Bayes_output_state_categorical_accuracy: 0.2929 - main_Bayes_output_reward_mean_absolute_error: 4.3572\n",
      "Boot_Epochs:\t 209 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2070 - main_Bayes_output_state_loss: 2.1223 - main_Bayes_output_reward_loss: 164.3782 - main_Bayes_output_state_categorical_accuracy: 0.3131 - main_Bayes_output_reward_mean_absolute_error: 4.6298\n",
      "Boot_Epochs:\t 210 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2371 - main_Bayes_output_state_loss: 2.0828 - main_Bayes_output_reward_loss: 237.3640 - main_Bayes_output_state_categorical_accuracy: 0.3030 - main_Bayes_output_reward_mean_absolute_error: 4.6960\n",
      "Boot_Epochs:\t 211 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3729 - main_Bayes_output_state_loss: 2.1140 - main_Bayes_output_reward_loss: 342.7339 - main_Bayes_output_state_categorical_accuracy: 0.2525 - main_Bayes_output_reward_mean_absolute_error: 6.0505\n",
      "Boot_Epochs:\t 212 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3211 - main_Bayes_output_state_loss: 2.1346 - main_Bayes_output_reward_loss: 272.6236 - main_Bayes_output_state_categorical_accuracy: 0.2929 - main_Bayes_output_reward_mean_absolute_error: 5.8053\n",
      "Boot_Epochs:\t 213 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.1371 - main_Bayes_output_state_loss: 2.0872 - main_Bayes_output_reward_loss: 136.8533 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 3.8101\n",
      "Boot_Epochs:\t 214 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.1710 - main_Bayes_output_state_loss: 2.1257 - main_Bayes_output_reward_loss: 132.7533 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 4.0184\n",
      "Boot_Epochs:\t 215 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2197 - main_Bayes_output_state_loss: 2.1668 - main_Bayes_output_reward_loss: 141.9861 - main_Bayes_output_state_categorical_accuracy: 0.2424 - main_Bayes_output_reward_mean_absolute_error: 4.1072\n",
      "Boot_Epochs:\t 216 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.1786 - main_Bayes_output_state_loss: 2.1109 - main_Bayes_output_reward_loss: 157.4747 - main_Bayes_output_state_categorical_accuracy: 0.3434 - main_Bayes_output_reward_mean_absolute_error: 4.1888\n",
      "Boot_Epochs:\t 217 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.3178 - main_Bayes_output_state_loss: 2.1382 - main_Bayes_output_reward_loss: 270.7378 - main_Bayes_output_state_categorical_accuracy: 0.3030 - main_Bayes_output_reward_mean_absolute_error: 5.0888\n",
      "Boot_Epochs:\t 218 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0699 - main_Bayes_output_state_loss: 2.0438 - main_Bayes_output_reward_loss: 117.8226 - main_Bayes_output_state_categorical_accuracy: 0.3232 - main_Bayes_output_reward_mean_absolute_error: 3.4800\n",
      "Boot_Epochs:\t 219 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0105 - main_Bayes_output_state_loss: 2.0592 - main_Bayes_output_reward_loss: 43.0798 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 2.7004\n",
      "Boot_Epochs:\t 220 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.2573 - main_Bayes_output_state_loss: 2.0919 - main_Bayes_output_reward_loss: 257.6989 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 4.8889\n",
      "Boot_Epochs:\t 221 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9886 - main_Bayes_output_state_loss: 2.0491 - main_Bayes_output_reward_loss: 31.9848 - main_Bayes_output_state_categorical_accuracy: 0.3131 - main_Bayes_output_reward_mean_absolute_error: 2.3978\n",
      "Boot_Epochs:\t 222 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0209 - main_Bayes_output_state_loss: 2.0532 - main_Bayes_output_reward_loss: 61.1496 - main_Bayes_output_state_categorical_accuracy: 0.3030 - main_Bayes_output_reward_mean_absolute_error: 2.6019\n",
      "Boot_Epochs:\t 223 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.1222 - main_Bayes_output_state_loss: 2.0800 - main_Bayes_output_reward_loss: 138.0541 - main_Bayes_output_state_categorical_accuracy: 0.3131 - main_Bayes_output_reward_mean_absolute_error: 3.7192\n",
      "Boot_Epochs:\t 224 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0143 - main_Bayes_output_state_loss: 2.0674 - main_Bayes_output_reward_loss: 43.1500 - main_Bayes_output_state_categorical_accuracy: 0.3030 - main_Bayes_output_reward_mean_absolute_error: 2.3653\n",
      "Boot_Epochs:\t 225 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9013 - main_Bayes_output_state_loss: 1.9617 - main_Bayes_output_reward_loss: 36.1625 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 2.2084\n",
      "Boot_Epochs:\t 226 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9607 - main_Bayes_output_state_loss: 1.9597 - main_Bayes_output_reward_loss: 97.6649 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 3.1794\n",
      "Boot_Epochs:\t 227 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.1409 - main_Bayes_output_state_loss: 2.0474 - main_Bayes_output_reward_loss: 193.8829 - main_Bayes_output_state_categorical_accuracy: 0.3434 - main_Bayes_output_reward_mean_absolute_error: 4.1463\n",
      "Boot_Epochs:\t 228 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0326 - main_Bayes_output_state_loss: 2.0597 - main_Bayes_output_reward_loss: 75.4750 - main_Bayes_output_state_categorical_accuracy: 0.3333 - main_Bayes_output_reward_mean_absolute_error: 2.8332\n",
      "Boot_Epochs:\t 229 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9869 - main_Bayes_output_state_loss: 1.9509 - main_Bayes_output_reward_loss: 141.7820 - main_Bayes_output_state_categorical_accuracy: 0.3333 - main_Bayes_output_reward_mean_absolute_error: 3.6766\n",
      "Boot_Epochs:\t 230 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0163 - main_Bayes_output_state_loss: 1.9720 - main_Bayes_output_reward_loss: 150.3058 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 3.9511\n",
      "Boot_Epochs:\t 231 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0007 - main_Bayes_output_state_loss: 2.0691 - main_Bayes_output_reward_loss: 40.6591 - main_Bayes_output_state_categorical_accuracy: 0.2828 - main_Bayes_output_reward_mean_absolute_error: 2.3648\n",
      "Boot_Epochs:\t 232 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0378 - main_Bayes_output_state_loss: 1.9896 - main_Bayes_output_reward_loss: 157.7722 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 3.5721\n",
      "Boot_Epochs:\t 233 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0126 - main_Bayes_output_state_loss: 1.9310 - main_Bayes_output_reward_loss: 191.0350 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 4.2586\n",
      "Boot_Epochs:\t 234 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0481 - main_Bayes_output_state_loss: 2.0373 - main_Bayes_output_reward_loss: 121.4300 - main_Bayes_output_state_categorical_accuracy: 0.3333 - main_Bayes_output_reward_mean_absolute_error: 3.0195\n",
      "Boot_Epochs:\t 235 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0931 - main_Bayes_output_state_loss: 2.0674 - main_Bayes_output_reward_loss: 137.6664 - main_Bayes_output_state_categorical_accuracy: 0.3131 - main_Bayes_output_reward_mean_absolute_error: 3.1532\n",
      "Boot_Epochs:\t 236 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9907 - main_Bayes_output_state_loss: 2.0233 - main_Bayes_output_reward_loss: 79.6474 - main_Bayes_output_state_categorical_accuracy: 0.3232 - main_Bayes_output_reward_mean_absolute_error: 2.7566\n",
      "Boot_Epochs:\t 237 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9599 - main_Bayes_output_state_loss: 1.9766 - main_Bayes_output_reward_loss: 97.9310 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 3.0279\n",
      "Boot_Epochs:\t 238 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0848 - main_Bayes_output_state_loss: 2.0077 - main_Bayes_output_reward_loss: 192.8230 - main_Bayes_output_state_categorical_accuracy: 0.2727 - main_Bayes_output_reward_mean_absolute_error: 3.6484\n",
      "Boot_Epochs:\t 239 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9378 - main_Bayes_output_state_loss: 1.9077 - main_Bayes_output_reward_loss: 145.1585 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 3.1685\n",
      "Boot_Epochs:\t 240 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9597 - main_Bayes_output_state_loss: 2.0023 - main_Bayes_output_reward_loss: 75.9680 - main_Bayes_output_state_categorical_accuracy: 0.3030 - main_Bayes_output_reward_mean_absolute_error: 2.6069\n",
      "Boot_Epochs:\t 241 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8611 - main_Bayes_output_state_loss: 1.9263 - main_Bayes_output_reward_loss: 54.6323 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 2.3698\n",
      "Boot_Epochs:\t 242 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9098 - main_Bayes_output_state_loss: 1.9797 - main_Bayes_output_reward_loss: 52.0792 - main_Bayes_output_state_categorical_accuracy: 0.3232 - main_Bayes_output_reward_mean_absolute_error: 2.0031\n",
      "Boot_Epochs:\t 243 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8947 - main_Bayes_output_state_loss: 1.9098 - main_Bayes_output_reward_loss: 106.8557 - main_Bayes_output_state_categorical_accuracy: 0.3232 - main_Bayes_output_reward_mean_absolute_error: 3.4801\n",
      "Boot_Epochs:\t 244 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8027 - main_Bayes_output_state_loss: 1.8910 - main_Bayes_output_reward_loss: 35.5821 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 2.3005\n",
      "Boot_Epochs:\t 245 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9115 - main_Bayes_output_state_loss: 1.9240 - main_Bayes_output_reward_loss: 113.8609 - main_Bayes_output_state_categorical_accuracy: 0.3131 - main_Bayes_output_reward_mean_absolute_error: 2.9716\n",
      "Boot_Epochs:\t 246 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8590 - main_Bayes_output_state_loss: 1.9034 - main_Bayes_output_reward_loss: 79.9935 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 2.5556\n",
      "Boot_Epochs:\t 247 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9488 - main_Bayes_output_state_loss: 1.9275 - main_Bayes_output_reward_loss: 146.9199 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 3.4318\n",
      "Boot_Epochs:\t 248 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.0278 - main_Bayes_output_state_loss: 1.9557 - main_Bayes_output_reward_loss: 199.0466 - main_Bayes_output_state_categorical_accuracy: 0.2929 - main_Bayes_output_reward_mean_absolute_error: 4.1699\n",
      "Boot_Epochs:\t 249 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7841 - main_Bayes_output_state_loss: 1.8586 - main_Bayes_output_reward_loss: 53.4546 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 2.0749\n",
      "Boot_Epochs:\t 250 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7683 - main_Bayes_output_state_loss: 1.8600 - main_Bayes_output_reward_loss: 34.6672 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 1.9991\n",
      "Boot_Epochs:\t 251 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9216 - main_Bayes_output_state_loss: 1.9764 - main_Bayes_output_reward_loss: 73.7741 - main_Bayes_output_state_categorical_accuracy: 0.3333 - main_Bayes_output_reward_mean_absolute_error: 2.4406\n",
      "Boot_Epochs:\t 252 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8624 - main_Bayes_output_state_loss: 1.9445 - main_Bayes_output_reward_loss: 49.3358 - main_Bayes_output_state_categorical_accuracy: 0.3434 - main_Bayes_output_reward_mean_absolute_error: 1.7712\n",
      "Boot_Epochs:\t 253 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8577 - main_Bayes_output_state_loss: 1.9302 - main_Bayes_output_reward_loss: 59.1610 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 2.0687\n",
      "Boot_Epochs:\t 254 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8080 - main_Bayes_output_state_loss: 1.8749 - main_Bayes_output_reward_loss: 66.6269 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 2.5795\n",
      "Boot_Epochs:\t 255 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9758 - main_Bayes_output_state_loss: 1.9358 - main_Bayes_output_reward_loss: 174.5785 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 3.8118\n",
      "Boot_Epochs:\t 256 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7726 - main_Bayes_output_state_loss: 1.8684 - main_Bayes_output_reward_loss: 37.5049 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 1.7664\n",
      "Boot_Epochs:\t 257 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7821 - main_Bayes_output_state_loss: 1.8894 - main_Bayes_output_reward_loss: 27.7660 - main_Bayes_output_state_categorical_accuracy: 0.3434 - main_Bayes_output_reward_mean_absolute_error: 1.5347\n",
      "Boot_Epochs:\t 258 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7418 - main_Bayes_output_state_loss: 1.8537 - main_Bayes_output_reward_loss: 21.6916 - main_Bayes_output_state_categorical_accuracy: 0.3232 - main_Bayes_output_reward_mean_absolute_error: 1.6862\n",
      "Boot_Epochs:\t 259 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8224 - main_Bayes_output_state_loss: 1.9268 - main_Bayes_output_reward_loss: 29.2698 - main_Bayes_output_state_categorical_accuracy: 0.3333 - main_Bayes_output_reward_mean_absolute_error: 1.5202\n",
      "Boot_Epochs:\t 260 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.9342 - main_Bayes_output_state_loss: 1.9287 - main_Bayes_output_reward_loss: 138.6343 - main_Bayes_output_state_categorical_accuracy: 0.3131 - main_Bayes_output_reward_mean_absolute_error: 2.6845\n",
      "Boot_Epochs:\t 261 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7179 - main_Bayes_output_state_loss: 1.8292 - main_Bayes_output_reward_loss: 22.7763 - main_Bayes_output_state_categorical_accuracy: 0.3636 - main_Bayes_output_reward_mean_absolute_error: 1.3190\n",
      "Boot_Epochs:\t 262 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7760 - main_Bayes_output_state_loss: 1.8539 - main_Bayes_output_reward_loss: 57.4553 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 1.8252\n",
      "Boot_Epochs:\t 263 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6752 - main_Bayes_output_state_loss: 1.7536 - main_Bayes_output_reward_loss: 55.7627 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.8499\n",
      "Boot_Epochs:\t 264 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7309 - main_Bayes_output_state_loss: 1.8403 - main_Bayes_output_reward_loss: 25.8368 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 1.3483\n",
      "Boot_Epochs:\t 265 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7459 - main_Bayes_output_state_loss: 1.8652 - main_Bayes_output_reward_loss: 15.3664 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 1.3917\n",
      "Boot_Epochs:\t 266 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7221 - main_Bayes_output_state_loss: 1.8369 - main_Bayes_output_reward_loss: 21.2042 - main_Bayes_output_state_categorical_accuracy: 0.3434 - main_Bayes_output_reward_mean_absolute_error: 1.4308\n",
      "Boot_Epochs:\t 267 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8229 - main_Bayes_output_state_loss: 1.8339 - main_Bayes_output_reward_loss: 124.6558 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 3.0285\n",
      "Boot_Epochs:\t 268 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7003 - main_Bayes_output_state_loss: 1.8214 - main_Bayes_output_reward_loss: 14.2736 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 1.2605\n",
      "Boot_Epochs:\t 269 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6934 - main_Bayes_output_state_loss: 1.7699 - main_Bayes_output_reward_loss: 58.7218 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.9276\n",
      "Boot_Epochs:\t 270 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8860 - main_Bayes_output_state_loss: 1.8620 - main_Bayes_output_reward_loss: 159.8322 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 2.8226\n",
      "Boot_Epochs:\t 271 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7885 - main_Bayes_output_state_loss: 1.8758 - main_Bayes_output_reward_loss: 48.9655 - main_Bayes_output_state_categorical_accuracy: 0.3636 - main_Bayes_output_reward_mean_absolute_error: 1.6082\n",
      "Boot_Epochs:\t 272 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6979 - main_Bayes_output_state_loss: 1.8012 - main_Bayes_output_reward_loss: 31.4575 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 1.6603 \n",
      "Boot_Epochs:\t 273 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6256 - main_Bayes_output_state_loss: 1.7101 - main_Bayes_output_reward_loss: 51.3156 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.9840\n",
      "Boot_Epochs:\t 274 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7231 - main_Bayes_output_state_loss: 1.7882 - main_Bayes_output_reward_loss: 71.9761 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 2.2666\n",
      "Boot_Epochs:\t 275 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6942 - main_Bayes_output_state_loss: 1.7639 - main_Bayes_output_reward_loss: 67.0698 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 2.3396\n",
      "Boot_Epochs:\t 276 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7434 - main_Bayes_output_state_loss: 1.8246 - main_Bayes_output_reward_loss: 56.0547 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 1.8051\n",
      "Boot_Epochs:\t 277 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7455 - main_Bayes_output_state_loss: 1.7835 - main_Bayes_output_reward_loss: 98.4052 - main_Bayes_output_state_categorical_accuracy: 0.3333 - main_Bayes_output_reward_mean_absolute_error: 2.1964\n",
      "Boot_Epochs:\t 278 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8314 - main_Bayes_output_state_loss: 1.8550 - main_Bayes_output_reward_loss: 112.9329 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 2.9044\n",
      "Boot_Epochs:\t 279 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6908 - main_Bayes_output_state_loss: 1.8075 - main_Bayes_output_reward_loss: 20.3944 - main_Bayes_output_state_categorical_accuracy: 0.3636 - main_Bayes_output_reward_mean_absolute_error: 1.3748\n",
      "Boot_Epochs:\t 280 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7095 - main_Bayes_output_state_loss: 1.8069 - main_Bayes_output_reward_loss: 41.1850 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 1.4627\n",
      "Boot_Epochs:\t 281 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.8907 - main_Bayes_output_state_loss: 1.8764 - main_Bayes_output_reward_loss: 153.8941 - main_Bayes_output_state_categorical_accuracy: 0.2626 - main_Bayes_output_reward_mean_absolute_error: 3.2442\n",
      "Boot_Epochs:\t 282 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7854 - main_Bayes_output_state_loss: 1.7857 - main_Bayes_output_reward_loss: 140.5877 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 2.5712\n",
      "Boot_Epochs:\t 283 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7786 - main_Bayes_output_state_loss: 1.8748 - main_Bayes_output_reward_loss: 44.9996 - main_Bayes_output_state_categorical_accuracy: 0.3232 - main_Bayes_output_reward_mean_absolute_error: 1.8231\n",
      "Boot_Epochs:\t 284 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7724 - main_Bayes_output_state_loss: 1.8680 - main_Bayes_output_reward_loss: 46.0087 - main_Bayes_output_state_categorical_accuracy: 0.3333 - main_Bayes_output_reward_mean_absolute_error: 1.5635\n",
      "Boot_Epochs:\t 285 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5999 - main_Bayes_output_state_loss: 1.7397 - main_Bayes_output_reward_loss: 1.3245 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 0.8045\n",
      "Boot_Epochs:\t 286 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7348 - main_Bayes_output_state_loss: 1.7770 - main_Bayes_output_reward_loss: 98.3508 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 2.4030\n",
      "Boot_Epochs:\t 287 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7239 - main_Bayes_output_state_loss: 1.8018 - main_Bayes_output_reward_loss: 63.1763 - main_Bayes_output_state_categorical_accuracy: 0.3636 - main_Bayes_output_reward_mean_absolute_error: 1.9136\n",
      "Boot_Epochs:\t 288 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6166 - main_Bayes_output_state_loss: 1.7184 - main_Bayes_output_reward_loss: 40.4531 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.6970\n",
      "Boot_Epochs:\t 289 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5756 - main_Bayes_output_state_loss: 1.6925 - main_Bayes_output_reward_loss: 23.7374 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.6445\n",
      "Boot_Epochs:\t 290 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7698 - main_Bayes_output_state_loss: 1.8293 - main_Bayes_output_reward_loss: 81.5747 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 2.1008\n",
      "Boot_Epochs:\t 291 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6412 - main_Bayes_output_state_loss: 1.7666 - main_Bayes_output_reward_loss: 16.1662 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 1.3281\n",
      "Boot_Epochs:\t 292 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7346 - main_Bayes_output_state_loss: 1.7947 - main_Bayes_output_reward_loss: 80.8722 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 2.6144\n",
      "Boot_Epochs:\t 293 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6582 - main_Bayes_output_state_loss: 1.6721 - main_Bayes_output_reward_loss: 128.3349 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.3827\n",
      "Boot_Epochs:\t 294 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7471 - main_Bayes_output_state_loss: 1.7451 - main_Bayes_output_reward_loss: 139.4958 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 3.4282\n",
      "Boot_Epochs:\t 295 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5956 - main_Bayes_output_state_loss: 1.7256 - main_Bayes_output_reward_loss: 11.7613 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 1.3453\n",
      "Boot_Epochs:\t 296 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7827 - main_Bayes_output_state_loss: 1.7316 - main_Bayes_output_reward_loss: 190.8061 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 3.5472\n",
      "Boot_Epochs:\t 297 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7370 - main_Bayes_output_state_loss: 1.7991 - main_Bayes_output_reward_loss: 79.9085 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 2.3128\n",
      "Boot_Epochs:\t 298 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6898 - main_Bayes_output_state_loss: 1.7260 - main_Bayes_output_reward_loss: 105.7815 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 2.5846\n",
      "Boot_Epochs:\t 299 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7052 - main_Bayes_output_state_loss: 1.7805 - main_Bayes_output_reward_loss: 65.9585 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 2.1189\n",
      "Boot_Epochs:\t 300 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6943 - main_Bayes_output_state_loss: 1.7795 - main_Bayes_output_reward_loss: 55.2398 - main_Bayes_output_state_categorical_accuracy: 0.3636 - main_Bayes_output_reward_mean_absolute_error: 2.1805\n",
      "Boot_Epochs:\t 301 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5442 - main_Bayes_output_state_loss: 1.6384 - main_Bayes_output_reward_loss: 47.6161 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.6421\n",
      "Boot_Epochs:\t 302 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5845 - main_Bayes_output_state_loss: 1.7017 - main_Bayes_output_reward_loss: 23.1264 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 1.6004\n",
      "Boot_Epochs:\t 303 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6168 - main_Bayes_output_state_loss: 1.6631 - main_Bayes_output_reward_loss: 94.8437 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 2.5291\n",
      "Boot_Epochs:\t 304 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7934 - main_Bayes_output_state_loss: 1.7893 - main_Bayes_output_reward_loss: 146.5440 - main_Bayes_output_state_categorical_accuracy: 0.3636 - main_Bayes_output_reward_mean_absolute_error: 2.9804\n",
      "Boot_Epochs:\t 305 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6564 - main_Bayes_output_state_loss: 1.6884 - main_Bayes_output_reward_loss: 109.0335 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 2.8320\n",
      "Boot_Epochs:\t 306 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5933 - main_Bayes_output_state_loss: 1.7036 - main_Bayes_output_reward_loss: 32.4568 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 1.7173\n",
      "Boot_Epochs:\t 307 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5582 - main_Bayes_output_state_loss: 1.5989 - main_Bayes_output_reward_loss: 101.9680 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 2.4199\n",
      "Boot_Epochs:\t 308 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6268 - main_Bayes_output_state_loss: 1.7177 - main_Bayes_output_reward_loss: 52.4092 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.7408\n",
      "Boot_Epochs:\t 309 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6332 - main_Bayes_output_state_loss: 1.6777 - main_Bayes_output_reward_loss: 98.9367 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 2.4264\n",
      "Boot_Epochs:\t 310 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5651 - main_Bayes_output_state_loss: 1.6372 - main_Bayes_output_reward_loss: 72.8672 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.0448\n",
      "Boot_Epochs:\t 311 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5938 - main_Bayes_output_state_loss: 1.6900 - main_Bayes_output_reward_loss: 50.4483 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.7445\n",
      "Boot_Epochs:\t 312 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5197 - main_Bayes_output_state_loss: 1.6201 - main_Bayes_output_reward_loss: 47.6728 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.6626\n",
      "Boot_Epochs:\t 313 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5975 - main_Bayes_output_state_loss: 1.6945 - main_Bayes_output_reward_loss: 51.4585 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.5726\n",
      "Boot_Epochs:\t 314 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6017 - main_Bayes_output_state_loss: 1.6999 - main_Bayes_output_reward_loss: 53.3939 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.7288\n",
      "Boot_Epochs:\t 315 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7635 - main_Bayes_output_state_loss: 1.7286 - main_Bayes_output_reward_loss: 186.6829 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 3.3252\n",
      "Boot_Epochs:\t 316 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6233 - main_Bayes_output_state_loss: 1.7124 - main_Bayes_output_reward_loss: 62.6375 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 2.1057\n",
      "Boot_Epochs:\t 317 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5531 - main_Bayes_output_state_loss: 1.6393 - main_Bayes_output_reward_loss: 65.6904 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.9134\n",
      "Boot_Epochs:\t 318 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5775 - main_Bayes_output_state_loss: 1.6756 - main_Bayes_output_reward_loss: 52.1689 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.8960\n",
      "Boot_Epochs:\t 319 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5814 - main_Bayes_output_state_loss: 1.6905 - main_Bayes_output_reward_loss: 42.7911 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 1.8554\n",
      "Boot_Epochs:\t 320 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6418 - main_Bayes_output_state_loss: 1.7116 - main_Bayes_output_reward_loss: 82.7904 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 2.6701\n",
      "Boot_Epochs:\t 321 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5462 - main_Bayes_output_state_loss: 1.6708 - main_Bayes_output_reward_loss: 27.7918 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.6077\n",
      "Boot_Epochs:\t 322 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6478 - main_Bayes_output_state_loss: 1.7749 - main_Bayes_output_reward_loss: 25.6267 - main_Bayes_output_state_categorical_accuracy: 0.3333 - main_Bayes_output_reward_mean_absolute_error: 1.7614\n",
      "Boot_Epochs:\t 323 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5385 - main_Bayes_output_state_loss: 1.6387 - main_Bayes_output_reward_loss: 51.2691 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.6543\n",
      "Boot_Epochs:\t 324 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5443 - main_Bayes_output_state_loss: 1.6836 - main_Bayes_output_reward_loss: 14.7266 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 1.3638\n",
      "Boot_Epochs:\t 325 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5302 - main_Bayes_output_state_loss: 1.6420 - main_Bayes_output_reward_loss: 42.0205 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.9523\n",
      "Boot_Epochs:\t 326 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5799 - main_Bayes_output_state_loss: 1.6689 - main_Bayes_output_reward_loss: 66.1439 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 1.9920\n",
      "Boot_Epochs:\t 327 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6070 - main_Bayes_output_state_loss: 1.7582 - main_Bayes_output_reward_loss: 4.5484 - main_Bayes_output_state_categorical_accuracy: 0.3636 - main_Bayes_output_reward_mean_absolute_error: 1.0261\n",
      "Boot_Epochs:\t 328 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4790 - main_Bayes_output_state_loss: 1.5989 - main_Bayes_output_reward_loss: 36.9711 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.5001\n",
      "Boot_Epochs:\t 329 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5221 - main_Bayes_output_state_loss: 1.6592 - main_Bayes_output_reward_loss: 21.3080 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.4986\n",
      "Boot_Epochs:\t 330 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5766 - main_Bayes_output_state_loss: 1.6596 - main_Bayes_output_reward_loss: 77.3331 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.0034\n",
      "Boot_Epochs:\t 331 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5168 - main_Bayes_output_state_loss: 1.5922 - main_Bayes_output_reward_loss: 85.6741 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 2.2794\n",
      "Boot_Epochs:\t 332 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5442 - main_Bayes_output_state_loss: 1.6407 - main_Bayes_output_reward_loss: 64.6404 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.8631\n",
      "Boot_Epochs:\t 333 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4978 - main_Bayes_output_state_loss: 1.6576 - main_Bayes_output_reward_loss: 3.1966 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 0.9559\n",
      "Boot_Epochs:\t 334 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4166 - main_Bayes_output_state_loss: 1.5768 - main_Bayes_output_reward_loss: 3.0779 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 0.9891\n",
      "Boot_Epochs:\t 335 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.6535 - main_Bayes_output_state_loss: 1.7227 - main_Bayes_output_reward_loss: 95.5245 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 2.1206\n",
      "Boot_Epochs:\t 336 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4876 - main_Bayes_output_state_loss: 1.6061 - main_Bayes_output_reward_loss: 46.0254 - main_Bayes_output_state_categorical_accuracy: 0.3636 - main_Bayes_output_reward_mean_absolute_error: 1.4350\n",
      "Boot_Epochs:\t 337 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5657 - main_Bayes_output_state_loss: 1.6477 - main_Bayes_output_reward_loss: 83.3254 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 2.1550\n",
      "Boot_Epochs:\t 338 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4832 - main_Bayes_output_state_loss: 1.5946 - main_Bayes_output_reward_loss: 53.2683 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.7006\n",
      "Boot_Epochs:\t 339 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4798 - main_Bayes_output_state_loss: 1.6184 - main_Bayes_output_reward_loss: 25.7452 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.7323\n",
      "Boot_Epochs:\t 340 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5089 - main_Bayes_output_state_loss: 1.6055 - main_Bayes_output_reward_loss: 67.3607 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.0706\n",
      "Boot_Epochs:\t 341 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5408 - main_Bayes_output_state_loss: 1.6212 - main_Bayes_output_reward_loss: 85.3774 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 2.1295\n",
      "Boot_Epochs:\t 342 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4741 - main_Bayes_output_state_loss: 1.5917 - main_Bayes_output_reward_loss: 49.9624 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 1.5877\n",
      "Boot_Epochs:\t 343 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4413 - main_Bayes_output_state_loss: 1.6039 - main_Bayes_output_reward_loss: 5.5239 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 1.1453\n",
      "Boot_Epochs:\t 344 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4675 - main_Bayes_output_state_loss: 1.6001 - main_Bayes_output_reward_loss: 34.8711 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.4906\n",
      "Boot_Epochs:\t 345 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4188 - main_Bayes_output_state_loss: 1.5796 - main_Bayes_output_reward_loss: 7.4962 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.1059\n",
      "Boot_Epochs:\t 346 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4307 - main_Bayes_output_state_loss: 1.5840 - main_Bayes_output_reward_loss: 14.7753 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.1426\n",
      "Boot_Epochs:\t 347 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5095 - main_Bayes_output_state_loss: 1.5357 - main_Bayes_output_reward_loss: 143.5327 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 3.0830\n",
      "Boot_Epochs:\t 348 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.7103 - main_Bayes_output_state_loss: 1.7740 - main_Bayes_output_reward_loss: 106.8594 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 2.7908\n",
      "Boot_Epochs:\t 349 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4256 - main_Bayes_output_state_loss: 1.5517 - main_Bayes_output_reward_loss: 44.6431 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.8931\n",
      "Boot_Epochs:\t 350 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4913 - main_Bayes_output_state_loss: 1.6382 - main_Bayes_output_reward_loss: 22.8371 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.2627\n",
      "Boot_Epochs:\t 351 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4917 - main_Bayes_output_state_loss: 1.6108 - main_Bayes_output_reward_loss: 50.4611 - main_Bayes_output_state_categorical_accuracy: 0.3636 - main_Bayes_output_reward_mean_absolute_error: 1.5651\n",
      "Boot_Epochs:\t 352 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3895 - main_Bayes_output_state_loss: 1.5270 - main_Bayes_output_reward_loss: 33.7264 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.7117\n",
      "Boot_Epochs:\t 353 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3098 - main_Bayes_output_state_loss: 1.4680 - main_Bayes_output_reward_loss: 11.9118 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.1479\n",
      "Boot_Epochs:\t 354 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4535 - main_Bayes_output_state_loss: 1.6068 - main_Bayes_output_reward_loss: 17.5593 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 1.2011\n",
      "Boot_Epochs:\t 355 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5375 - main_Bayes_output_state_loss: 1.6756 - main_Bayes_output_reward_loss: 32.0956 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.5364\n",
      "Boot_Epochs:\t 356 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4963 - main_Bayes_output_state_loss: 1.6464 - main_Bayes_output_reward_loss: 21.1280 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.2988\n",
      "Boot_Epochs:\t 357 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3659 - main_Bayes_output_state_loss: 1.5267 - main_Bayes_output_reward_loss: 10.0041 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.2219\n",
      "Boot_Epochs:\t 358 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4709 - main_Bayes_output_state_loss: 1.6093 - main_Bayes_output_reward_loss: 31.6328 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.4652\n",
      "Boot_Epochs:\t 359 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3583 - main_Bayes_output_state_loss: 1.5202 - main_Bayes_output_reward_loss: 9.2379 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.2541\n",
      "Boot_Epochs:\t 360 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4466 - main_Bayes_output_state_loss: 1.5657 - main_Bayes_output_reward_loss: 52.1737 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.9613\n",
      "Boot_Epochs:\t 361 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4461 - main_Bayes_output_state_loss: 1.5169 - main_Bayes_output_reward_loss: 100.2548 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 2.5204\n",
      "Boot_Epochs:\t 362 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5991 - main_Bayes_output_state_loss: 1.6505 - main_Bayes_output_reward_loss: 120.4772 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 2.6845\n",
      "Boot_Epochs:\t 363 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4952 - main_Bayes_output_state_loss: 1.5624 - main_Bayes_output_reward_loss: 104.5508 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.4669\n",
      "Boot_Epochs:\t 364 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5087 - main_Bayes_output_state_loss: 1.6091 - main_Bayes_output_reward_loss: 72.0420 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 2.1798\n",
      "Boot_Epochs:\t 365 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5030 - main_Bayes_output_state_loss: 1.6278 - main_Bayes_output_reward_loss: 47.5934 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.4589\n",
      "Boot_Epochs:\t 366 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4267 - main_Bayes_output_state_loss: 1.5730 - main_Bayes_output_reward_loss: 28.3642 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.4052\n",
      "Boot_Epochs:\t 367 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4354 - main_Bayes_output_state_loss: 1.5647 - main_Bayes_output_reward_loss: 44.8315 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.5819\n",
      "Boot_Epochs:\t 368 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4852 - main_Bayes_output_state_loss: 1.5971 - main_Bayes_output_reward_loss: 61.5787 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.0323\n",
      "Boot_Epochs:\t 369 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2925 - main_Bayes_output_state_loss: 1.4523 - main_Bayes_output_reward_loss: 15.3859 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.3419\n",
      "Boot_Epochs:\t 370 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3515 - main_Bayes_output_state_loss: 1.4956 - main_Bayes_output_reward_loss: 32.9376 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.4754\n",
      "Boot_Epochs:\t 371 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5995 - main_Bayes_output_state_loss: 1.6262 - main_Bayes_output_reward_loss: 150.7482 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 2.6798\n",
      "Boot_Epochs:\t 372 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5458 - main_Bayes_output_state_loss: 1.6098 - main_Bayes_output_reward_loss: 113.9821 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 2.3374\n",
      "Boot_Epochs:\t 373 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4016 - main_Bayes_output_state_loss: 1.5014 - main_Bayes_output_reward_loss: 81.0692 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.9982\n",
      "Boot_Epochs:\t 374 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3584 - main_Bayes_output_state_loss: 1.5153 - main_Bayes_output_reward_loss: 24.6550 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.4561\n",
      "Boot_Epochs:\t 375 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4659 - main_Bayes_output_state_loss: 1.5632 - main_Bayes_output_reward_loss: 85.7851 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.0607\n",
      "Boot_Epochs:\t 376 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3237 - main_Bayes_output_state_loss: 1.5023 - main_Bayes_output_reward_loss: 4.0158 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.0406\n",
      "Boot_Epochs:\t 377 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3764 - main_Bayes_output_state_loss: 1.5052 - main_Bayes_output_reward_loss: 53.9636 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.9107\n",
      "Boot_Epochs:\t 378 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4482 - main_Bayes_output_state_loss: 1.5998 - main_Bayes_output_reward_loss: 30.4521 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.4656\n",
      "Boot_Epochs:\t 379 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4521 - main_Bayes_output_state_loss: 1.4922 - main_Bayes_output_reward_loss: 143.1402 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.6795\n",
      "Boot_Epochs:\t 380 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4844 - main_Bayes_output_state_loss: 1.6118 - main_Bayes_output_reward_loss: 55.5366 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.7387\n",
      "Boot_Epochs:\t 381 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4599 - main_Bayes_output_state_loss: 1.5576 - main_Bayes_output_reward_loss: 86.0870 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.4378\n",
      "Boot_Epochs:\t 382 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4866 - main_Bayes_output_state_loss: 1.6187 - main_Bayes_output_reward_loss: 49.9501 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.7518\n",
      "Boot_Epochs:\t 383 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2751 - main_Bayes_output_state_loss: 1.4110 - main_Bayes_output_reward_loss: 47.4165 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.4882\n",
      "Boot_Epochs:\t 384 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4303 - main_Bayes_output_state_loss: 1.5601 - main_Bayes_output_reward_loss: 53.9743 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.6896\n",
      "Boot_Epochs:\t 385 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4409 - main_Bayes_output_state_loss: 1.6216 - main_Bayes_output_reward_loss: 4.1206 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.0591\n",
      "Boot_Epochs:\t 386 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3574 - main_Bayes_output_state_loss: 1.4781 - main_Bayes_output_reward_loss: 64.4381 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.1923\n",
      "Boot_Epochs:\t 387 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4146 - main_Bayes_output_state_loss: 1.5933 - main_Bayes_output_reward_loss: 7.7512 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.1700\n",
      "Boot_Epochs:\t 388 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3885 - main_Bayes_output_state_loss: 1.4867 - main_Bayes_output_reward_loss: 87.7079 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.2894\n",
      "Boot_Epochs:\t 389 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4525 - main_Bayes_output_state_loss: 1.5278 - main_Bayes_output_reward_loss: 110.9324 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 2.0743\n",
      "Boot_Epochs:\t 390 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3962 - main_Bayes_output_state_loss: 1.5234 - main_Bayes_output_reward_loss: 60.0470 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.7443\n",
      "Boot_Epochs:\t 391 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3471 - main_Bayes_output_state_loss: 1.4589 - main_Bayes_output_reward_loss: 75.6178 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 2.0657\n",
      "Boot_Epochs:\t 392 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3452 - main_Bayes_output_state_loss: 1.4866 - main_Bayes_output_reward_loss: 45.2580 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.6529\n",
      "Boot_Epochs:\t 393 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3764 - main_Bayes_output_state_loss: 1.5463 - main_Bayes_output_reward_loss: 16.2002 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.3142\n",
      "Boot_Epochs:\t 394 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5023 - main_Bayes_output_state_loss: 1.5864 - main_Bayes_output_reward_loss: 103.2553 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 2.5419\n",
      "Boot_Epochs:\t 395 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4053 - main_Bayes_output_state_loss: 1.5441 - main_Bayes_output_reward_loss: 48.9142 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.6490\n",
      "Boot_Epochs:\t 396 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4309 - main_Bayes_output_state_loss: 1.5808 - main_Bayes_output_reward_loss: 37.1812 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.3333\n",
      "Boot_Epochs:\t 397 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3954 - main_Bayes_output_state_loss: 1.5290 - main_Bayes_output_reward_loss: 53.1823 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.0669\n",
      "Boot_Epochs:\t 398 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4667 - main_Bayes_output_state_loss: 1.5754 - main_Bayes_output_reward_loss: 78.4398 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 2.3602\n",
      "Boot_Epochs:\t 399 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4314 - main_Bayes_output_state_loss: 1.5616 - main_Bayes_output_reward_loss: 57.8282 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.9806\n",
      "Boot_Epochs:\t 400 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4485 - main_Bayes_output_state_loss: 1.5975 - main_Bayes_output_reward_loss: 38.7274 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 1.4777\n",
      "Boot_Epochs:\t 401 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5198 - main_Bayes_output_state_loss: 1.5182 - main_Bayes_output_reward_loss: 188.9471 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 3.7052\n",
      "Boot_Epochs:\t 402 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3218 - main_Bayes_output_state_loss: 1.4992 - main_Bayes_output_reward_loss: 10.0954 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.2383\n",
      "Boot_Epochs:\t 403 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5134 - main_Bayes_output_state_loss: 1.4841 - main_Bayes_output_reward_loss: 216.8958 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 3.7586\n",
      "Boot_Epochs:\t 404 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4388 - main_Bayes_output_state_loss: 1.5649 - main_Bayes_output_reward_loss: 62.3151 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.1460\n",
      "Boot_Epochs:\t 405 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4216 - main_Bayes_output_state_loss: 1.5274 - main_Bayes_output_reward_loss: 82.4732 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.0784\n",
      "Boot_Epochs:\t 406 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3124 - main_Bayes_output_state_loss: 1.4853 - main_Bayes_output_reward_loss: 15.4485 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.4524\n",
      "Boot_Epochs:\t 407 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3405 - main_Bayes_output_state_loss: 1.4841 - main_Bayes_output_reward_loss: 44.7271 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.4141\n",
      "Boot_Epochs:\t 408 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3879 - main_Bayes_output_state_loss: 1.5557 - main_Bayes_output_reward_loss: 20.1019 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 1.3914\n",
      "Boot_Epochs:\t 409 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3586 - main_Bayes_output_state_loss: 1.5386 - main_Bayes_output_reward_loss: 7.7329 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.0417\n",
      "Boot_Epochs:\t 410 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3528 - main_Bayes_output_state_loss: 1.4777 - main_Bayes_output_reward_loss: 63.6718 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 2.1739\n",
      "Boot_Epochs:\t 411 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3839 - main_Bayes_output_state_loss: 1.5325 - main_Bayes_output_reward_loss: 41.0063 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 1.5439\n",
      "Boot_Epochs:\t 412 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4306 - main_Bayes_output_state_loss: 1.5583 - main_Bayes_output_reward_loss: 62.5638 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 2.3984\n",
      "Boot_Epochs:\t 413 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4491 - main_Bayes_output_state_loss: 1.5370 - main_Bayes_output_reward_loss: 101.9332 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 2.3389\n",
      "Boot_Epochs:\t 414 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3380 - main_Bayes_output_state_loss: 1.4802 - main_Bayes_output_reward_loss: 47.8054 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.5809\n",
      "Boot_Epochs:\t 415 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3831 - main_Bayes_output_state_loss: 1.5146 - main_Bayes_output_reward_loss: 57.7729 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.0048\n",
      "Boot_Epochs:\t 416 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4354 - main_Bayes_output_state_loss: 1.5208 - main_Bayes_output_reward_loss: 104.9101 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 2.5282\n",
      "Boot_Epochs:\t 417 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2616 - main_Bayes_output_state_loss: 1.4273 - main_Bayes_output_reward_loss: 23.1391 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.4561\n",
      "Boot_Epochs:\t 418 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3036 - main_Bayes_output_state_loss: 1.4545 - main_Bayes_output_reward_loss: 39.7433 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.5108\n",
      "Boot_Epochs:\t 419 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3051 - main_Bayes_output_state_loss: 1.4602 - main_Bayes_output_reward_loss: 35.6364 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.8041\n",
      "Boot_Epochs:\t 420 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3833 - main_Bayes_output_state_loss: 1.5565 - main_Bayes_output_reward_loss: 17.2492 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.5592\n",
      "Boot_Epochs:\t 421 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3181 - main_Bayes_output_state_loss: 1.4911 - main_Bayes_output_reward_loss: 18.2554 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.2974\n",
      "Boot_Epochs:\t 422 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2195 - main_Bayes_output_state_loss: 1.3927 - main_Bayes_output_reward_loss: 16.1177 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.3480\n",
      "Boot_Epochs:\t 423 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3042 - main_Bayes_output_state_loss: 1.4739 - main_Bayes_output_reward_loss: 20.8560 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.3118\n",
      "Boot_Epochs:\t 424 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2559 - main_Bayes_output_state_loss: 1.4403 - main_Bayes_output_reward_loss: 6.2051 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.2172\n",
      "Boot_Epochs:\t 425 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3341 - main_Bayes_output_state_loss: 1.4691 - main_Bayes_output_reward_loss: 54.1644 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.4759\n",
      "Boot_Epochs:\t 426 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3060 - main_Bayes_output_state_loss: 1.4372 - main_Bayes_output_reward_loss: 60.0181 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 2.1653\n",
      "Boot_Epochs:\t 427 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3203 - main_Bayes_output_state_loss: 1.4727 - main_Bayes_output_reward_loss: 38.4686 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.7675\n",
      "Boot_Epochs:\t 428 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2762 - main_Bayes_output_state_loss: 1.4645 - main_Bayes_output_reward_loss: 2.1054 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.8730\n",
      "Boot_Epochs:\t 429 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2723 - main_Bayes_output_state_loss: 1.4249 - main_Bayes_output_reward_loss: 36.9508 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 2.0538\n",
      "Boot_Epochs:\t 430 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1960 - main_Bayes_output_state_loss: 1.3791 - main_Bayes_output_reward_loss: 6.3325 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.2618\n",
      "Boot_Epochs:\t 431 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1961 - main_Bayes_output_state_loss: 1.3315 - main_Bayes_output_reward_loss: 54.7078 - main_Bayes_output_state_categorical_accuracy: 0.5556 - main_Bayes_output_reward_mean_absolute_error: 1.9196\n",
      "Boot_Epochs:\t 432 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1966 - main_Bayes_output_state_loss: 1.3817 - main_Bayes_output_reward_loss: 4.6554 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.1159\n",
      "Boot_Epochs:\t 433 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3398 - main_Bayes_output_state_loss: 1.4826 - main_Bayes_output_reward_loss: 47.1589 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.8656\n",
      "Boot_Epochs:\t 434 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3175 - main_Bayes_output_state_loss: 1.4173 - main_Bayes_output_reward_loss: 90.8766 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.4014\n",
      "Boot_Epochs:\t 435 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3327 - main_Bayes_output_state_loss: 1.3877 - main_Bayes_output_reward_loss: 135.7709 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.3484\n",
      "Boot_Epochs:\t 436 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3594 - main_Bayes_output_state_loss: 1.5320 - main_Bayes_output_reward_loss: 17.5326 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.3515\n",
      "Boot_Epochs:\t 437 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2523 - main_Bayes_output_state_loss: 1.4078 - main_Bayes_output_reward_loss: 34.8097 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.5383\n",
      "Boot_Epochs:\t 438 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1818 - main_Bayes_output_state_loss: 1.3452 - main_Bayes_output_reward_loss: 27.1128 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.2861\n",
      "Boot_Epochs:\t 439 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2780 - main_Bayes_output_state_loss: 1.4156 - main_Bayes_output_reward_loss: 52.5744 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.6770\n",
      "Boot_Epochs:\t 440 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2939 - main_Bayes_output_state_loss: 1.4183 - main_Bayes_output_reward_loss: 66.3111 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.2855\n",
      "Boot_Epochs:\t 441 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2832 - main_Bayes_output_state_loss: 1.4692 - main_Bayes_output_reward_loss: 4.8603 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.1114\n",
      "Boot_Epochs:\t 442 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2465 - main_Bayes_output_state_loss: 1.3753 - main_Bayes_output_reward_loss: 62.3111 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.8805\n",
      "Boot_Epochs:\t 443 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2172 - main_Bayes_output_state_loss: 1.3568 - main_Bayes_output_reward_loss: 53.9548 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.7973\n",
      "Boot_Epochs:\t 444 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2403 - main_Bayes_output_state_loss: 1.4230 - main_Bayes_output_reward_loss: 11.2799 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.3547\n",
      "Boot_Epochs:\t 445 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3059 - main_Bayes_output_state_loss: 1.4542 - main_Bayes_output_reward_loss: 46.0691 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.4250\n",
      "Boot_Epochs:\t 446 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3508 - main_Bayes_output_state_loss: 1.5240 - main_Bayes_output_reward_loss: 22.1766 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.7148\n",
      "Boot_Epochs:\t 447 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4350 - main_Bayes_output_state_loss: 1.5655 - main_Bayes_output_reward_loss: 64.7964 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 2.0570\n",
      "Boot_Epochs:\t 448 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3824 - main_Bayes_output_state_loss: 1.4910 - main_Bayes_output_reward_loss: 85.8243 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 2.3623\n",
      "Boot_Epochs:\t 449 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1967 - main_Bayes_output_state_loss: 1.3598 - main_Bayes_output_reward_loss: 32.7391 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.4613\n",
      "Boot_Epochs:\t 450 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3645 - main_Bayes_output_state_loss: 1.5076 - main_Bayes_output_reward_loss: 54.0305 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 2.0764\n",
      "Boot_Epochs:\t 451 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2749 - main_Bayes_output_state_loss: 1.4646 - main_Bayes_output_reward_loss: 8.3260 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.2186\n",
      "Boot_Epochs:\t 452 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3070 - main_Bayes_output_state_loss: 1.4925 - main_Bayes_output_reward_loss: 12.6540 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.1468\n",
      "Boot_Epochs:\t 453 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2169 - main_Bayes_output_state_loss: 1.3997 - main_Bayes_output_reward_loss: 17.1655 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.1990\n",
      "Boot_Epochs:\t 454 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3479 - main_Bayes_output_state_loss: 1.4545 - main_Bayes_output_reward_loss: 92.9693 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 2.4224\n",
      "Boot_Epochs:\t 455 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3069 - main_Bayes_output_state_loss: 1.4644 - main_Bayes_output_reward_loss: 44.1401 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.5020\n",
      "Boot_Epochs:\t 456 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2712 - main_Bayes_output_state_loss: 1.4129 - main_Bayes_output_reward_loss: 60.4657 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.8579\n",
      "Boot_Epochs:\t 457 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1959 - main_Bayes_output_state_loss: 1.3890 - main_Bayes_output_reward_loss: 10.6618 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.4183\n",
      "Boot_Epochs:\t 458 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3386 - main_Bayes_output_state_loss: 1.4875 - main_Bayes_output_reward_loss: 55.0872 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.8219\n",
      "Boot_Epochs:\t 459 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2637 - main_Bayes_output_state_loss: 1.4591 - main_Bayes_output_reward_loss: 8.0858 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.1375\n",
      "Boot_Epochs:\t 460 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3272 - main_Bayes_output_state_loss: 1.5006 - main_Bayes_output_reward_loss: 28.9584 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.3740\n",
      "Boot_Epochs:\t 461 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2333 - main_Bayes_output_state_loss: 1.4315 - main_Bayes_output_reward_loss: 8.3115 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.0248\n",
      "Boot_Epochs:\t 462 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2312 - main_Bayes_output_state_loss: 1.3656 - main_Bayes_output_reward_loss: 71.6664 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.5150\n",
      "Boot_Epochs:\t 463 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1833 - main_Bayes_output_state_loss: 1.3423 - main_Bayes_output_reward_loss: 45.4212 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.5157\n",
      "Boot_Epochs:\t 464 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2752 - main_Bayes_output_state_loss: 1.3551 - main_Bayes_output_reward_loss: 125.5596 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 2.6882\n",
      "Boot_Epochs:\t 465 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2626 - main_Bayes_output_state_loss: 1.4417 - main_Bayes_output_reward_loss: 27.8876 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.2523\n",
      "Boot_Epochs:\t 466 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1741 - main_Bayes_output_state_loss: 1.3790 - main_Bayes_output_reward_loss: 1.2271 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 0.7994\n",
      "Boot_Epochs:\t 467 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2135 - main_Bayes_output_state_loss: 1.3811 - main_Bayes_output_reward_loss: 39.7601 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.4697\n",
      "Boot_Epochs:\t 468 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2361 - main_Bayes_output_state_loss: 1.3591 - main_Bayes_output_reward_loss: 85.1241 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 2.4049\n",
      "Boot_Epochs:\t 469 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1695 - main_Bayes_output_state_loss: 1.3359 - main_Bayes_output_reward_loss: 41.9216 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.4080\n",
      "Boot_Epochs:\t 470 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2727 - main_Bayes_output_state_loss: 1.4203 - main_Bayes_output_reward_loss: 61.2801 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.0540\n",
      "Boot_Epochs:\t 471 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2735 - main_Bayes_output_state_loss: 1.4681 - main_Bayes_output_reward_loss: 14.1607 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.5279\n",
      "Boot_Epochs:\t 472 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1643 - main_Bayes_output_state_loss: 1.3249 - main_Bayes_output_reward_loss: 45.5510 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 2.0056\n",
      "Boot_Epochs:\t 473 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1653 - main_Bayes_output_state_loss: 1.3657 - main_Bayes_output_reward_loss: 8.8698 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.3161\n",
      "Boot_Epochs:\t 474 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2286 - main_Bayes_output_state_loss: 1.4368 - main_Bayes_output_reward_loss: 1.4107 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.8503\n",
      "Boot_Epochs:\t 475 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3369 - main_Bayes_output_state_loss: 1.4412 - main_Bayes_output_reward_loss: 106.6991 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.5353\n",
      "Boot_Epochs:\t 476 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1771 - main_Bayes_output_state_loss: 1.3420 - main_Bayes_output_reward_loss: 45.7104 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.6257\n",
      "Boot_Epochs:\t 477 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1564 - main_Bayes_output_state_loss: 1.3339 - main_Bayes_output_reward_loss: 33.8565 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.4937\n",
      "Boot_Epochs:\t 478 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2192 - main_Bayes_output_state_loss: 1.4256 - main_Bayes_output_reward_loss: 5.0833 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.0682\n",
      "Boot_Epochs:\t 479 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2241 - main_Bayes_output_state_loss: 1.3929 - main_Bayes_output_reward_loss: 44.7635 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.4254\n",
      "Boot_Epochs:\t 480 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3047 - main_Bayes_output_state_loss: 1.4396 - main_Bayes_output_reward_loss: 78.8462 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.0630\n",
      "Boot_Epochs:\t 481 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3926 - main_Bayes_output_state_loss: 1.5380 - main_Bayes_output_reward_loss: 69.2459 - main_Bayes_output_state_categorical_accuracy: 0.3535 - main_Bayes_output_reward_mean_absolute_error: 1.9899\n",
      "Boot_Epochs:\t 482 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2313 - main_Bayes_output_state_loss: 1.3964 - main_Bayes_output_reward_loss: 49.4679 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.5951\n",
      "Boot_Epochs:\t 483 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2359 - main_Bayes_output_state_loss: 1.3787 - main_Bayes_output_reward_loss: 72.0289 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.0468\n",
      "Boot_Epochs:\t 484 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1930 - main_Bayes_output_state_loss: 1.3437 - main_Bayes_output_reward_loss: 64.6783 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.2396\n",
      "Boot_Epochs:\t 485 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2263 - main_Bayes_output_state_loss: 1.4426 - main_Bayes_output_reward_loss: 1.4078 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 0.8826\n",
      "Boot_Epochs:\t 486 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2356 - main_Bayes_output_state_loss: 1.3828 - main_Bayes_output_reward_loss: 69.7858 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.6874\n",
      "Boot_Epochs:\t 487 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2576 - main_Bayes_output_state_loss: 1.3838 - main_Bayes_output_reward_loss: 91.6164 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 2.5415\n",
      "Boot_Epochs:\t 488 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2759 - main_Bayes_output_state_loss: 1.4589 - main_Bayes_output_reward_loss: 33.6136 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.3927\n",
      "Boot_Epochs:\t 489 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2629 - main_Bayes_output_state_loss: 1.4259 - main_Bayes_output_reward_loss: 55.9674 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 2.0536\n",
      "Boot_Epochs:\t 490 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1309 - main_Bayes_output_state_loss: 1.3275 - main_Bayes_output_reward_loss: 21.0140 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.6624\n",
      "Boot_Epochs:\t 491 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1693 - main_Bayes_output_state_loss: 1.3824 - main_Bayes_output_reward_loss: 3.2632 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 0.9646\n",
      "Boot_Epochs:\t 492 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1979 - main_Bayes_output_state_loss: 1.3819 - main_Bayes_output_reward_loss: 35.3385 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.5396\n",
      "Boot_Epochs:\t 493 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3433 - main_Bayes_output_state_loss: 1.4824 - main_Bayes_output_reward_loss: 81.5520 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.9764\n",
      "Boot_Epochs:\t 494 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2301 - main_Bayes_output_state_loss: 1.3709 - main_Bayes_output_reward_loss: 78.9205 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.1643\n",
      "Boot_Epochs:\t 495 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2446 - main_Bayes_output_state_loss: 1.3906 - main_Bayes_output_reward_loss: 72.9240 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.2637\n",
      "Boot_Epochs:\t 496 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2231 - main_Bayes_output_state_loss: 1.3815 - main_Bayes_output_reward_loss: 61.6482 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.9023\n",
      "Boot_Epochs:\t 497 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2033 - main_Bayes_output_state_loss: 1.3752 - main_Bayes_output_reward_loss: 50.0978 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.7938\n",
      "Boot_Epochs:\t 498 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2543 - main_Bayes_output_state_loss: 1.4250 - main_Bayes_output_reward_loss: 52.0664 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.7597\n",
      "Boot_Epochs:\t 499 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1543 - main_Bayes_output_state_loss: 1.3378 - main_Bayes_output_reward_loss: 40.9090 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.5012\n",
      "Boot_Epochs:\t 500 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1807 - main_Bayes_output_state_loss: 1.3533 - main_Bayes_output_reward_loss: 51.5563 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.7753\n",
      "Boot_Epochs:\t 501 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1668 - main_Bayes_output_state_loss: 1.3733 - main_Bayes_output_reward_loss: 16.6102 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.3977\n",
      "Boot_Epochs:\t 502 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3037 - main_Bayes_output_state_loss: 1.4382 - main_Bayes_output_reward_loss: 91.9022 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.1671\n",
      "Boot_Epochs:\t 503 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2984 - main_Bayes_output_state_loss: 1.4683 - main_Bayes_output_reward_loss: 55.9937 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.0790\n",
      "Boot_Epochs:\t 504 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2096 - main_Bayes_output_state_loss: 1.3868 - main_Bayes_output_reward_loss: 43.9485 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.6267\n",
      "Boot_Epochs:\t 505 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2553 - main_Bayes_output_state_loss: 1.4531 - main_Bayes_output_reward_loss: 28.7102 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.5273\n",
      "Boot_Epochs:\t 506 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1705 - main_Bayes_output_state_loss: 1.3339 - main_Bayes_output_reward_loss: 61.1849 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 2.0876\n",
      "Boot_Epochs:\t 507 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2375 - main_Bayes_output_state_loss: 1.4373 - main_Bayes_output_reward_loss: 26.5323 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.4882\n",
      "Boot_Epochs:\t 508 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1831 - main_Bayes_output_state_loss: 1.3671 - main_Bayes_output_reward_loss: 42.6616 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.7423\n",
      "Boot_Epochs:\t 509 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1795 - main_Bayes_output_state_loss: 1.3898 - main_Bayes_output_reward_loss: 16.9764 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.2318\n",
      "Boot_Epochs:\t 510 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1510 - main_Bayes_output_state_loss: 1.3025 - main_Bayes_output_reward_loss: 74.9751 - main_Bayes_output_state_categorical_accuracy: 0.5556 - main_Bayes_output_reward_mean_absolute_error: 2.2232\n",
      "Boot_Epochs:\t 511 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2597 - main_Bayes_output_state_loss: 1.4551 - main_Bayes_output_reward_loss: 32.5759 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 1.3584\n",
      "Boot_Epochs:\t 512 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1903 - main_Bayes_output_state_loss: 1.3932 - main_Bayes_output_reward_loss: 24.4895 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.5623\n",
      "Boot_Epochs:\t 513 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1776 - main_Bayes_output_state_loss: 1.3669 - main_Bayes_output_reward_loss: 37.9076 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.6231\n",
      "Boot_Epochs:\t 514 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2642 - main_Bayes_output_state_loss: 1.3732 - main_Bayes_output_reward_loss: 118.9435 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.3049\n",
      "Boot_Epochs:\t 515 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2955 - main_Bayes_output_state_loss: 1.5026 - main_Bayes_output_reward_loss: 19.8106 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 1.3771\n",
      "Boot_Epochs:\t 516 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2403 - main_Bayes_output_state_loss: 1.4080 - main_Bayes_output_reward_loss: 61.3383 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.9901\n",
      "Boot_Epochs:\t 517 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2797 - main_Bayes_output_state_loss: 1.4525 - main_Bayes_output_reward_loss: 56.0476 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.8729\n",
      "Boot_Epochs:\t 518 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1670 - main_Bayes_output_state_loss: 1.3963 - main_Bayes_output_reward_loss: 0.7867 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 0.7107\n",
      "Boot_Epochs:\t 519 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1164 - main_Bayes_output_state_loss: 1.3383 - main_Bayes_output_reward_loss: 7.3477 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.0881\n",
      "Boot_Epochs:\t 520 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2352 - main_Bayes_output_state_loss: 1.3430 - main_Bayes_output_reward_loss: 120.5477 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.5138\n",
      "Boot_Epochs:\t 521 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2281 - main_Bayes_output_state_loss: 1.4059 - main_Bayes_output_reward_loss: 51.6638 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.8917\n",
      "Boot_Epochs:\t 522 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1648 - main_Bayes_output_state_loss: 1.3903 - main_Bayes_output_reward_loss: 3.3641 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.0004\n",
      "Boot_Epochs:\t 523 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2813 - main_Bayes_output_state_loss: 1.4240 - main_Bayes_output_reward_loss: 86.4602 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.2982\n",
      "Boot_Epochs:\t 524 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2269 - main_Bayes_output_state_loss: 1.4499 - main_Bayes_output_reward_loss: 5.7415 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 1.0614\n",
      "Boot_Epochs:\t 525 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2032 - main_Bayes_output_state_loss: 1.4311 - main_Bayes_output_reward_loss: 2.1284 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 0.8847\n",
      "Boot_Epochs:\t 526 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2227 - main_Bayes_output_state_loss: 1.4384 - main_Bayes_output_reward_loss: 14.0896 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.2617\n",
      "Boot_Epochs:\t 527 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1648 - main_Bayes_output_state_loss: 1.3926 - main_Bayes_output_reward_loss: 1.9809 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.8783\n",
      "Boot_Epochs:\t 528 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1247 - main_Bayes_output_state_loss: 1.3013 - main_Bayes_output_reward_loss: 51.6423 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.7352\n",
      "Boot_Epochs:\t 529 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2761 - main_Bayes_output_state_loss: 1.4301 - main_Bayes_output_reward_loss: 74.3777 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.5475\n",
      "Boot_Epochs:\t 530 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2193 - main_Bayes_output_state_loss: 1.4481 - main_Bayes_output_reward_loss: 1.1185 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.8215\n",
      "Boot_Epochs:\t 531 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1949 - main_Bayes_output_state_loss: 1.3742 - main_Bayes_output_reward_loss: 49.3359 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.6750\n",
      "Boot_Epochs:\t 532 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2281 - main_Bayes_output_state_loss: 1.4105 - main_Bayes_output_reward_loss: 48.1410 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.5415\n",
      "Boot_Epochs:\t 533 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2246 - main_Bayes_output_state_loss: 1.4388 - main_Bayes_output_reward_loss: 14.8987 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 1.1853\n",
      "Boot_Epochs:\t 534 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1259 - main_Bayes_output_state_loss: 1.3251 - main_Bayes_output_reward_loss: 29.7884 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.5128\n",
      "Boot_Epochs:\t 535 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1396 - main_Bayes_output_state_loss: 1.3540 - main_Bayes_output_reward_loss: 15.8710 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.4266\n",
      "Boot_Epochs:\t 536 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1642 - main_Bayes_output_state_loss: 1.3572 - main_Bayes_output_reward_loss: 35.7379 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.6001\n",
      "Boot_Epochs:\t 537 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1327 - main_Bayes_output_state_loss: 1.3608 - main_Bayes_output_reward_loss: 1.6319 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.8546\n",
      "Boot_Epochs:\t 538 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1767 - main_Bayes_output_state_loss: 1.3906 - main_Bayes_output_reward_loss: 15.6699 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.2216\n",
      "Boot_Epochs:\t 539 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0891 - main_Bayes_output_state_loss: 1.3168 - main_Bayes_output_reward_loss: 2.4324 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 0.9184\n",
      "Boot_Epochs:\t 540 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1510 - main_Bayes_output_state_loss: 1.3572 - main_Bayes_output_reward_loss: 23.8469 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.4420\n",
      "Boot_Epochs:\t 541 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1427 - main_Bayes_output_state_loss: 1.3473 - main_Bayes_output_reward_loss: 25.3728 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.3735\n",
      "Boot_Epochs:\t 542 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1770 - main_Bayes_output_state_loss: 1.3667 - main_Bayes_output_reward_loss: 39.6132 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.9570\n",
      "Boot_Epochs:\t 543 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1498 - main_Bayes_output_state_loss: 1.3183 - main_Bayes_output_reward_loss: 60.6101 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.8137\n",
      "Boot_Epochs:\t 544 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1851 - main_Bayes_output_state_loss: 1.3779 - main_Bayes_output_reward_loss: 36.5808 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.7974\n",
      "Boot_Epochs:\t 545 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3368 - main_Bayes_output_state_loss: 1.5122 - main_Bayes_output_reward_loss: 55.3852 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.9274\n",
      "Boot_Epochs:\t 546 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0929 - main_Bayes_output_state_loss: 1.2993 - main_Bayes_output_reward_loss: 23.1878 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.5203\n",
      "Boot_Epochs:\t 547 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2087 - main_Bayes_output_state_loss: 1.4297 - main_Bayes_output_reward_loss: 8.5660 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.2408\n",
      "Boot_Epochs:\t 548 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1442 - main_Bayes_output_state_loss: 1.3460 - main_Bayes_output_reward_loss: 27.8305 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.4371\n",
      "Boot_Epochs:\t 549 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1925 - main_Bayes_output_state_loss: 1.3953 - main_Bayes_output_reward_loss: 26.8160 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.5269\n",
      "Boot_Epochs:\t 550 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1448 - main_Bayes_output_state_loss: 1.3242 - main_Bayes_output_reward_loss: 50.2790 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.6847\n",
      "Boot_Epochs:\t 551 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1638 - main_Bayes_output_state_loss: 1.3384 - main_Bayes_output_reward_loss: 54.6078 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.8432\n",
      "Boot_Epochs:\t 552 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1349 - main_Bayes_output_state_loss: 1.3450 - main_Bayes_output_reward_loss: 20.1959 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.2669\n",
      "Boot_Epochs:\t 553 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2299 - main_Bayes_output_state_loss: 1.3679 - main_Bayes_output_reward_loss: 90.2835 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.4957\n",
      "Boot_Epochs:\t 554 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1096 - main_Bayes_output_state_loss: 1.2974 - main_Bayes_output_reward_loss: 41.2972 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.7962\n",
      "Boot_Epochs:\t 555 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2597 - main_Bayes_output_state_loss: 1.3668 - main_Bayes_output_reward_loss: 122.3833 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 2.6170\n",
      "Boot_Epochs:\t 556 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2077 - main_Bayes_output_state_loss: 1.4307 - main_Bayes_output_reward_loss: 6.6084 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.1172\n",
      "Boot_Epochs:\t 557 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1933 - main_Bayes_output_state_loss: 1.4121 - main_Bayes_output_reward_loss: 11.8756 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.1729\n",
      "Boot_Epochs:\t 558 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2082 - main_Bayes_output_state_loss: 1.3390 - main_Bayes_output_reward_loss: 99.2741 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 2.5110\n",
      "Boot_Epochs:\t 559 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0612 - main_Bayes_output_state_loss: 1.2586 - main_Bayes_output_reward_loss: 33.0965 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.7156\n",
      "Boot_Epochs:\t 560 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2858 - main_Bayes_output_state_loss: 1.5003 - main_Bayes_output_reward_loss: 15.8402 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.2944\n",
      "Boot_Epochs:\t 561 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0437 - main_Bayes_output_state_loss: 1.2353 - main_Bayes_output_reward_loss: 39.4784 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.5069\n",
      "Boot_Epochs:\t 562 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1510 - main_Bayes_output_state_loss: 1.3448 - main_Bayes_output_reward_loss: 37.2552 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.4504\n",
      "Boot_Epochs:\t 563 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2234 - main_Bayes_output_state_loss: 1.3415 - main_Bayes_output_reward_loss: 112.7434 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.2031\n",
      "Boot_Epochs:\t 564 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1547 - main_Bayes_output_state_loss: 1.3143 - main_Bayes_output_reward_loss: 72.4145 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.9697\n",
      "Boot_Epochs:\t 565 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0666 - main_Bayes_output_state_loss: 1.2974 - main_Bayes_output_reward_loss: 1.1300 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.7684\n",
      "Boot_Epochs:\t 566 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1741 - main_Bayes_output_state_loss: 1.4053 - main_Bayes_output_reward_loss: 2.9986 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.9129\n",
      "Boot_Epochs:\t 567 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1758 - main_Bayes_output_state_loss: 1.3612 - main_Bayes_output_reward_loss: 50.0636 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.7060\n",
      "Boot_Epochs:\t 568 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1299 - main_Bayes_output_state_loss: 1.3253 - main_Bayes_output_reward_loss: 40.9941 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.5677\n",
      "Boot_Epochs:\t 569 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0581 - main_Bayes_output_state_loss: 1.2885 - main_Bayes_output_reward_loss: 5.9876 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.0477\n",
      "Boot_Epochs:\t 570 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1375 - main_Bayes_output_state_loss: 1.3656 - main_Bayes_output_reward_loss: 7.7599 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.0851\n",
      "Boot_Epochs:\t 571 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1436 - main_Bayes_output_state_loss: 1.3746 - main_Bayes_output_reward_loss: 5.5755 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.1040\n",
      "Boot_Epochs:\t 572 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0912 - main_Bayes_output_state_loss: 1.3168 - main_Bayes_output_reward_loss: 12.2168 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.0331\n",
      "Boot_Epochs:\t 573 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2114 - main_Bayes_output_state_loss: 1.4471 - main_Bayes_output_reward_loss: 2.0750 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 0.9202\n",
      "Boot_Epochs:\t 574 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2653 - main_Bayes_output_state_loss: 1.4606 - main_Bayes_output_reward_loss: 42.7281 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 1.4017\n",
      "Boot_Epochs:\t 575 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0623 - main_Bayes_output_state_loss: 1.2971 - main_Bayes_output_reward_loss: 3.8455 - main_Bayes_output_state_categorical_accuracy: 0.5556 - main_Bayes_output_reward_mean_absolute_error: 1.0325\n",
      "Boot_Epochs:\t 576 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1235 - main_Bayes_output_state_loss: 1.3299 - main_Bayes_output_reward_loss: 31.8312 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.4501\n",
      "Boot_Epochs:\t 577 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1478 - main_Bayes_output_state_loss: 1.3685 - main_Bayes_output_reward_loss: 20.8003 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.2568\n",
      "Boot_Epochs:\t 578 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9822 - main_Bayes_output_state_loss: 1.1987 - main_Bayes_output_reward_loss: 23.8830 - main_Bayes_output_state_categorical_accuracy: 0.5556 - main_Bayes_output_reward_mean_absolute_error: 1.4597\n",
      "Boot_Epochs:\t 579 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1311 - main_Bayes_output_state_loss: 1.3171 - main_Bayes_output_reward_loss: 55.2112 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.7418\n",
      "Boot_Epochs:\t 580 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1401 - main_Bayes_output_state_loss: 1.2982 - main_Bayes_output_reward_loss: 83.9933 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.1539\n",
      "Boot_Epochs:\t 581 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1705 - main_Bayes_output_state_loss: 1.4106 - main_Bayes_output_reward_loss: 1.2504 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.8147\n",
      "Boot_Epochs:\t 582 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0816 - main_Bayes_output_state_loss: 1.2712 - main_Bayes_output_reward_loss: 53.0184 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.5008\n",
      "Boot_Epochs:\t 583 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0586 - main_Bayes_output_state_loss: 1.2847 - main_Bayes_output_reward_loss: 17.0274 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.2779\n",
      "Boot_Epochs:\t 584 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1515 - main_Bayes_output_state_loss: 1.3916 - main_Bayes_output_reward_loss: 3.2198 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 0.9249\n",
      "Boot_Epochs:\t 585 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1347 - main_Bayes_output_state_loss: 1.3717 - main_Bayes_output_reward_loss: 6.8260 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.1422\n",
      "Boot_Epochs:\t 586 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1201 - main_Bayes_output_state_loss: 1.3582 - main_Bayes_output_reward_loss: 6.1147 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.1505\n",
      "Boot_Epochs:\t 587 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0871 - main_Bayes_output_state_loss: 1.3209 - main_Bayes_output_reward_loss: 9.9034 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.2328\n",
      "Boot_Epochs:\t 588 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0893 - main_Bayes_output_state_loss: 1.3307 - main_Bayes_output_reward_loss: 2.2042 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 0.9667\n",
      "Boot_Epochs:\t 589 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0909 - main_Bayes_output_state_loss: 1.2964 - main_Bayes_output_reward_loss: 38.2461 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.4718\n",
      "Boot_Epochs:\t 590 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2563 - main_Bayes_output_state_loss: 1.3963 - main_Bayes_output_reward_loss: 103.6119 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.0900\n",
      "Boot_Epochs:\t 591 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1218 - main_Bayes_output_state_loss: 1.3573 - main_Bayes_output_reward_loss: 9.2938 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.3355\n",
      "Boot_Epochs:\t 592 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2022 - main_Bayes_output_state_loss: 1.4466 - main_Bayes_output_reward_loss: 1.2540 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.8596\n",
      "Boot_Epochs:\t 593 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1340 - main_Bayes_output_state_loss: 1.3619 - main_Bayes_output_reward_loss: 16.9965 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.4595\n",
      "Boot_Epochs:\t 594 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0165 - main_Bayes_output_state_loss: 1.2595 - main_Bayes_output_reward_loss: 1.0632 - main_Bayes_output_state_categorical_accuracy: 0.5657 - main_Bayes_output_reward_mean_absolute_error: 0.7987\n",
      "Boot_Epochs:\t 595 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1285 - main_Bayes_output_state_loss: 1.3713 - main_Bayes_output_reward_loss: 1.7211 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.8595\n",
      "Boot_Epochs:\t 596 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1743 - main_Bayes_output_state_loss: 1.3912 - main_Bayes_output_reward_loss: 29.1197 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.3642\n",
      "Boot_Epochs:\t 597 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0784 - main_Bayes_output_state_loss: 1.3226 - main_Bayes_output_reward_loss: 3.7927 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 0.9949\n",
      "Boot_Epochs:\t 598 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2246 - main_Bayes_output_state_loss: 1.3976 - main_Bayes_output_reward_loss: 75.2244 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.0496\n",
      "Boot_Epochs:\t 599 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1009 - main_Bayes_output_state_loss: 1.3468 - main_Bayes_output_reward_loss: 2.1261 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.8733\n",
      "Boot_Epochs:\t 600 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0146 - main_Bayes_output_state_loss: 1.2476 - main_Bayes_output_reward_loss: 15.1946 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.3817\n",
      "Boot_Epochs:\t 601 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0478 - main_Bayes_output_state_loss: 1.2952 - main_Bayes_output_reward_loss: 1.8086 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 0.8535\n",
      "Boot_Epochs:\t 602 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1518 - main_Bayes_output_state_loss: 1.3901 - main_Bayes_output_reward_loss: 9.6496 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.1769\n",
      "Boot_Epochs:\t 603 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1145 - main_Bayes_output_state_loss: 1.3570 - main_Bayes_output_reward_loss: 6.9506 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.0860\n",
      "Boot_Epochs:\t 604 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1001 - main_Bayes_output_state_loss: 1.3472 - main_Bayes_output_reward_loss: 1.4033 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 0.8903\n",
      "Boot_Epochs:\t 605 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1882 - main_Bayes_output_state_loss: 1.4322 - main_Bayes_output_reward_loss: 3.9596 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.0423\n",
      "Boot_Epochs:\t 606 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1742 - main_Bayes_output_state_loss: 1.3989 - main_Bayes_output_reward_loss: 24.1905 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.4458\n",
      "Boot_Epochs:\t 607 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1652 - main_Bayes_output_state_loss: 1.3256 - main_Bayes_output_reward_loss: 88.1481 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.8572\n",
      "Boot_Epochs:\t 608 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0851 - main_Bayes_output_state_loss: 1.3313 - main_Bayes_output_reward_loss: 2.9744 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.9301\n",
      "Boot_Epochs:\t 609 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2492 - main_Bayes_output_state_loss: 1.4556 - main_Bayes_output_reward_loss: 41.5915 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.6019\n",
      "Boot_Epochs:\t 610 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1723 - main_Bayes_output_state_loss: 1.3910 - main_Bayes_output_reward_loss: 30.5783 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.4307\n",
      "Boot_Epochs:\t 611 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1061 - main_Bayes_output_state_loss: 1.3392 - main_Bayes_output_reward_loss: 15.0336 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.1114\n",
      "Boot_Epochs:\t 612 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0929 - main_Bayes_output_state_loss: 1.3343 - main_Bayes_output_reward_loss: 7.0912 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.0556\n",
      "Boot_Epochs:\t 613 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0848 - main_Bayes_output_state_loss: 1.3149 - main_Bayes_output_reward_loss: 19.1385 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.1437\n",
      "Boot_Epochs:\t 614 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1307 - main_Bayes_output_state_loss: 1.3362 - main_Bayes_output_reward_loss: 43.9149 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.4943\n",
      "Boot_Epochs:\t 615 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1273 - main_Bayes_output_state_loss: 1.3385 - main_Bayes_output_reward_loss: 38.1712 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.6187\n",
      "Boot_Epochs:\t 616 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0336 - main_Bayes_output_state_loss: 1.2603 - main_Bayes_output_reward_loss: 22.2564 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.4886\n",
      "Boot_Epochs:\t 617 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0916 - main_Bayes_output_state_loss: 1.3238 - main_Bayes_output_reward_loss: 16.0536 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.4167\n",
      "Boot_Epochs:\t 618 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0770 - main_Bayes_output_state_loss: 1.2845 - main_Bayes_output_reward_loss: 43.4581 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.4690\n",
      "Boot_Epochs:\t 619 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0507 - main_Bayes_output_state_loss: 1.3004 - main_Bayes_output_reward_loss: 1.5326 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 0.8577\n",
      "Boot_Epochs:\t 620 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1731 - main_Bayes_output_state_loss: 1.3064 - main_Bayes_output_reward_loss: 119.0369 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.3274\n",
      "Boot_Epochs:\t 621 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0621 - main_Bayes_output_state_loss: 1.3128 - main_Bayes_output_reward_loss: 1.7315 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 0.8763\n",
      "Boot_Epochs:\t 622 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1206 - main_Bayes_output_state_loss: 1.3649 - main_Bayes_output_reward_loss: 6.9139 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.1154\n",
      "Boot_Epochs:\t 623 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0289 - main_Bayes_output_state_loss: 1.2682 - main_Bayes_output_reward_loss: 12.9388 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.1537\n",
      "Boot_Epochs:\t 624 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1433 - main_Bayes_output_state_loss: 1.3934 - main_Bayes_output_reward_loss: 2.7922 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.9580\n",
      "Boot_Epochs:\t 625 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1583 - main_Bayes_output_state_loss: 1.3696 - main_Bayes_output_reward_loss: 40.8462 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 1.4945\n",
      "Boot_Epochs:\t 626 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1906 - main_Bayes_output_state_loss: 1.4063 - main_Bayes_output_reward_loss: 35.8847 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.5071\n",
      "Boot_Epochs:\t 627 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0812 - main_Bayes_output_state_loss: 1.3324 - main_Bayes_output_reward_loss: 1.0246 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.8107\n",
      "Boot_Epochs:\t 628 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2023 - main_Bayes_output_state_loss: 1.3952 - main_Bayes_output_reward_loss: 60.5379 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.9450\n",
      "Boot_Epochs:\t 629 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2182 - main_Bayes_output_state_loss: 1.4318 - main_Bayes_output_reward_loss: 38.5706 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 1.7910\n",
      "Boot_Epochs:\t 630 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2121 - main_Bayes_output_state_loss: 1.3940 - main_Bayes_output_reward_loss: 70.8163 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.3580\n",
      "Boot_Epochs:\t 631 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0939 - main_Bayes_output_state_loss: 1.3395 - main_Bayes_output_reward_loss: 6.7638 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.0502\n",
      "Boot_Epochs:\t 632 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0409 - main_Bayes_output_state_loss: 1.2705 - main_Bayes_output_reward_loss: 21.6438 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.5167\n",
      "Boot_Epochs:\t 633 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0982 - main_Bayes_output_state_loss: 1.2708 - main_Bayes_output_reward_loss: 79.4494 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.2349\n",
      "Boot_Epochs:\t 634 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0763 - main_Bayes_output_state_loss: 1.3275 - main_Bayes_output_reward_loss: 1.1253 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 0.7955\n",
      "Boot_Epochs:\t 635 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1699 - main_Bayes_output_state_loss: 1.4212 - main_Bayes_output_reward_loss: 0.9183 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 0.7765\n",
      "Boot_Epochs:\t 636 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1319 - main_Bayes_output_state_loss: 1.3680 - main_Bayes_output_reward_loss: 13.9010 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.2636\n",
      "Boot_Epochs:\t 637 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0582 - main_Bayes_output_state_loss: 1.2978 - main_Bayes_output_reward_loss: 13.5766 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.3819\n",
      "Boot_Epochs:\t 638 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1477 - main_Bayes_output_state_loss: 1.3716 - main_Bayes_output_reward_loss: 27.5641 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.3130\n",
      "Boot_Epochs:\t 639 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0761 - main_Bayes_output_state_loss: 1.3186 - main_Bayes_output_reward_loss: 9.9425 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.0668\n",
      "Boot_Epochs:\t 640 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1704 - main_Bayes_output_state_loss: 1.4228 - main_Bayes_output_reward_loss: 0.7852 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.7364\n",
      "Boot_Epochs:\t 641 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1316 - main_Bayes_output_state_loss: 1.3690 - main_Bayes_output_reward_loss: 15.6162 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.3094\n",
      "Boot_Epochs:\t 642 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1206 - main_Bayes_output_state_loss: 1.3541 - main_Bayes_output_reward_loss: 19.3950 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.3478\n",
      "Boot_Epochs:\t 643 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1213 - main_Bayes_output_state_loss: 1.3681 - main_Bayes_output_reward_loss: 6.6060 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.1101\n",
      "Boot_Epochs:\t 644 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0214 - main_Bayes_output_state_loss: 1.2735 - main_Bayes_output_reward_loss: 1.1024 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 0.8062\n",
      "Boot_Epochs:\t 645 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1352 - main_Bayes_output_state_loss: 1.3820 - main_Bayes_output_reward_loss: 6.8636 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.1718\n",
      "Boot_Epochs:\t 646 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1867 - main_Bayes_output_state_loss: 1.4390 - main_Bayes_output_reward_loss: 0.9212 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 0.7646\n",
      "Boot_Epochs:\t 647 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1483 - main_Bayes_output_state_loss: 1.4006 - main_Bayes_output_reward_loss: 1.0584 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 0.8016\n",
      "Boot_Epochs:\t 648 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0709 - main_Bayes_output_state_loss: 1.2751 - main_Bayes_output_reward_loss: 48.8750 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.4317\n",
      "Boot_Epochs:\t 649 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9966 - main_Bayes_output_state_loss: 1.2473 - main_Bayes_output_reward_loss: 3.4331 - main_Bayes_output_state_categorical_accuracy: 0.5657 - main_Bayes_output_reward_mean_absolute_error: 0.9717\n",
      "Boot_Epochs:\t 650 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0916 - main_Bayes_output_state_loss: 1.2845 - main_Bayes_output_reward_loss: 59.8843 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.8297\n",
      "Boot_Epochs:\t 651 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0906 - main_Bayes_output_state_loss: 1.3262 - main_Bayes_output_reward_loss: 18.1263 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.3230\n",
      "Boot_Epochs:\t 652 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1579 - main_Bayes_output_state_loss: 1.3790 - main_Bayes_output_reward_loss: 34.6408 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.4065\n",
      "Boot_Epochs:\t 653 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0753 - main_Bayes_output_state_loss: 1.3289 - main_Bayes_output_reward_loss: 1.0626 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.7954\n",
      "Boot_Epochs:\t 654 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0448 - main_Bayes_output_state_loss: 1.2542 - main_Bayes_output_reward_loss: 45.9080 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.5165\n",
      "Boot_Epochs:\t 655 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9988 - main_Bayes_output_state_loss: 1.2531 - main_Bayes_output_reward_loss: 0.8631 - main_Bayes_output_state_categorical_accuracy: 0.5455 - main_Bayes_output_reward_mean_absolute_error: 0.7631\n",
      "Boot_Epochs:\t 656 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1141 - main_Bayes_output_state_loss: 1.3478 - main_Bayes_output_reward_loss: 21.3393 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.3832\n",
      "Boot_Epochs:\t 657 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0805 - main_Bayes_output_state_loss: 1.3102 - main_Bayes_output_reward_loss: 25.3979 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.7301\n",
      "Boot_Epochs:\t 658 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0988 - main_Bayes_output_state_loss: 1.3053 - main_Bayes_output_reward_loss: 49.4389 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.4698\n",
      "Boot_Epochs:\t 659 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0227 - main_Bayes_output_state_loss: 1.2691 - main_Bayes_output_reward_loss: 9.7703 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.1709\n",
      "Boot_Epochs:\t 660 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1277 - main_Bayes_output_state_loss: 1.3290 - main_Bayes_output_reward_loss: 54.1954 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.7845\n",
      "Boot_Epochs:\t 661 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1612 - main_Bayes_output_state_loss: 1.3885 - main_Bayes_output_reward_loss: 28.7730 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.2162\n",
      "Boot_Epochs:\t 662 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0981 - main_Bayes_output_state_loss: 1.3295 - main_Bayes_output_reward_loss: 23.8754 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.4354\n",
      "Boot_Epochs:\t 663 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1250 - main_Bayes_output_state_loss: 1.3366 - main_Bayes_output_reward_loss: 44.1841 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.3948\n",
      "Boot_Epochs:\t 664 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1191 - main_Bayes_output_state_loss: 1.3239 - main_Bayes_output_reward_loss: 50.9587 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.7824\n",
      "Boot_Epochs:\t 665 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0572 - main_Bayes_output_state_loss: 1.2208 - main_Bayes_output_reward_loss: 92.0690 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.9045\n",
      "Boot_Epochs:\t 666 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0956 - main_Bayes_output_state_loss: 1.3213 - main_Bayes_output_reward_loss: 30.7662 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.5798\n",
      "Boot_Epochs:\t 667 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1000 - main_Bayes_output_state_loss: 1.3478 - main_Bayes_output_reward_loss: 9.2891 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.0856\n",
      "Boot_Epochs:\t 668 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1190 - main_Bayes_output_state_loss: 1.3740 - main_Bayes_output_reward_loss: 0.8410 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 0.7479\n",
      "Boot_Epochs:\t 669 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0870 - main_Bayes_output_state_loss: 1.3336 - main_Bayes_output_reward_loss: 7.8403 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.9989\n",
      "Boot_Epochs:\t 670 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0025 - main_Bayes_output_state_loss: 1.2469 - main_Bayes_output_reward_loss: 11.9731 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.1226\n",
      "Boot_Epochs:\t 671 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9204 - main_Bayes_output_state_loss: 1.1671 - main_Bayes_output_reward_loss: 8.6790 - main_Bayes_output_state_categorical_accuracy: 0.5455 - main_Bayes_output_reward_mean_absolute_error: 1.2972\n",
      "Boot_Epochs:\t 672 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0066 - main_Bayes_output_state_loss: 1.2599 - main_Bayes_output_reward_loss: 2.2864 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 0.8832\n",
      "Boot_Epochs:\t 673 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0109 - main_Bayes_output_state_loss: 1.2648 - main_Bayes_output_reward_loss: 1.8346 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 0.9191\n",
      "Boot_Epochs:\t 674 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1166 - main_Bayes_output_state_loss: 1.3679 - main_Bayes_output_reward_loss: 4.6544 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.0092\n",
      "Boot_Epochs:\t 675 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0267 - main_Bayes_output_state_loss: 1.2525 - main_Bayes_output_reward_loss: 29.6589 - main_Bayes_output_state_categorical_accuracy: 0.5657 - main_Bayes_output_reward_mean_absolute_error: 1.2817\n",
      "Boot_Epochs:\t 676 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1457 - main_Bayes_output_state_loss: 1.2661 - main_Bayes_output_reward_loss: 133.3097 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 2.3686\n",
      "Boot_Epochs:\t 677 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0556 - main_Bayes_output_state_loss: 1.3095 - main_Bayes_output_reward_loss: 1.8526 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 0.8088\n",
      "Boot_Epochs:\t 678 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2254 - main_Bayes_output_state_loss: 1.3629 - main_Bayes_output_reward_loss: 116.9308 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 2.2267\n",
      "Boot_Epochs:\t 679 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1630 - main_Bayes_output_state_loss: 1.4032 - main_Bayes_output_reward_loss: 15.4920 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.2131\n",
      "Boot_Epochs:\t 680 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1608 - main_Bayes_output_state_loss: 1.2862 - main_Bayes_output_reward_loss: 130.4919 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 2.8739\n",
      "Boot_Epochs:\t 681 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1455 - main_Bayes_output_state_loss: 1.4008 - main_Bayes_output_reward_loss: 1.0640 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.8005\n",
      "Boot_Epochs:\t 682 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0841 - main_Bayes_output_state_loss: 1.3252 - main_Bayes_output_reward_loss: 14.4101 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.3861\n",
      "Boot_Epochs:\t 683 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0135 - main_Bayes_output_state_loss: 1.2671 - main_Bayes_output_reward_loss: 2.0607 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 0.8133\n",
      "Boot_Epochs:\t 684 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1323 - main_Bayes_output_state_loss: 1.3210 - main_Bayes_output_reward_loss: 66.5297 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.8495\n",
      "Boot_Epochs:\t 685 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1510 - main_Bayes_output_state_loss: 1.3121 - main_Bayes_output_reward_loss: 95.0311 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.8357\n",
      "Boot_Epochs:\t 686 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0479 - main_Bayes_output_state_loss: 1.3025 - main_Bayes_output_reward_loss: 1.3474 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.8565\n",
      "Boot_Epochs:\t 687 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0848 - main_Bayes_output_state_loss: 1.2894 - main_Bayes_output_reward_loss: 51.8156 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.5598\n",
      "Boot_Epochs:\t 688 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1475 - main_Bayes_output_state_loss: 1.3747 - main_Bayes_output_reward_loss: 28.8727 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.4734\n",
      "Boot_Epochs:\t 689 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0875 - main_Bayes_output_state_loss: 1.2978 - main_Bayes_output_reward_loss: 45.8825 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.4802\n",
      "Boot_Epochs:\t 690 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0609 - main_Bayes_output_state_loss: 1.3037 - main_Bayes_output_reward_loss: 12.4311 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.1217\n",
      "Boot_Epochs:\t 691 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0794 - main_Bayes_output_state_loss: 1.3352 - main_Bayes_output_reward_loss: 1.3181 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.8426\n",
      "Boot_Epochs:\t 692 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1623 - main_Bayes_output_state_loss: 1.3652 - main_Bayes_output_reward_loss: 53.1199 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.7965\n",
      "Boot_Epochs:\t 693 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1869 - main_Bayes_output_state_loss: 1.3766 - main_Bayes_output_reward_loss: 66.7130 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.9992\n",
      "Boot_Epochs:\t 694 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2860 - main_Bayes_output_state_loss: 1.4975 - main_Bayes_output_reward_loss: 44.7818 - main_Bayes_output_state_categorical_accuracy: 0.3737 - main_Bayes_output_reward_mean_absolute_error: 1.4450\n",
      "Boot_Epochs:\t 695 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0709 - main_Bayes_output_state_loss: 1.3249 - main_Bayes_output_reward_loss: 1.3691 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.8190\n",
      "Boot_Epochs:\t 696 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1604 - main_Bayes_output_state_loss: 1.3663 - main_Bayes_output_reward_loss: 49.9326 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.7284\n",
      "Boot_Epochs:\t 697 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9434 - main_Bayes_output_state_loss: 1.1991 - main_Bayes_output_reward_loss: 1.1269 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 0.7979\n",
      "Boot_Epochs:\t 698 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1227 - main_Bayes_output_state_loss: 1.2506 - main_Bayes_output_reward_loss: 127.3838 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.9668\n",
      "Boot_Epochs:\t 699 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1010 - main_Bayes_output_state_loss: 1.3484 - main_Bayes_output_reward_loss: 8.6185 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.0903\n",
      "Boot_Epochs:\t 700 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1768 - main_Bayes_output_state_loss: 1.3321 - main_Bayes_output_reward_loss: 99.4891 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.5961\n",
      "Boot_Epochs:\t 701 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9300 - main_Bayes_output_state_loss: 1.1818 - main_Bayes_output_reward_loss: 4.7038 - main_Bayes_output_state_categorical_accuracy: 0.5657 - main_Bayes_output_reward_mean_absolute_error: 1.1040\n",
      "Boot_Epochs:\t 702 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0309 - main_Bayes_output_state_loss: 1.2434 - main_Bayes_output_reward_loss: 43.7221 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.6071\n",
      "Boot_Epochs:\t 703 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0485 - main_Bayes_output_state_loss: 1.2295 - main_Bayes_output_reward_loss: 74.7152 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.0294\n",
      "Boot_Epochs:\t 704 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0495 - main_Bayes_output_state_loss: 1.3042 - main_Bayes_output_reward_loss: 1.0701 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.7719\n",
      "Boot_Epochs:\t 705 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2352 - main_Bayes_output_state_loss: 1.3440 - main_Bayes_output_reward_loss: 147.0368 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.4852\n",
      "Boot_Epochs:\t 706 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1821 - main_Bayes_output_state_loss: 1.3903 - main_Bayes_output_reward_loss: 46.8984 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.4986\n",
      "Boot_Epochs:\t 707 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1049 - main_Bayes_output_state_loss: 1.3174 - main_Bayes_output_reward_loss: 41.9987 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.5064\n",
      "Boot_Epochs:\t 708 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0395 - main_Bayes_output_state_loss: 1.2869 - main_Bayes_output_reward_loss: 6.8218 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.0608\n",
      "Boot_Epochs:\t 709 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9402 - main_Bayes_output_state_loss: 1.1882 - main_Bayes_output_reward_loss: 6.9542 - main_Bayes_output_state_categorical_accuracy: 0.5758 - main_Bayes_output_reward_mean_absolute_error: 1.0287\n",
      "Boot_Epochs:\t 710 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2232 - main_Bayes_output_state_loss: 1.4265 - main_Bayes_output_reward_loss: 53.3397 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.8166\n",
      "Boot_Epochs:\t 711 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2107 - main_Bayes_output_state_loss: 1.3542 - main_Bayes_output_reward_loss: 112.5628 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.0103\n",
      "Boot_Epochs:\t 712 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0828 - main_Bayes_output_state_loss: 1.3380 - main_Bayes_output_reward_loss: 0.9116 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 0.7622\n",
      "Boot_Epochs:\t 713 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2020 - main_Bayes_output_state_loss: 1.3539 - main_Bayes_output_reward_loss: 104.0783 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.2093\n",
      "Boot_Epochs:\t 714 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1033 - main_Bayes_output_state_loss: 1.2562 - main_Bayes_output_reward_loss: 102.6295 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.7683\n",
      "Boot_Epochs:\t 715 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1840 - main_Bayes_output_state_loss: 1.3696 - main_Bayes_output_reward_loss: 70.2764 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.9221\n",
      "Boot_Epochs:\t 716 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1577 - main_Bayes_output_state_loss: 1.2687 - main_Bayes_output_reward_loss: 144.8010 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 2.8309\n",
      "Boot_Epochs:\t 717 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1272 - main_Bayes_output_state_loss: 1.3824 - main_Bayes_output_reward_loss: 1.1553 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 0.8167\n",
      "Boot_Epochs:\t 718 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1563 - main_Bayes_output_state_loss: 1.2732 - main_Bayes_output_reward_loss: 138.2152 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.4896\n",
      "Boot_Epochs:\t 719 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0295 - main_Bayes_output_state_loss: 1.2845 - main_Bayes_output_reward_loss: 0.7374 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.7014\n",
      "Boot_Epochs:\t 720 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1152 - main_Bayes_output_state_loss: 1.3551 - main_Bayes_output_reward_loss: 16.3730 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.4205\n",
      "Boot_Epochs:\t 721 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1134 - main_Bayes_output_state_loss: 1.3621 - main_Bayes_output_reward_loss: 7.8349 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 1.0518\n",
      "Boot_Epochs:\t 722 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0422 - main_Bayes_output_state_loss: 1.2973 - main_Bayes_output_reward_loss: 0.8041 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 0.7339\n",
      "Boot_Epochs:\t 723 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1115 - main_Bayes_output_state_loss: 1.3671 - main_Bayes_output_reward_loss: 0.8314 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 0.7050\n",
      "Boot_Epochs:\t 724 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0358 - main_Bayes_output_state_loss: 1.2514 - main_Bayes_output_reward_loss: 40.0533 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.5904\n",
      "Boot_Epochs:\t 725 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0267 - main_Bayes_output_state_loss: 1.1924 - main_Bayes_output_reward_loss: 89.2103 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.8202\n",
      "Boot_Epochs:\t 726 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0683 - main_Bayes_output_state_loss: 1.3226 - main_Bayes_output_reward_loss: 2.5093 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.8751\n",
      "Boot_Epochs:\t 727 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3231 - main_Bayes_output_state_loss: 1.5240 - main_Bayes_output_reward_loss: 55.2167 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.7338\n",
      "Boot_Epochs:\t 728 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0427 - main_Bayes_output_state_loss: 1.2836 - main_Bayes_output_reward_loss: 14.4837 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.0869\n",
      "Boot_Epochs:\t 729 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0126 - main_Bayes_output_state_loss: 1.2671 - main_Bayes_output_reward_loss: 0.9456 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 0.7721\n",
      "Boot_Epochs:\t 730 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0757 - main_Bayes_output_state_loss: 1.3281 - main_Bayes_output_reward_loss: 1.9985 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.8540\n",
      "Boot_Epochs:\t 731 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0631 - main_Bayes_output_state_loss: 1.3186 - main_Bayes_output_reward_loss: 0.9053 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 0.7719\n",
      "Boot_Epochs:\t 732 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0738 - main_Bayes_output_state_loss: 1.3279 - main_Bayes_output_reward_loss: 1.5274 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 0.8620\n",
      "Boot_Epochs:\t 733 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0617 - main_Bayes_output_state_loss: 1.3133 - main_Bayes_output_reward_loss: 4.3339 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.0978\n",
      "Boot_Epochs:\t 734 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0072 - main_Bayes_output_state_loss: 1.2533 - main_Bayes_output_reward_loss: 8.0603 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.1363\n",
      "Boot_Epochs:\t 735 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0724 - main_Bayes_output_state_loss: 1.2635 - main_Bayes_output_reward_loss: 65.2174 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.0657\n",
      "Boot_Epochs:\t 736 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1487 - main_Bayes_output_state_loss: 1.3583 - main_Bayes_output_reward_loss: 45.8290 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.4265\n",
      "Boot_Epochs:\t 737 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2750 - main_Bayes_output_state_loss: 1.3600 - main_Bayes_output_reward_loss: 170.2878 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 3.3345\n",
      "Boot_Epochs:\t 738 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0081 - main_Bayes_output_state_loss: 1.2548 - main_Bayes_output_reward_loss: 8.8272 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.0058\n",
      "Boot_Epochs:\t 739 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1936 - main_Bayes_output_state_loss: 1.4017 - main_Bayes_output_reward_loss: 47.7950 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.5585\n",
      "Boot_Epochs:\t 740 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0764 - main_Bayes_output_state_loss: 1.2620 - main_Bayes_output_reward_loss: 69.2146 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.9330\n",
      "Boot_Epochs:\t 741 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0572 - main_Bayes_output_state_loss: 1.2995 - main_Bayes_output_reward_loss: 13.2687 - main_Bayes_output_state_categorical_accuracy: 0.5455 - main_Bayes_output_reward_mean_absolute_error: 1.2364\n",
      "Boot_Epochs:\t 742 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1395 - main_Bayes_output_state_loss: 1.2799 - main_Bayes_output_reward_loss: 114.8890 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.6712\n",
      "Boot_Epochs:\t 743 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0712 - main_Bayes_output_state_loss: 1.3251 - main_Bayes_output_reward_loss: 1.1471 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.8108\n",
      "Boot_Epochs:\t 744 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0907 - main_Bayes_output_state_loss: 1.3292 - main_Bayes_output_reward_loss: 17.4324 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.1628\n",
      "Boot_Epochs:\t 745 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3600 - main_Bayes_output_state_loss: 1.4522 - main_Bayes_output_reward_loss: 163.6655 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 2.6450\n",
      "Boot_Epochs:\t 746 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1680 - main_Bayes_output_state_loss: 1.3528 - main_Bayes_output_reward_loss: 71.3895 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.9633\n",
      "Boot_Epochs:\t 747 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1429 - main_Bayes_output_state_loss: 1.3062 - main_Bayes_output_reward_loss: 92.6892 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.3190\n",
      "Boot_Epochs:\t 748 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0018 - main_Bayes_output_state_loss: 1.2448 - main_Bayes_output_reward_loss: 13.3806 - main_Bayes_output_state_categorical_accuracy: 0.5455 - main_Bayes_output_reward_mean_absolute_error: 1.1843\n",
      "Boot_Epochs:\t 749 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1295 - main_Bayes_output_state_loss: 1.3747 - main_Bayes_output_reward_loss: 12.0783 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.1685\n",
      "Boot_Epochs:\t 750 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1882 - main_Bayes_output_state_loss: 1.4241 - main_Bayes_output_reward_loss: 20.1486 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.3227\n",
      "Boot_Epochs:\t 751 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1368 - main_Bayes_output_state_loss: 1.3809 - main_Bayes_output_reward_loss: 12.7733 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.2093\n",
      "Boot_Epochs:\t 752 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1197 - main_Bayes_output_state_loss: 1.3757 - main_Bayes_output_reward_loss: 1.2759 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.8138\n",
      "Boot_Epochs:\t 753 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0549 - main_Bayes_output_state_loss: 1.3099 - main_Bayes_output_reward_loss: 1.0908 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 0.8453\n",
      "Boot_Epochs:\t 754 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0476 - main_Bayes_output_state_loss: 1.2747 - main_Bayes_output_reward_loss: 30.4360 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.3717\n",
      "Boot_Epochs:\t 755 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2428 - main_Bayes_output_state_loss: 1.3594 - main_Bayes_output_reward_loss: 139.8788 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.6010\n",
      "Boot_Epochs:\t 756 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1034 - main_Bayes_output_state_loss: 1.3165 - main_Bayes_output_reward_loss: 44.7096 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.4713\n",
      "Boot_Epochs:\t 757 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1204 - main_Bayes_output_state_loss: 1.3783 - main_Bayes_output_reward_loss: 0.9318 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 0.7469\n",
      "Boot_Epochs:\t 758 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9661 - main_Bayes_output_state_loss: 1.2244 - main_Bayes_output_reward_loss: 0.8926 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.7751\n",
      "Boot_Epochs:\t 759 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0797 - main_Bayes_output_state_loss: 1.3297 - main_Bayes_output_reward_loss: 9.9305 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.2220\n",
      "Boot_Epochs:\t 760 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0788 - main_Bayes_output_state_loss: 1.3370 - main_Bayes_output_reward_loss: 1.4641 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 0.7794\n",
      "Boot_Epochs:\t 761 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1168 - main_Bayes_output_state_loss: 1.3718 - main_Bayes_output_reward_loss: 4.3778 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.0001\n",
      "Boot_Epochs:\t 762 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0568 - main_Bayes_output_state_loss: 1.2863 - main_Bayes_output_reward_loss: 29.5767 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.2958\n",
      "Boot_Epochs:\t 763 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9989 - main_Bayes_output_state_loss: 1.2155 - main_Bayes_output_reward_loss: 41.4982 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.4586\n",
      "Boot_Epochs:\t 764 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1499 - main_Bayes_output_state_loss: 1.3767 - main_Bayes_output_reward_loss: 32.9008 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.4744\n",
      "Boot_Epochs:\t 765 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9845 - main_Bayes_output_state_loss: 1.2422 - main_Bayes_output_reward_loss: 0.8565 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 0.7710\n",
      "Boot_Epochs:\t 766 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1367 - main_Bayes_output_state_loss: 1.3361 - main_Bayes_output_reward_loss: 58.4346 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.9142\n",
      "Boot_Epochs:\t 767 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0524 - main_Bayes_output_state_loss: 1.2952 - main_Bayes_output_reward_loss: 16.7072 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.5801\n",
      "Boot_Epochs:\t 768 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2388 - main_Bayes_output_state_loss: 1.3780 - main_Bayes_output_reward_loss: 118.6498 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 2.1828\n",
      "Boot_Epochs:\t 769 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1149 - main_Bayes_output_state_loss: 1.3542 - main_Bayes_output_reward_loss: 19.1796 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.4387\n",
      "Boot_Epochs:\t 770 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2912 - main_Bayes_output_state_loss: 1.2861 - main_Bayes_output_reward_loss: 264.3542 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 4.3139\n",
      "Boot_Epochs:\t 771 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1010 - main_Bayes_output_state_loss: 1.2942 - main_Bayes_output_reward_loss: 66.4767 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.8453\n",
      "Boot_Epochs:\t 772 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1129 - main_Bayes_output_state_loss: 1.3545 - main_Bayes_output_reward_loss: 16.8479 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.5350\n",
      "Boot_Epochs:\t 773 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0639 - main_Bayes_output_state_loss: 1.3005 - main_Bayes_output_reward_loss: 22.2302 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.2167\n",
      "Boot_Epochs:\t 774 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0846 - main_Bayes_output_state_loss: 1.3385 - main_Bayes_output_reward_loss: 6.3816 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.0737\n",
      "Boot_Epochs:\t 775 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0541 - main_Bayes_output_state_loss: 1.3118 - main_Bayes_output_reward_loss: 2.0996 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.9093\n",
      "Boot_Epochs:\t 776 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1205 - main_Bayes_output_state_loss: 1.3777 - main_Bayes_output_reward_loss: 1.6318 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.8614\n",
      "Boot_Epochs:\t 777 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0891 - main_Bayes_output_state_loss: 1.3450 - main_Bayes_output_reward_loss: 2.9562 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 0.8974\n",
      "Boot_Epochs:\t 778 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1329 - main_Bayes_output_state_loss: 1.3444 - main_Bayes_output_reward_loss: 46.2878 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.4548\n",
      "Boot_Epochs:\t 779 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0987 - main_Bayes_output_state_loss: 1.2978 - main_Bayes_output_reward_loss: 58.4501 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.8825\n",
      "Boot_Epochs:\t 780 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1784 - main_Bayes_output_state_loss: 1.4319 - main_Bayes_output_reward_loss: 6.2061 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 1.1478\n",
      "Boot_Epochs:\t 781 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4408 - main_Bayes_output_state_loss: 1.4679 - main_Bayes_output_reward_loss: 232.8005 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 3.5952\n",
      "Boot_Epochs:\t 782 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1608 - main_Bayes_output_state_loss: 1.3829 - main_Bayes_output_reward_loss: 36.4485 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.5874\n",
      "Boot_Epochs:\t 783 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1851 - main_Bayes_output_state_loss: 1.3468 - main_Bayes_output_reward_loss: 97.6824 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.7855\n",
      "Boot_Epochs:\t 784 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3757 - main_Bayes_output_state_loss: 1.4208 - main_Bayes_output_reward_loss: 213.8678 - main_Bayes_output_state_categorical_accuracy: 0.3434 - main_Bayes_output_reward_mean_absolute_error: 2.9694\n",
      "Boot_Epochs:\t 785 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1322 - main_Bayes_output_state_loss: 1.3906 - main_Bayes_output_reward_loss: 1.0777 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.8157\n",
      "Boot_Epochs:\t 786 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2100 - main_Bayes_output_state_loss: 1.4428 - main_Bayes_output_reward_loss: 27.8255 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.3055\n",
      "Boot_Epochs:\t 787 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1725 - main_Bayes_output_state_loss: 1.3844 - main_Bayes_output_reward_loss: 48.4244 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.5525\n",
      "Boot_Epochs:\t 788 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1354 - main_Bayes_output_state_loss: 1.3814 - main_Bayes_output_reward_loss: 12.9578 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.1433\n",
      "Boot_Epochs:\t 789 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0202 - main_Bayes_output_state_loss: 1.2779 - main_Bayes_output_reward_loss: 2.0499 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 0.9019\n",
      "Boot_Epochs:\t 790 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1078 - main_Bayes_output_state_loss: 1.3564 - main_Bayes_output_reward_loss: 11.4157 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.2128\n",
      "Boot_Epochs:\t 791 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2187 - main_Bayes_output_state_loss: 1.3663 - main_Bayes_output_reward_loss: 112.8403 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.3943\n",
      "Boot_Epochs:\t 792 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0410 - main_Bayes_output_state_loss: 1.3012 - main_Bayes_output_reward_loss: 1.5308 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 0.8912\n",
      "Boot_Epochs:\t 793 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0482 - main_Bayes_output_state_loss: 1.2798 - main_Bayes_output_reward_loss: 30.2355 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.6015\n",
      "Boot_Epochs:\t 794 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1682 - main_Bayes_output_state_loss: 1.3657 - main_Bayes_output_reward_loss: 63.6090 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.9927\n",
      "Boot_Epochs:\t 795 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2817 - main_Bayes_output_state_loss: 1.4003 - main_Bayes_output_reward_loss: 144.2861 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.5890\n",
      "Boot_Epochs:\t 796 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3861 - main_Bayes_output_state_loss: 1.5474 - main_Bayes_output_reward_loss: 101.6259 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 2.3529\n",
      "Boot_Epochs:\t 797 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1071 - main_Bayes_output_state_loss: 1.3519 - main_Bayes_output_reward_loss: 17.2364 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.1527\n",
      "Boot_Epochs:\t 798 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0914 - main_Bayes_output_state_loss: 1.3553 - main_Bayes_output_reward_loss: 1.6819 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.8933\n",
      "Boot_Epochs:\t 799 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0643 - main_Bayes_output_state_loss: 1.2293 - main_Bayes_output_reward_loss: 99.1265 - main_Bayes_output_state_categorical_accuracy: 0.5758 - main_Bayes_output_reward_mean_absolute_error: 1.7933\n",
      "Boot_Epochs:\t 800 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3841 - main_Bayes_output_state_loss: 1.5347 - main_Bayes_output_reward_loss: 112.9134 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 2.2663\n",
      "Boot_Epochs:\t 801 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1642 - main_Bayes_output_state_loss: 1.2782 - main_Bayes_output_reward_loss: 149.6468 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 3.1864\n",
      "Boot_Epochs:\t 802 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3826 - main_Bayes_output_state_loss: 1.4029 - main_Bayes_output_reward_loss: 244.9872 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 3.6189\n",
      "Boot_Epochs:\t 803 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2112 - main_Bayes_output_state_loss: 1.4514 - main_Bayes_output_reward_loss: 25.5025 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.2560\n",
      "Boot_Epochs:\t 804 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1974 - main_Bayes_output_state_loss: 1.3304 - main_Bayes_output_reward_loss: 132.7694 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 2.7992\n",
      "Boot_Epochs:\t 805 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1373 - main_Bayes_output_state_loss: 1.3556 - main_Bayes_output_reward_loss: 47.8502 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.5851\n",
      "Boot_Epochs:\t 806 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1872 - main_Bayes_output_state_loss: 1.3684 - main_Bayes_output_reward_loss: 84.9563 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.0449\n",
      "Boot_Epochs:\t 807 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2141 - main_Bayes_output_state_loss: 1.3567 - main_Bayes_output_reward_loss: 122.0070 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.3012\n",
      "Boot_Epochs:\t 808 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0622 - main_Bayes_output_state_loss: 1.3248 - main_Bayes_output_reward_loss: 1.9257 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 0.9294\n",
      "Boot_Epochs:\t 809 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1257 - main_Bayes_output_state_loss: 1.3573 - main_Bayes_output_reward_loss: 31.4157 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.4075\n",
      "Boot_Epochs:\t 810 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1018 - main_Bayes_output_state_loss: 1.3624 - main_Bayes_output_reward_loss: 5.2160 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.1266\n",
      "Boot_Epochs:\t 811 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1312 - main_Bayes_output_state_loss: 1.3939 - main_Bayes_output_reward_loss: 3.3943 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.0240\n",
      "Boot_Epochs:\t 812 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2541 - main_Bayes_output_state_loss: 1.3787 - main_Bayes_output_reward_loss: 141.4346 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 2.6853\n",
      "Boot_Epochs:\t 813 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1568 - main_Bayes_output_state_loss: 1.2971 - main_Bayes_output_reward_loss: 126.1656 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 2.3964\n",
      "Boot_Epochs:\t 814 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0359 - main_Bayes_output_state_loss: 1.2996 - main_Bayes_output_reward_loss: 2.2247 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 0.9992\n",
      "Boot_Epochs:\t 815 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0332 - main_Bayes_output_state_loss: 1.2979 - main_Bayes_output_reward_loss: 1.5189 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 0.8436\n",
      "Boot_Epochs:\t 816 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1230 - main_Bayes_output_state_loss: 1.3727 - main_Bayes_output_reward_loss: 15.6365 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.2958\n",
      "Boot_Epochs:\t 817 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0334 - main_Bayes_output_state_loss: 1.2957 - main_Bayes_output_reward_loss: 1.9083 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 0.8846\n",
      "Boot_Epochs:\t 818 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0243 - main_Bayes_output_state_loss: 1.2827 - main_Bayes_output_reward_loss: 8.0314 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.1944\n",
      "Boot_Epochs:\t 819 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1695 - main_Bayes_output_state_loss: 1.4228 - main_Bayes_output_reward_loss: 13.3073 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.4389\n",
      "Boot_Epochs:\t 820 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9912 - main_Bayes_output_state_loss: 1.2562 - main_Bayes_output_reward_loss: 1.1021 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.8220\n",
      "Boot_Epochs:\t 821 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0822 - main_Bayes_output_state_loss: 1.3432 - main_Bayes_output_reward_loss: 5.0989 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.9974\n",
      "Boot_Epochs:\t 822 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0915 - main_Bayes_output_state_loss: 1.3356 - main_Bayes_output_reward_loss: 21.8358 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.3606\n",
      "Boot_Epochs:\t 823 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0656 - main_Bayes_output_state_loss: 1.2878 - main_Bayes_output_reward_loss: 43.9647 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.5967\n",
      "Boot_Epochs:\t 824 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1707 - main_Bayes_output_state_loss: 1.3055 - main_Bayes_output_reward_loss: 132.0532 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 3.0688\n",
      "Boot_Epochs:\t 825 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0135 - main_Bayes_output_state_loss: 1.2781 - main_Bayes_output_reward_loss: 1.7904 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.8679\n",
      "Boot_Epochs:\t 826 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1704 - main_Bayes_output_state_loss: 1.2836 - main_Bayes_output_reward_loss: 153.3606 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 2.2146\n",
      "Boot_Epochs:\t 827 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0860 - main_Bayes_output_state_loss: 1.2784 - main_Bayes_output_reward_loss: 72.4589 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.2412\n",
      "Boot_Epochs:\t 828 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0727 - main_Bayes_output_state_loss: 1.3340 - main_Bayes_output_reward_loss: 3.4785 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.0456\n",
      "Boot_Epochs:\t 829 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0732 - main_Bayes_output_state_loss: 1.3388 - main_Bayes_output_reward_loss: 1.2226 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.7840\n",
      "Boot_Epochs:\t 830 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0717 - main_Bayes_output_state_loss: 1.3325 - main_Bayes_output_reward_loss: 5.7043 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.1117\n",
      "Boot_Epochs:\t 831 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0551 - main_Bayes_output_state_loss: 1.3194 - main_Bayes_output_reward_loss: 0.8804 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.7412\n",
      "Boot_Epochs:\t 832 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2261 - main_Bayes_output_state_loss: 1.3761 - main_Bayes_output_reward_loss: 116.3941 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.6308\n",
      "Boot_Epochs:\t 833 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0612 - main_Bayes_output_state_loss: 1.3208 - main_Bayes_output_reward_loss: 7.1099 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.1250\n",
      "Boot_Epochs:\t 834 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0810 - main_Bayes_output_state_loss: 1.2487 - main_Bayes_output_reward_loss: 97.3726 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 2.2466\n",
      "Boot_Epochs:\t 835 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1584 - main_Bayes_output_state_loss: 1.4239 - main_Bayes_output_reward_loss: 0.9370 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 0.7857\n",
      "Boot_Epochs:\t 836 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0216 - main_Bayes_output_state_loss: 1.2860 - main_Bayes_output_reward_loss: 1.6272 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 0.8224\n",
      "Boot_Epochs:\t 837 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1764 - main_Bayes_output_state_loss: 1.4060 - main_Bayes_output_reward_loss: 35.3899 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 1.3883\n",
      "Boot_Epochs:\t 838 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1178 - main_Bayes_output_state_loss: 1.2719 - main_Bayes_output_reward_loss: 109.5173 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.1551\n",
      "Boot_Epochs:\t 839 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0577 - main_Bayes_output_state_loss: 1.2881 - main_Bayes_output_reward_loss: 35.8033 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.7159\n",
      "Boot_Epochs:\t 840 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2858 - main_Bayes_output_state_loss: 1.4442 - main_Bayes_output_reward_loss: 108.0238 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 2.2098\n",
      "Boot_Epochs:\t 841 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1537 - main_Bayes_output_state_loss: 1.3156 - main_Bayes_output_reward_loss: 104.3911 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.7452\n",
      "Boot_Epochs:\t 842 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1103 - main_Bayes_output_state_loss: 1.3751 - main_Bayes_output_reward_loss: 1.2138 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.8030\n",
      "Boot_Epochs:\t 843 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0811 - main_Bayes_output_state_loss: 1.3071 - main_Bayes_output_reward_loss: 38.5637 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.5633\n",
      "Boot_Epochs:\t 844 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1178 - main_Bayes_output_state_loss: 1.3090 - main_Bayes_output_reward_loss: 75.1011 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.0305\n",
      "Boot_Epochs:\t 845 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1853 - main_Bayes_output_state_loss: 1.4010 - main_Bayes_output_reward_loss: 51.5484 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.8833\n",
      "Boot_Epochs:\t 846 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0196 - main_Bayes_output_state_loss: 1.2787 - main_Bayes_output_reward_loss: 7.8619 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.2549\n",
      "Boot_Epochs:\t 847 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1547 - main_Bayes_output_state_loss: 1.4094 - main_Bayes_output_reward_loss: 10.1548 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.1997\n",
      "Boot_Epochs:\t 848 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3827 - main_Bayes_output_state_loss: 1.4590 - main_Bayes_output_reward_loss: 189.5003 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 3.4119\n",
      "Boot_Epochs:\t 849 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0972 - main_Bayes_output_state_loss: 1.2619 - main_Bayes_output_reward_loss: 101.6029 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 2.5501\n",
      "Boot_Epochs:\t 850 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2848 - main_Bayes_output_state_loss: 1.3956 - main_Bayes_output_reward_loss: 153.1885 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.8057\n",
      "Boot_Epochs:\t 851 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0722 - main_Bayes_output_state_loss: 1.3351 - main_Bayes_output_reward_loss: 3.4996 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.9283\n",
      "Boot_Epochs:\t 852 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0598 - main_Bayes_output_state_loss: 1.3245 - main_Bayes_output_reward_loss: 1.0990 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.7857\n",
      "Boot_Epochs:\t 853 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0445 - main_Bayes_output_state_loss: 1.3036 - main_Bayes_output_reward_loss: 6.2312 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.0658\n",
      "Boot_Epochs:\t 854 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1693 - main_Bayes_output_state_loss: 1.2795 - main_Bayes_output_reward_loss: 155.9831 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.5405\n",
      "Boot_Epochs:\t 855 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2164 - main_Bayes_output_state_loss: 1.3734 - main_Bayes_output_reward_loss: 108.9860 - main_Bayes_output_state_categorical_accuracy: 0.3636 - main_Bayes_output_reward_mean_absolute_error: 2.5318\n",
      "Boot_Epochs:\t 856 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0111 - main_Bayes_output_state_loss: 1.2727 - main_Bayes_output_reward_loss: 4.5104 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.1373\n",
      "Boot_Epochs:\t 857 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1341 - main_Bayes_output_state_loss: 1.3415 - main_Bayes_output_reward_loss: 59.4322 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.8817\n",
      "Boot_Epochs:\t 858 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0324 - main_Bayes_output_state_loss: 1.2982 - main_Bayes_output_reward_loss: 0.8790 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 0.7596\n",
      "Boot_Epochs:\t 859 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0853 - main_Bayes_output_state_loss: 1.2806 - main_Bayes_output_reward_loss: 71.7527 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 2.0123\n",
      "Boot_Epochs:\t 860 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1463 - main_Bayes_output_state_loss: 1.3647 - main_Bayes_output_reward_loss: 49.6620 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.5056\n",
      "Boot_Epochs:\t 861 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0054 - main_Bayes_output_state_loss: 1.2468 - main_Bayes_output_reward_loss: 24.3234 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.4185\n",
      "Boot_Epochs:\t 862 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2798 - main_Bayes_output_state_loss: 1.3043 - main_Bayes_output_reward_loss: 244.1892 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 3.9780\n",
      "Boot_Epochs:\t 863 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0719 - main_Bayes_output_state_loss: 1.3323 - main_Bayes_output_reward_loss: 8.0102 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.9935\n",
      "Boot_Epochs:\t 864 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0717 - main_Bayes_output_state_loss: 1.3382 - main_Bayes_output_reward_loss: 2.4302 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 0.8520\n",
      "Boot_Epochs:\t 865 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0749 - main_Bayes_output_state_loss: 1.3273 - main_Bayes_output_reward_loss: 15.9017 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.1305\n",
      "Boot_Epochs:\t 866 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1702 - main_Bayes_output_state_loss: 1.4012 - main_Bayes_output_reward_loss: 37.9984 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.6144\n",
      "Boot_Epochs:\t 867 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1521 - main_Bayes_output_state_loss: 1.2947 - main_Bayes_output_reward_loss: 126.0303 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 2.4271\n",
      "Boot_Epochs:\t 868 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0820 - main_Bayes_output_state_loss: 1.2904 - main_Bayes_output_reward_loss: 60.0918 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 2.0906\n",
      "Boot_Epochs:\t 869 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0775 - main_Bayes_output_state_loss: 1.3273 - main_Bayes_output_reward_loss: 19.2132 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.2157\n",
      "Boot_Epochs:\t 870 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1688 - main_Bayes_output_state_loss: 1.3628 - main_Bayes_output_reward_loss: 75.4245 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 1.7305\n",
      "Boot_Epochs:\t 871 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1256 - main_Bayes_output_state_loss: 1.3385 - main_Bayes_output_reward_loss: 56.8569 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 1.8140\n",
      "Boot_Epochs:\t 872 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0454 - main_Bayes_output_state_loss: 1.3142 - main_Bayes_output_reward_loss: 0.9884 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.7877\n",
      "Boot_Epochs:\t 873 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9223 - main_Bayes_output_state_loss: 1.1903 - main_Bayes_output_reward_loss: 0.9954 - main_Bayes_output_state_categorical_accuracy: 0.5758 - main_Bayes_output_reward_mean_absolute_error: 0.8003\n",
      "Boot_Epochs:\t 874 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1553 - main_Bayes_output_state_loss: 1.3242 - main_Bayes_output_reward_loss: 99.5346 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.0795\n",
      "Boot_Epochs:\t 875 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1257 - main_Bayes_output_state_loss: 1.2285 - main_Bayes_output_reward_loss: 166.2332 - main_Bayes_output_state_categorical_accuracy: 0.5556 - main_Bayes_output_reward_mean_absolute_error: 2.9507\n",
      "Boot_Epochs:\t 876 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0480 - main_Bayes_output_state_loss: 1.3044 - main_Bayes_output_reward_loss: 13.7248 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.3262\n",
      "Boot_Epochs:\t 877 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9676 - main_Bayes_output_state_loss: 1.2344 - main_Bayes_output_reward_loss: 1.5512 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.8830\n",
      "Boot_Epochs:\t 878 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9897 - main_Bayes_output_state_loss: 1.2527 - main_Bayes_output_reward_loss: 7.0912 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.1119\n",
      "Boot_Epochs:\t 879 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0887 - main_Bayes_output_state_loss: 1.3448 - main_Bayes_output_reward_loss: 13.2207 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.2257\n",
      "Boot_Epochs:\t 880 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1606 - main_Bayes_output_state_loss: 1.3413 - main_Bayes_output_reward_loss: 89.1655 - main_Bayes_output_state_categorical_accuracy: 0.5455 - main_Bayes_output_reward_mean_absolute_error: 2.4948\n",
      "Boot_Epochs:\t 881 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0708 - main_Bayes_output_state_loss: 1.3395 - main_Bayes_output_reward_loss: 1.2327 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.8176\n",
      "Boot_Epochs:\t 882 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0785 - main_Bayes_output_state_loss: 1.2738 - main_Bayes_output_reward_loss: 74.7349 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 2.0977\n",
      "Boot_Epochs:\t 883 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0497 - main_Bayes_output_state_loss: 1.2714 - main_Bayes_output_reward_loss: 48.3478 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.6859\n",
      "Boot_Epochs:\t 884 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0541 - main_Bayes_output_state_loss: 1.3207 - main_Bayes_output_reward_loss: 3.1020 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.9193\n",
      "Boot_Epochs:\t 885 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1274 - main_Bayes_output_state_loss: 1.3368 - main_Bayes_output_reward_loss: 60.5367 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.0364\n",
      "Boot_Epochs:\t 886 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1415 - main_Bayes_output_state_loss: 1.3525 - main_Bayes_output_reward_loss: 59.2065 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.8231\n",
      "Boot_Epochs:\t 887 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1641 - main_Bayes_output_state_loss: 1.3897 - main_Bayes_output_reward_loss: 44.0699 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.5074\n",
      "Boot_Epochs:\t 888 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0708 - main_Bayes_output_state_loss: 1.2975 - main_Bayes_output_reward_loss: 44.0156 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.5279\n",
      "Boot_Epochs:\t 889 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9424 - main_Bayes_output_state_loss: 1.1753 - main_Bayes_output_reward_loss: 37.8129 - main_Bayes_output_state_categorical_accuracy: 0.5455 - main_Bayes_output_reward_mean_absolute_error: 1.8366\n",
      "Boot_Epochs:\t 890 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9617 - main_Bayes_output_state_loss: 1.2040 - main_Bayes_output_reward_loss: 28.1174 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.5288\n",
      "Boot_Epochs:\t 891 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1638 - main_Bayes_output_state_loss: 1.3463 - main_Bayes_output_reward_loss: 88.0751 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.1167\n",
      "Boot_Epochs:\t 892 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0444 - main_Bayes_output_state_loss: 1.2299 - main_Bayes_output_reward_loss: 83.9431 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.2648\n",
      "Boot_Epochs:\t 893 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0329 - main_Bayes_output_state_loss: 1.2781 - main_Bayes_output_reward_loss: 24.0406 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.4076\n",
      "Boot_Epochs:\t 894 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0442 - main_Bayes_output_state_loss: 1.2447 - main_Bayes_output_reward_loss: 70.3915 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 2.1771\n",
      "Boot_Epochs:\t 895 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0208 - main_Bayes_output_state_loss: 1.2875 - main_Bayes_output_reward_loss: 4.3596 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.1058\n",
      "Boot_Epochs:\t 896 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1052 - main_Bayes_output_state_loss: 1.3617 - main_Bayes_output_reward_loss: 15.1787 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.2852\n",
      "Boot_Epochs:\t 897 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0857 - main_Bayes_output_state_loss: 1.3571 - main_Bayes_output_reward_loss: 1.2239 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 0.8320\n",
      "Boot_Epochs:\t 898 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9609 - main_Bayes_output_state_loss: 1.2197 - main_Bayes_output_reward_loss: 12.8743 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.1506\n",
      "Boot_Epochs:\t 899 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1798 - main_Bayes_output_state_loss: 1.3112 - main_Bayes_output_reward_loss: 141.2872 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.7943\n",
      "Boot_Epochs:\t 900 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1313 - main_Bayes_output_state_loss: 1.3874 - main_Bayes_output_reward_loss: 17.2676 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.4163\n",
      "Boot_Epochs:\t 901 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1097 - main_Bayes_output_state_loss: 1.3183 - main_Bayes_output_reward_loss: 64.2045 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.7968\n",
      "Boot_Epochs:\t 902 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0001 - main_Bayes_output_state_loss: 1.2711 - main_Bayes_output_reward_loss: 1.0412 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 0.8113\n",
      "Boot_Epochs:\t 903 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1063 - main_Bayes_output_state_loss: 1.3689 - main_Bayes_output_reward_loss: 9.2572 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.1972\n",
      "Boot_Epochs:\t 904 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2360 - main_Bayes_output_state_loss: 1.4540 - main_Bayes_output_reward_loss: 54.1710 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.7216\n",
      "Boot_Epochs:\t 905 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0270 - main_Bayes_output_state_loss: 1.2900 - main_Bayes_output_reward_loss: 10.4037 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.3074\n",
      "Boot_Epochs:\t 906 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0923 - main_Bayes_output_state_loss: 1.3057 - main_Bayes_output_reward_loss: 61.9887 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.8504\n",
      "Boot_Epochs:\t 907 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3186 - main_Bayes_output_state_loss: 1.4236 - main_Bayes_output_reward_loss: 170.4725 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 3.6798\n",
      "Boot_Epochs:\t 908 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1320 - main_Bayes_output_state_loss: 1.3108 - main_Bayes_output_reward_loss: 94.2669 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.0968\n",
      "Boot_Epochs:\t 909 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1445 - main_Bayes_output_state_loss: 1.3591 - main_Bayes_output_reward_loss: 60.6304 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.9152\n",
      "Boot_Epochs:\t 910 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0382 - main_Bayes_output_state_loss: 1.3126 - main_Bayes_output_reward_loss: 0.8275 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.7389\n",
      "Boot_Epochs:\t 911 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0028 - main_Bayes_output_state_loss: 1.2765 - main_Bayes_output_reward_loss: 1.9420 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 0.9243\n",
      "Boot_Epochs:\t 912 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0666 - main_Bayes_output_state_loss: 1.3215 - main_Bayes_output_reward_loss: 21.5014 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.4253\n",
      "Boot_Epochs:\t 913 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0754 - main_Bayes_output_state_loss: 1.3180 - main_Bayes_output_reward_loss: 33.2772 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.5736\n",
      "Boot_Epochs:\t 914 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1736 - main_Bayes_output_state_loss: 1.3315 - main_Bayes_output_reward_loss: 117.6419 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.3040\n",
      "Boot_Epochs:\t 915 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1594 - main_Bayes_output_state_loss: 1.4318 - main_Bayes_output_reward_loss: 3.9425 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.9244\n",
      "Boot_Epochs:\t 916 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2454 - main_Bayes_output_state_loss: 1.4211 - main_Bayes_output_reward_loss: 99.5023 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.8541\n",
      "Boot_Epochs:\t 917 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1346 - main_Bayes_output_state_loss: 1.3216 - main_Bayes_output_reward_loss: 89.2002 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.9331\n",
      "Boot_Epochs:\t 918 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1711 - main_Bayes_output_state_loss: 1.3741 - main_Bayes_output_reward_loss: 72.9681 - main_Bayes_output_state_categorical_accuracy: 0.4141 - main_Bayes_output_reward_mean_absolute_error: 2.2093\n",
      "Boot_Epochs:\t 919 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2567 - main_Bayes_output_state_loss: 1.3780 - main_Bayes_output_reward_loss: 153.5619 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 3.0834\n",
      "Boot_Epochs:\t 920 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1515 - main_Bayes_output_state_loss: 1.3758 - main_Bayes_output_reward_loss: 50.8013 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.6930\n",
      "Boot_Epochs:\t 921 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1043 - main_Bayes_output_state_loss: 1.3420 - main_Bayes_output_reward_loss: 38.4031 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.9558\n",
      "Boot_Epochs:\t 922 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2042 - main_Bayes_output_state_loss: 1.4782 - main_Bayes_output_reward_loss: 2.2636 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.9188\n",
      "Boot_Epochs:\t 923 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0634 - main_Bayes_output_state_loss: 1.2936 - main_Bayes_output_reward_loss: 45.8238 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.4534\n",
      "Boot_Epochs:\t 924 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1764 - main_Bayes_output_state_loss: 1.4017 - main_Bayes_output_reward_loss: 50.0338 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.5787\n",
      "Boot_Epochs:\t 925 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1098 - main_Bayes_output_state_loss: 1.3418 - main_Bayes_output_reward_loss: 43.9728 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.5561\n",
      "Boot_Epochs:\t 926 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1554 - main_Bayes_output_state_loss: 1.3633 - main_Bayes_output_reward_loss: 68.2086 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.1251\n",
      "Boot_Epochs:\t 927 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1296 - main_Bayes_output_state_loss: 1.2497 - main_Bayes_output_reward_loss: 154.9416 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 2.8903\n",
      "Boot_Epochs:\t 928 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1060 - main_Bayes_output_state_loss: 1.3059 - main_Bayes_output_reward_loss: 76.5084 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 2.2466\n",
      "Boot_Epochs:\t 929 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2547 - main_Bayes_output_state_loss: 1.3704 - main_Bayes_output_reward_loss: 159.1484 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.7754\n",
      "Boot_Epochs:\t 930 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1219 - main_Bayes_output_state_loss: 1.3408 - main_Bayes_output_reward_loss: 57.3409 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.5667\n",
      "Boot_Epochs:\t 931 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3106 - main_Bayes_output_state_loss: 1.3392 - main_Bayes_output_reward_loss: 246.8036 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 4.1548\n",
      "Boot_Epochs:\t 932 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0680 - main_Bayes_output_state_loss: 1.3002 - main_Bayes_output_reward_loss: 42.8211 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 1.7140\n",
      "Boot_Epochs:\t 933 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1393 - main_Bayes_output_state_loss: 1.3582 - main_Bayes_output_reward_loss: 56.4349 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.9941\n",
      "Boot_Epochs:\t 934 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1070 - main_Bayes_output_state_loss: 1.3795 - main_Bayes_output_reward_loss: 2.9940 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 0.9772\n",
      "Boot_Epochs:\t 935 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1620 - main_Bayes_output_state_loss: 1.4333 - main_Bayes_output_reward_loss: 3.6163 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 0.8873\n",
      "Boot_Epochs:\t 936 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0393 - main_Bayes_output_state_loss: 1.2149 - main_Bayes_output_reward_loss: 100.1216 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 2.1026\n",
      "Boot_Epochs:\t 937 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1316 - main_Bayes_output_state_loss: 1.3353 - main_Bayes_output_reward_loss: 72.0209 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.9171\n",
      "Boot_Epochs:\t 938 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2306 - main_Bayes_output_state_loss: 1.3573 - main_Bayes_output_reward_loss: 149.5338 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 2.6925\n",
      "Boot_Epochs:\t 939 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0718 - main_Bayes_output_state_loss: 1.3154 - main_Bayes_output_reward_loss: 31.3871 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.4882\n",
      "Boot_Epochs:\t 940 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1446 - main_Bayes_output_state_loss: 1.4194 - main_Bayes_output_reward_loss: 1.2426 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 0.8018\n",
      "Boot_Epochs:\t 941 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0837 - main_Bayes_output_state_loss: 1.3257 - main_Bayes_output_reward_loss: 32.5626 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.3192\n",
      "Boot_Epochs:\t 942 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1653 - main_Bayes_output_state_loss: 1.3761 - main_Bayes_output_reward_loss: 65.0671 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 2.0347\n",
      "Boot_Epochs:\t 943 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1883 - main_Bayes_output_state_loss: 1.3385 - main_Bayes_output_reward_loss: 126.1312 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 2.9017\n",
      "Boot_Epochs:\t 944 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1812 - main_Bayes_output_state_loss: 1.3874 - main_Bayes_output_reward_loss: 68.3794 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.9723\n",
      "Boot_Epochs:\t 945 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2139 - main_Bayes_output_state_loss: 1.4397 - main_Bayes_output_reward_loss: 49.5546 - main_Bayes_output_state_categorical_accuracy: 0.4242 - main_Bayes_output_reward_mean_absolute_error: 1.5851\n",
      "Boot_Epochs:\t 946 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1809 - main_Bayes_output_state_loss: 1.4374 - main_Bayes_output_reward_loss: 18.5126 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.3418\n",
      "Boot_Epochs:\t 947 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1789 - main_Bayes_output_state_loss: 1.3000 - main_Bayes_output_reward_loss: 153.1211 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 2.8278\n",
      "Boot_Epochs:\t 948 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1358 - main_Bayes_output_state_loss: 1.3633 - main_Bayes_output_reward_loss: 48.3860 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.6836\n",
      "Boot_Epochs:\t 949 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0325 - main_Bayes_output_state_loss: 1.3068 - main_Bayes_output_reward_loss: 1.4485 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 0.8541\n",
      "Boot_Epochs:\t 950 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0554 - main_Bayes_output_state_loss: 1.3281 - main_Bayes_output_reward_loss: 2.1102 - main_Bayes_output_state_categorical_accuracy: 0.5051 - main_Bayes_output_reward_mean_absolute_error: 0.9399\n",
      "Boot_Epochs:\t 951 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0726 - main_Bayes_output_state_loss: 1.3480 - main_Bayes_output_reward_loss: 0.9550 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 0.7387\n",
      "Boot_Epochs:\t 952 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2956 - main_Bayes_output_state_loss: 1.3835 - main_Bayes_output_reward_loss: 188.6910 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 3.2420\n",
      "Boot_Epochs:\t 953 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1978 - main_Bayes_output_state_loss: 1.2929 - main_Bayes_output_reward_loss: 180.5241 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 2.8639\n",
      "Boot_Epochs:\t 954 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0604 - main_Bayes_output_state_loss: 1.2833 - main_Bayes_output_reward_loss: 54.3601 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.7440\n",
      "Boot_Epochs:\t 955 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1532 - main_Bayes_output_state_loss: 1.3957 - main_Bayes_output_reward_loss: 33.2257 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.3887\n",
      "Boot_Epochs:\t 956 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1045 - main_Bayes_output_state_loss: 1.3798 - main_Bayes_output_reward_loss: 2.7052 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 0.9161\n",
      "Boot_Epochs:\t 957 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1568 - main_Bayes_output_state_loss: 1.3755 - main_Bayes_output_reward_loss: 57.9188 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 1.9644\n",
      "Boot_Epochs:\t 958 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1249 - main_Bayes_output_state_loss: 1.3732 - main_Bayes_output_reward_loss: 29.5550 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.4367\n",
      "Boot_Epochs:\t 959 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0476 - main_Bayes_output_state_loss: 1.3205 - main_Bayes_output_reward_loss: 7.2367 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.0524\n",
      "Boot_Epochs:\t 960 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.9772 - main_Bayes_output_state_loss: 1.2239 - main_Bayes_output_reward_loss: 33.0563 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 1.6072\n",
      "Boot_Epochs:\t 961 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2369 - main_Bayes_output_state_loss: 1.4573 - main_Bayes_output_reward_loss: 60.7090 - main_Bayes_output_state_categorical_accuracy: 0.4444 - main_Bayes_output_reward_mean_absolute_error: 1.9878\n",
      "Boot_Epochs:\t 962 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0074 - main_Bayes_output_state_loss: 1.2070 - main_Bayes_output_reward_loss: 81.5252 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 2.2209\n",
      "Boot_Epochs:\t 963 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1509 - main_Bayes_output_state_loss: 1.3919 - main_Bayes_output_reward_loss: 38.7177 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.0814\n",
      "Boot_Epochs:\t 964 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2679 - main_Bayes_output_state_loss: 1.4371 - main_Bayes_output_reward_loss: 112.3836 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.4581\n",
      "Boot_Epochs:\t 965 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0640 - main_Bayes_output_state_loss: 1.3438 - main_Bayes_output_reward_loss: 2.1118 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 0.8796\n",
      "Boot_Epochs:\t 966 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1356 - main_Bayes_output_state_loss: 1.3558 - main_Bayes_output_reward_loss: 61.1004 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.1669\n",
      "Boot_Epochs:\t 967 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0454 - main_Bayes_output_state_loss: 1.2299 - main_Bayes_output_reward_loss: 100.1371 - main_Bayes_output_state_categorical_accuracy: 0.5354 - main_Bayes_output_reward_mean_absolute_error: 1.7272\n",
      "Boot_Epochs:\t 968 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1727 - main_Bayes_output_state_loss: 1.4267 - main_Bayes_output_reward_loss: 27.6748 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.5192\n",
      "Boot_Epochs:\t 969 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0441 - main_Bayes_output_state_loss: 1.2736 - main_Bayes_output_reward_loss: 53.1370 - main_Bayes_output_state_categorical_accuracy: 0.5253 - main_Bayes_output_reward_mean_absolute_error: 1.9603\n",
      "Boot_Epochs:\t 970 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2982 - main_Bayes_output_state_loss: 1.4105 - main_Bayes_output_reward_loss: 168.4306 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 3.1751\n",
      "Boot_Epochs:\t 971 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2178 - main_Bayes_output_state_loss: 1.3860 - main_Bayes_output_reward_loss: 114.3425 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 2.6563\n",
      "Boot_Epochs:\t 972 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2241 - main_Bayes_output_state_loss: 1.4751 - main_Bayes_output_reward_loss: 32.5413 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.8023\n",
      "Boot_Epochs:\t 973 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2234 - main_Bayes_output_state_loss: 1.4134 - main_Bayes_output_reward_loss: 91.4235 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.3654\n",
      "Boot_Epochs:\t 974 / 1000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2617 - main_Bayes_output_state_loss: 1.4971 - main_Bayes_output_reward_loss: 50.9204 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.2858\n",
      "Boot_Epochs:\t 975 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4340 - main_Bayes_output_state_loss: 1.5178 - main_Bayes_output_reward_loss: 198.4160 - main_Bayes_output_state_categorical_accuracy: 0.4848 - main_Bayes_output_reward_mean_absolute_error: 3.5656\n",
      "Boot_Epochs:\t 976 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1924 - main_Bayes_output_state_loss: 1.3796 - main_Bayes_output_reward_loss: 95.1794 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 2.6455\n",
      "Boot_Epochs:\t 977 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1843 - main_Bayes_output_state_loss: 1.4243 - main_Bayes_output_reward_loss: 44.2582 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 1.4792\n",
      "Boot_Epochs:\t 978 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2263 - main_Bayes_output_state_loss: 1.4710 - main_Bayes_output_reward_loss: 40.8303 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.9151\n",
      "Boot_Epochs:\t 979 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1624 - main_Bayes_output_state_loss: 1.2973 - main_Bayes_output_reward_loss: 148.5581 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 2.9610\n",
      "Boot_Epochs:\t 980 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2093 - main_Bayes_output_state_loss: 1.4793 - main_Bayes_output_reward_loss: 15.1299 - main_Bayes_output_state_categorical_accuracy: 0.4040 - main_Bayes_output_reward_mean_absolute_error: 1.3903\n",
      "Boot_Epochs:\t 981 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0750 - main_Bayes_output_state_loss: 1.3312 - main_Bayes_output_reward_loss: 28.1454 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.4633\n",
      "Boot_Epochs:\t 982 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1485 - main_Bayes_output_state_loss: 1.3824 - main_Bayes_output_reward_loss: 50.1400 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 1.8738\n",
      "Boot_Epochs:\t 983 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0800 - main_Bayes_output_state_loss: 1.3623 - main_Bayes_output_reward_loss: 2.8061 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 0.9566\n",
      "Boot_Epochs:\t 984 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1456 - main_Bayes_output_state_loss: 1.3502 - main_Bayes_output_reward_loss: 80.2994 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 2.2512\n",
      "Boot_Epochs:\t 985 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2758 - main_Bayes_output_state_loss: 1.3384 - main_Bayes_output_reward_loss: 223.2357 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 3.6880\n",
      "Boot_Epochs:\t 986 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0780 - main_Bayes_output_state_loss: 1.2605 - main_Bayes_output_reward_loss: 101.7231 - main_Bayes_output_state_categorical_accuracy: 0.5455 - main_Bayes_output_reward_mean_absolute_error: 2.1979\n",
      "Boot_Epochs:\t 987 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1924 - main_Bayes_output_state_loss: 1.3748 - main_Bayes_output_reward_loss: 102.9227 - main_Bayes_output_state_categorical_accuracy: 0.5152 - main_Bayes_output_reward_mean_absolute_error: 3.4847\n",
      "Boot_Epochs:\t 988 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1872 - main_Bayes_output_state_loss: 1.4365 - main_Bayes_output_reward_loss: 36.7517 - main_Bayes_output_state_categorical_accuracy: 0.3838 - main_Bayes_output_reward_mean_absolute_error: 1.4550\n",
      "Boot_Epochs:\t 989 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1066 - main_Bayes_output_state_loss: 1.3754 - main_Bayes_output_reward_loss: 16.0336 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 1.4164\n",
      "Boot_Epochs:\t 990 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2315 - main_Bayes_output_state_loss: 1.4469 - main_Bayes_output_reward_loss: 69.9861 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 2.2010\n",
      "Boot_Epochs:\t 991 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2035 - main_Bayes_output_state_loss: 1.3658 - main_Bayes_output_reward_loss: 123.8188 - main_Bayes_output_state_categorical_accuracy: 0.4646 - main_Bayes_output_reward_mean_absolute_error: 2.5118\n",
      "Boot_Epochs:\t 992 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2135 - main_Bayes_output_state_loss: 1.4428 - main_Bayes_output_reward_loss: 55.7684 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 1.9286\n",
      "Boot_Epochs:\t 993 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2532 - main_Bayes_output_state_loss: 1.5304 - main_Bayes_output_reward_loss: 8.4312 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 1.0896\n",
      "Boot_Epochs:\t 994 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.2334 - main_Bayes_output_state_loss: 1.2746 - main_Bayes_output_reward_loss: 243.6897 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 3.6061\n",
      "Boot_Epochs:\t 995 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.0547 - main_Bayes_output_state_loss: 1.2765 - main_Bayes_output_reward_loss: 63.4688 - main_Bayes_output_state_categorical_accuracy: 0.4949 - main_Bayes_output_reward_mean_absolute_error: 2.2659\n",
      "Boot_Epochs:\t 996 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.4313 - main_Bayes_output_state_loss: 1.4517 - main_Bayes_output_reward_loss: 265.0371 - main_Bayes_output_state_categorical_accuracy: 0.4545 - main_Bayes_output_reward_mean_absolute_error: 4.1547\n",
      "Boot_Epochs:\t 997 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.1258 - main_Bayes_output_state_loss: 1.3732 - main_Bayes_output_reward_loss: 38.1998 - main_Bayes_output_state_categorical_accuracy: 0.4747 - main_Bayes_output_reward_mean_absolute_error: 1.3887\n",
      "Boot_Epochs:\t 998 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.5178 - main_Bayes_output_state_loss: 1.4426 - main_Bayes_output_reward_loss: 360.6621 - main_Bayes_output_state_categorical_accuracy: 0.4343 - main_Bayes_output_reward_mean_absolute_error: 4.9491\n",
      "Boot_Epochs:\t 999 / 1000\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 1.3111 - main_Bayes_output_state_loss: 1.5193 - main_Bayes_output_reward_loss: 75.8144 - main_Bayes_output_state_categorical_accuracy: 0.3939 - main_Bayes_output_reward_mean_absolute_error: 2.2708\n",
      "[[-99.68954    -99.864685    99.62955    -97.47566    -99.74529\n",
      "   95.48462     99.68352     99.8676     -99.30609    -99.0894\n",
      "   98.79223     -1.          99.58374     98.61348    -99.80353\n",
      "  -99.669655    95.84647     99.51935      0.99985456  98.9482\n",
      "  -99.15853     99.40483     99.38494    -99.527794   -98.59039\n",
      "   99.49306     98.506615    99.618675    99.0066     -98.85818\n",
      "  -99.717316   -99.575165    -0.49356472  98.46593    -98.90286\n",
      "   99.78365     99.60479    -99.66302     99.59702     99.32897\n",
      "  -98.92414     -1.          99.38803    -99.639725   -99.46606\n",
      "   98.29958    -98.58253     99.81746    -99.59027      0.9666318\n",
      "   96.37724     99.00267    -99.77774     99.365776     1.\n",
      "   99.73569     99.61923     98.10234     98.41888     99.62874\n",
      "  -99.78342    -99.844955    99.80295     99.31017    -99.68817\n",
      "  -99.25247    -99.83117     99.19214     -0.72829306  99.72517\n",
      "  -99.76951    -98.52182     99.62759     99.54318     98.518524\n",
      "   98.88009    -98.41588     99.78268    -99.5199      98.753845\n",
      "   -1.6456032   97.99318    -99.58566      1.9571214   98.830284\n",
      "  -99.67676     99.76306    -99.89757      0.54643774  99.52469\n",
      "   -0.73061514 -99.719154   -99.2227      99.77042    -99.49015\n",
      "    2.2565389   -0.9284611   99.79721    -99.68316     99.72429   ]] [[-0.08027425 -1.          1.         -0.90658    -0.          0.\n",
      "   0.33596998  1.         -1.         -1.          1.         -0.7615942\n",
      "   0.8786763   1.         -1.         -0.79115736  0.          1.\n",
      "   0.7615331   1.         -0.          0.          0.8100164  -0.\n",
      "  -1.          0.          1.          1.          1.         -0.24094623\n",
      "  -0.16329798 -0.         -0.15991633  1.         -1.          0.\n",
      "   1.         -1.          0.          0.31158745 -1.         -0.7615942\n",
      "   1.         -0.14062771 -0.          1.         -0.          0.\n",
      "  -0.          0.74722046  0.7347654   0.95836866 -1.          0.55200624\n",
      "   0.55102307  0.          0.          1.          1.          0.9029451\n",
      "  -1.         -1.          0.9465667   0.         -0.         -1.\n",
      "  -0.          1.         -0.62202     1.         -0.         -1.\n",
      "   0.          0.          0.5102273   1.         -1.          1.\n",
      "  -0.          1.         -0.92825174  1.         -1.          0.3530177\n",
      "   0.6741127  -0.42078906  0.         -0.          0.49784562  1.\n",
      "  -0.6234416  -1.         -0.          0.8366867  -1.          0.97830856\n",
      "  -0.7298756   0.8647846  -0.          0.2770816 ]]\n",
      "[[-1.0802742  -2.          2.         -1.90658    -1.          1.\n",
      "   1.3359699   2.         -2.         -2.          2.         -1.\n",
      "   1.8786763   2.         -2.         -1.7911574   1.          2.\n",
      "  -1.          2.         -1.          1.          1.8100164  -1.\n",
      "  -2.          1.          2.          2.          2.         -1.2409463\n",
      "  -1.163298   -1.         -1.          2.         -2.          1.\n",
      "   2.         -2.          1.          1.3115875  -2.         -1.\n",
      "   2.         -1.1406277  -1.          2.         -1.          1.\n",
      "  -1.         -1.          1.7347654   1.9583687  -2.          1.5520062\n",
      "   1.          1.          1.          2.          2.          1.902945\n",
      "  -2.         -2.          1.9465667   1.         -1.         -2.\n",
      "  -1.          2.         -1.62202     2.         -1.         -2.\n",
      "   1.          1.          1.5102273   2.         -2.          2.\n",
      "  -1.          2.         -1.9282517   2.         -2.          1.\n",
      "   1.6741127  -1.420789    1.         -1.         -1.          2.\n",
      "   1.         -2.         -1.          1.8366866  -2.          1.\n",
      "   0.27012438  1.8647846  -1.          1.2770816 ]]\n",
      "T 10\n",
      "P 4\n",
      "T [-0.58778325]\n",
      "P [[-0.9980303]]\n",
      "[[-2.0802739  -2.9999993   2.999999   -2.90658    -2.          2.\n",
      "   2.33597     2.9999409  -2.999813   -3.          3.         -0.9990355\n",
      "   2.8786588   3.         -3.         -2.7911572   1.9999926   2.9999754\n",
      "  -0.9998462   3.         -2.          1.9999993   2.81       -1.9999995\n",
      "  -3.          1.9999999   3.          3.          3.         -2.2409463\n",
      "  -2.1632981  -1.9999999  -0.99421513  2.9999962  -3.          1.9999957\n",
      "   2.9999936  -2.9999313   1.9999847   2.311587   -2.9999719  -1.6824409\n",
      "   3.         -2.1406279  -1.9999989   3.         -2.          2.\n",
      "  -1.9999945  -0.99992776  2.7347655   2.9583688  -2.9999993   2.5520062\n",
      "  -0.28232917  1.9999948   1.9999981   2.9999998   3.          2.902945\n",
      "  -2.999991   -3.          2.9465666   2.         -2.         -2.9999995\n",
      "  -2.          3.         -1.8708187   3.         -1.9999998  -2.9999318\n",
      "   2.          1.9999619   2.5102272   2.9999998  -3.          2.9999986\n",
      "  -2.          3.         -2.1464503   3.         -3.          1.5238051\n",
      "   2.6741023  -2.420789    2.         -2.         -0.97539407  3.\n",
      "   1.6106923  -2.9999976  -1.9999776   2.8366857  -2.9999971   1.9784386\n",
      "   1.1435639   2.8647847  -1.9999998   2.2770467 ]]\n",
      "T 6\n",
      "P 6\n",
      "T [-1.66879421]\n",
      "P [[-1.1853436]]\n",
      "[[-3.0802739  -3.9999993   3.999998   -3.90658    -3.          3.\n",
      "   3.33597     3.9999375  -3.9998     -4.          4.         -0.9999667\n",
      "   3.8786511   4.         -4.         -3.7911572   2.999992    3.9999635\n",
      "  -0.99968755  4.         -3.          2.9999993   3.8098824  -2.9999962\n",
      "  -4.          2.9999998   4.          4.          4.         -3.2409463\n",
      "  -3.1632981  -3.         -1.1854903   3.9999957  -3.9999998   2.9999907\n",
      "   3.9999933  -3.9999056   2.9999838   3.311587   -3.9999332  -2.639924\n",
      "   4.         -3.1406274  -2.999999    3.9999988  -3.          3.\n",
      "  -2.9999943  -0.9999405   3.7347655   3.9583688  -3.9999971   3.5520062\n",
      "   0.45259532  2.9999728   2.9999971   3.9999998   4.          3.902945\n",
      "  -3.9999895  -3.9999998   3.946566    3.         -3.         -3.9999962\n",
      "  -3.          3.9999998  -2.8708186   4.         -2.999999   -3.9999251\n",
      "   3.          2.9999368   3.5102262   3.999999   -4.          3.999994\n",
      "  -3.          4.         -2.8309755   4.         -4.          0.993299\n",
      "   3.6740975  -3.420789    2.9999998  -3.         -0.9999932   4.\n",
      "   1.6278249  -3.9999955  -2.9999712   3.8366854  -3.9999924   2.799927\n",
      "   0.8890171   3.8647847  -2.9999995   3.2770317 ]]\n",
      "T 5\n",
      "P 8\n",
      "T [-0.96311349]\n",
      "P [[-0.87845767]]\n",
      "[[-4.0802736  -4.999999    4.9999976  -4.90658    -4.          4.\n",
      "   4.33597     4.9999304  -4.9988923  -5.          5.         -0.9239183\n",
      "   4.878644    5.         -5.         -4.7911572   3.9999917   4.9999313\n",
      "  -0.9999982   5.         -4.          3.999999    4.8098397  -3.9999952\n",
      "  -5.          3.9999995   5.          5.          5.         -4.2409463\n",
      "  -4.163298   -4.         -1.0974221   4.9999957  -4.9999995   3.9999878\n",
      "   4.9999933  -4.99983     3.9999819   4.311587   -4.999931   -2.2464738\n",
      "   5.         -4.1406274  -3.9999986   4.999999   -4.          4.\n",
      "  -3.9999943  -1.732558    4.7347655   4.958369   -4.999995    4.5520062\n",
      "   0.47343034  3.9999366   3.9999938   5.          5.          4.902945\n",
      "  -4.9999733  -4.999999    4.946566    4.         -4.         -4.999989\n",
      "  -4.          5.         -2.5510476   4.9999995  -3.999998   -4.9999247\n",
      "   4.          3.99987     4.5102262   4.999997   -5.          4.9999933\n",
      "  -4.          5.         -2.692722    5.         -5.          0.998753\n",
      "   4.6740966  -4.420789    3.9999998  -4.         -0.869421    5.\n",
      "   1.8952465  -4.9999943  -3.9999413   4.836685   -4.9999886   3.7473636\n",
      "   1.639101    4.8647847  -3.9999995   4.2770133 ]]\n",
      "T 15\n",
      "P 15\n",
      "T [-1.29934994]\n",
      "P [[-0.8779274]]\n",
      "[[-5.0802736  -5.999999    5.999997   -5.90658    -5.          5.\n",
      "   5.33597     5.9999304  -5.9988914  -6.          6.         -1.\n",
      "   5.878641    6.         -6.         -5.7911572   4.9999914   5.9999294\n",
      "   0.9804652   6.         -5.          4.999999    5.8098183  -4.9999948\n",
      "  -5.999999    4.9999995   6.          6.          6.         -5.2409463\n",
      "  -5.163298   -5.         -1.1750253   5.9999957  -5.9999995   4.999986\n",
      "   5.9999914  -5.999803    4.9999733   5.311587   -5.999234   -0.9796407\n",
      "   6.         -5.1406274  -4.9999986   5.999949   -5.          5.\n",
      "  -4.999994    0.1646671   5.7347655   5.958369   -5.9999933   5.5520062\n",
      "   0.88815194  4.9999304   4.9999933   6.          6.          5.9029446\n",
      "  -5.9999733  -5.999999    5.9465647   5.         -4.9999995  -5.999989\n",
      "  -5.          6.         -2.4622264   5.9999995  -4.999998   -5.999924\n",
      "   4.9999976   4.999837    5.5102186   5.999994   -6.          5.9999933\n",
      "  -5.          6.         -2.7796907   6.         -6.          0.9997478\n",
      "   5.6740966  -5.420789    4.999999   -5.         -0.8414881   6.\n",
      "  -0.46909654 -5.99999    -4.999936    5.8366847  -5.9999843   4.7473636\n",
      "   0.45226222  5.8647847  -4.9999986   5.277012  ]]\n",
      "T 13\n",
      "P 11\n",
      "T [100.35202769]\n",
      "P [[101.49465]]\n",
      "[[-6.0802736  -6.999999    6.999997   -6.90658    -6.          6.\n",
      "   6.33597     6.99993    -6.99884    -7.          7.         -0.62802607\n",
      "   6.8786387   7.         -7.         -6.7911572   5.9999914   6.999929\n",
      "  -1.          7.         -6.          5.9999948   6.809816   -5.9999948\n",
      "  -6.999999    5.9999995   7.          7.          7.         -6.2409463\n",
      "  -6.163298   -6.         -0.53184295  6.9999957  -6.9999995   5.9999847\n",
      "   6.999991   -6.9998016   5.9999685   6.311587   -6.999234   -0.9687589\n",
      "   7.         -6.1406274  -5.9999986   6.999949   -6.          6.\n",
      "  -5.999994   -0.9096626   6.7347655   6.958369   -6.9999905   6.5520062\n",
      "   0.50697625  5.9999285   5.999992    7.          7.          6.9029446\n",
      "  -6.999953   -6.9999986   6.9465647   6.         -5.999999   -6.9999886\n",
      "  -6.          7.         -1.3616034   6.9999995  -5.999998   -6.9999156\n",
      "   5.9999976   5.99982     6.5102186   6.9999924  -7.          6.9999924\n",
      "  -6.          7.         -1.9937024   7.         -7.          0.99999976\n",
      "   6.6740966  -6.420789    5.9999986  -6.         -1.          7.\n",
      "   0.88874286 -6.999989   -5.9999304   6.8366847  -6.9999766   5.0832124\n",
      "   1.452261    6.8647847  -5.9999986   6.277012  ]]\n",
      "T 2\n",
      "P 11\n",
      "T [-1.53237124]\n",
      "P [[-0.91403043]]\n",
      "[[-7.0802736  -7.999999    7.999997   -7.90658    -7.          7.\n",
      "   7.33597     7.99993    -7.99884    -8.          8.         -0.99999946\n",
      "   7.8786383   8.         -8.         -7.7911572   6.9999905   7.9999275\n",
      "  -0.99955153  8.         -7.          6.9999948   7.8098154  -6.9999948\n",
      "  -7.999999    6.9999995   8.          8.          8.         -7.2409463\n",
      "  -7.163298   -7.         -1.2779964   7.9999957  -7.9999995   6.9999847\n",
      "   7.9999905  -7.9997997   6.9999685   7.3115845  -7.999234   -1.3934815\n",
      "   8.         -7.1406274  -6.9999986   7.999949   -7.          7.\n",
      "  -6.999994   -1.0016075   7.7347655   7.958369   -7.9999905   7.5520062\n",
      "   0.99999917  6.9999275   6.9999914   8.          8.          7.9029446\n",
      "  -7.999953   -7.9999986   7.9465647   7.         -6.999999   -7.9999886\n",
      "  -7.          8.         -1.9854792   7.9999995  -6.9999976  -7.9999127\n",
      "   6.9999976   6.9998193   7.5102186   7.9999924  -8.          7.9999924\n",
      "  -7.          8.         -1.9234893   8.         -8.          1.2130917\n",
      "   7.6740966  -7.420789    6.9999986  -7.         -0.74999505  8.\n",
      "   1.0318713  -7.9999886  -6.9999304   7.8366847  -7.9999766   4.0787177\n",
      "   1.872665    7.8647847  -6.9999986   7.2770066 ]]\n",
      "T 4\n",
      "P 15\n",
      "T [-1.2318122]\n",
      "P [[-0.8849231]]\n",
      "[[-8.080274   -8.999999    8.999997   -8.90658    -8.          8.\n",
      "   8.33597     8.999929   -8.998839   -9.          9.         -0.9999853\n",
      "   8.878637    9.         -9.         -8.791157    7.99999     8.9999275\n",
      "  -0.9999989   9.         -8.          7.9999948   8.809813   -7.9999948\n",
      "  -8.999999    7.9999995   9.          9.          9.         -8.240946\n",
      "  -8.163298   -8.         -0.9996373   8.999996   -9.          7.9999843\n",
      "   8.99999    -8.9998      7.999968    8.311584   -8.999234   -0.9968933\n",
      "   9.         -8.140627   -7.999998    8.9999485  -8.          8.\n",
      "  -7.999994   -1.8462272   8.734766    8.958368   -8.99999     8.552006\n",
      "   0.99984235  7.9999266   7.9999914   9.          9.          8.902945\n",
      "  -8.999952   -8.999998    8.946565    8.         -7.999997   -8.999989\n",
      "  -8.          9.         -0.93487847  9.         -7.9999976  -8.999912\n",
      "   7.9999976   7.999818    8.510219    8.999992   -9.          8.999992\n",
      "  -8.          9.         -1.8389783   9.         -9.          1.3306199\n",
      "   8.674097   -8.420789    7.9999986  -8.         -0.9999499   9.\n",
      "   0.6849946  -8.999989   -7.999928    8.836684   -8.999974    3.838004\n",
      "   2.3353071   8.864784   -7.9999986   8.277006  ]]\n",
      "T 16\n",
      "P 3\n",
      "T [-1.5470788]\n",
      "P [[-0.8812815]]\n",
      "[[ -9.080274    -9.999999     9.999997    -9.90658     -9.\n",
      "    9.           9.33597      9.999929    -9.998839   -10.\n",
      "   10.          -0.9999999    9.878636    10.         -10.\n",
      "   -9.791157     8.9999895    9.999921    -0.90858626  10.\n",
      "   -9.           8.999994     9.809802    -8.999994    -9.999999\n",
      "    9.          10.          10.          10.          -9.240946\n",
      "   -9.163298    -9.          -1.1727655    9.999996   -10.\n",
      "    8.999984     9.99999     -9.999794     8.999967     9.311584\n",
      "   -9.999233    -1.0206013   10.          -9.140627    -8.999996\n",
      "    9.9999485   -9.           9.          -8.999994    -0.9997823\n",
      "    9.734766     9.958368    -9.99999      9.552006     0.8489458\n",
      "    8.999925     8.999991    10.          10.           9.902945\n",
      "   -9.999952    -9.999998     9.946565     9.          -8.999997\n",
      "   -9.999989    -9.          10.          -1.4895314   10.\n",
      "   -8.999997    -9.999904     8.999998     8.999814     9.510219\n",
      "    9.999992   -10.           9.999992    -9.          10.\n",
      "   -2.1749718   10.         -10.           1.352737     9.674097\n",
      "   -9.420789     8.999998    -9.          -0.9999999   10.\n",
      "    0.9983786   -9.999988    -8.999924     9.836684    -9.999973\n",
      "    4.0887327    0.787842     9.864784    -8.999998     9.277002  ]]\n",
      "T 7\n",
      "P 7\n",
      "T [-2.44998446]\n",
      "P [[-0.9241847]]\n",
      "[[-10.080273   -10.999999    10.999997   -10.90658    -10.\n",
      "   10.          10.33597     10.999929   -10.998839   -11.\n",
      "   11.          -0.98283315  10.878634    11.         -11.\n",
      "  -10.791157     9.999989    10.999916    -0.9997749   11.\n",
      "  -10.           9.999994    10.809793    -9.999994   -10.999999\n",
      "   10.          11.          11.          11.         -10.240946\n",
      "  -10.163298   -10.          -1.1949594   10.999996   -11.\n",
      "    9.999983    10.9999895  -10.999792     9.999967    10.311584\n",
      "  -10.999233    -1.1531632   11.         -10.140627    -9.999996\n",
      "   10.9999485  -10.          10.          -9.999994    -1.3817557\n",
      "   10.734766    10.958368   -10.99999     10.552006     0.9739218\n",
      "    9.999924     9.99999     11.          11.          10.902945\n",
      "  -10.999952   -10.999998    10.946565    10.          -9.999997\n",
      "  -10.999989   -10.          11.          -1.5804043   11.\n",
      "   -9.999997   -10.999899     9.999998     9.999812    10.510219\n",
      "   10.999992   -11.          10.999991   -10.          11.\n",
      "   -1.5589643   11.         -11.           1.566032    10.674097\n",
      "  -10.420789     9.999998   -10.          -0.9999998   11.\n",
      "    1.3004471  -10.999988    -9.999923    10.836682   -10.999973\n",
      "    5.088599     1.2666641   10.864784    -9.999998    10.2769985 ]]\n",
      "T 12\n",
      "P 4\n",
      "T [-0.75125822]\n",
      "P [[-0.9199904]]\n",
      "[[-11.080273   -11.999999    11.999997   -11.90658    -11.\n",
      "   11.          11.33597     11.999929   -11.998839   -12.\n",
      "   12.          -0.8685665   11.878633    12.         -12.\n",
      "  -11.791157    10.999983    11.999901    -0.99971056  12.\n",
      "  -11.          10.999994    11.809791   -10.999994   -11.999999\n",
      "   11.          12.          12.          12.         -11.240946\n",
      "  -11.163298   -11.          -0.9999978   11.999996   -12.\n",
      "   10.999982    11.9999895  -11.999791    10.999967    11.311584\n",
      "  -11.999233    -1.3295424   12.         -11.140627   -10.999996\n",
      "   11.9999485  -11.          11.         -10.999994    -1.2190641\n",
      "   11.734766    11.958368   -11.9999895   11.552006     0.99996465\n",
      "   10.999922    10.9999895   12.          12.          11.902945\n",
      "  -11.999951   -11.999998    11.946565    11.         -10.999997\n",
      "  -11.999989   -11.          12.          -1.8402822   12.\n",
      "  -10.999997   -11.999899    10.999998    10.999811    11.510219\n",
      "   11.999992   -12.          11.99999    -11.          12.\n",
      "   -1.5325229   12.         -12.           1.6462942   11.674097\n",
      "  -11.420789    10.999998   -11.          -0.9999988   12.\n",
      "    1.6739061  -11.999988   -10.999921    11.836682   -11.99997\n",
      "    5.893854     1.4023044   11.864784   -10.999998    11.276995  ]]\n",
      "T 10\n",
      "P 10\n",
      "T [-1.85827241]\n",
      "P [[-0.94947684]]\n",
      "[[-12.080273   -12.999999    12.999997   -12.90658    -12.\n",
      "   12.          12.33597     12.9999275  -12.998837   -13.\n",
      "   13.          -0.9999988   12.878632    13.         -13.\n",
      "  -12.791157    11.999982    12.999901    -0.99234176  13.\n",
      "  -12.          11.999994    12.80979    -11.999994   -12.999999\n",
      "   12.          13.          13.          13.         -12.240946\n",
      "  -12.163298   -12.          -0.9999938   12.999996   -13.\n",
      "   11.999981    12.999986   -12.999786    11.999966    12.311584\n",
      "  -12.999227    -0.47141433  13.         -12.140627   -11.999996\n",
      "   12.9999485  -12.          12.         -11.999994    -0.999937\n",
      "   12.734766    12.958368   -12.9999895   12.552006     0.9860478\n",
      "   11.99992     11.9999895   13.          13.          12.902945\n",
      "  -12.999951   -12.999998    12.946565    12.         -11.999995\n",
      "  -12.999989   -12.          13.          -2.0190513   13.\n",
      "  -11.999997   -12.999895    11.999998    11.999797    12.510219\n",
      "   12.999992   -13.          12.99999    -12.          13.\n",
      "   -1.7493672   13.         -13.           2.476489    12.674097\n",
      "  -12.420789    11.999998   -12.          -0.98415715  13.\n",
      "    0.5338763  -12.999987   -11.999917    12.836682   -12.9999695\n",
      "    5.943662     1.2687832   12.864784   -11.999998    12.276992  ]]\n",
      "T 10\n",
      "P 4\n",
      "T [-2.20880412]\n",
      "P [[-0.91339433]]\n",
      "[[-13.080273   -13.999999    13.999997   -13.90658    -13.\n",
      "   13.          13.33597     13.999925   -13.998821   -14.\n",
      "   14.          -0.99990755  13.878628    14.         -14.\n",
      "  -13.791157    12.999982    13.999898    -0.99920034  14.\n",
      "  -13.          12.999994    13.809783   -12.999994   -13.999999\n",
      "   13.          14.          14.          14.         -13.240946\n",
      "  -13.163298   -13.          -0.9999639   13.999996   -14.\n",
      "   12.999981    13.999986   -13.999781    12.99996     13.311584\n",
      "  -13.999222    -1.2867272   14.         -13.140627   -12.999996\n",
      "   13.9999485  -13.          13.         -12.999994    -0.9999566\n",
      "   13.734766    13.958368   -13.9999895   13.552006    -0.33625564\n",
      "   12.999919    12.9999895   14.          14.          13.902945\n",
      "  -13.9999485  -13.999998    13.946565    13.         -12.999995\n",
      "  -13.999989   -13.          14.          -2.2330682   14.\n",
      "  -12.999997   -13.999891    12.999998    12.999784    13.510219\n",
      "   13.999992   -14.          13.99999    -13.          14.\n",
      "   -2.2707798   14.         -14.           2.4195766   13.674096\n",
      "  -13.420789    12.999998   -13.          -0.9999968   14.\n",
      "    1.3866235  -13.999987   -12.999912    13.836682   -13.999969\n",
      "    6.9389486    1.7075396   13.864784   -12.999998    13.276987  ]]\n",
      "T 15\n",
      "P 8\n",
      "T [-2.02906128]\n",
      "P [[-1.122732]]\n",
      "[[-14.080273   -14.999999    14.999996   -14.90658    -14.\n",
      "   14.          14.33597     14.999925   -14.998821   -15.\n",
      "   15.          -0.9999999   14.878594    15.         -15.\n",
      "  -14.791157    13.999982    14.999889     0.57293755  15.\n",
      "  -14.          13.999994    14.809339   -13.999985   -14.999999\n",
      "   14.          15.          15.          15.         -14.240946\n",
      "  -14.163298   -14.          -1.          14.999996   -15.\n",
      "   13.999979    14.999985   -14.999749    13.99994     14.311584\n",
      "  -14.999188    -1.7026103   15.         -14.140627   -13.999996\n",
      "   14.999948   -14.          14.         -13.999993    -0.8613314\n",
      "   14.734766    14.958368   -14.999977    14.552006     0.9375834\n",
      "   13.999903    13.9999895   15.          15.          14.902945\n",
      "  -14.999948   -14.999998    14.946561    14.         -13.999995\n",
      "  -14.999989   -14.          15.          -2.511509    15.\n",
      "  -13.999997   -14.999891    13.999998    13.999729    14.510218\n",
      "   14.99999    -15.          14.9999895  -14.          15.\n",
      "   -2.8242307   15.         -15.           0.9996745   14.674096\n",
      "  -14.420789    13.999998   -14.          -0.9999805   15.\n",
      "    0.81798255 -14.999978   -13.999904    14.836681   -14.999951\n",
      "    7.9389486    1.3455217   14.864784   -13.999998    14.276983  ]]\n",
      "T 7\n",
      "P 7\n",
      "T [99.62266525]\n",
      "P [[97.3008]]\n",
      "[[-15.080271   -15.999999    15.999996   -15.90658    -15.\n",
      "   15.          15.33597     15.999925   -15.998821   -16.\n",
      "   16.          -0.99934405  15.878585    16.         -16.\n",
      "  -15.791157    14.99996     15.999888    -0.99999785  16.\n",
      "  -15.          14.999992    15.809328   -14.999984   -15.999999\n",
      "   15.          16.          16.          16.         -15.240946\n",
      "  -15.163298   -15.          -1.0168242   15.999996   -16.\n",
      "   14.999977    15.999976   -15.999745    14.999938    15.311584\n",
      "  -15.999188    -2.0551512   16.         -15.140627   -14.999996\n",
      "   15.999948   -15.          15.         -14.999993    -1.7071612\n",
      "   15.734766    15.958368   -15.999941    15.552006     0.943014\n",
      "   14.999901    14.999989    16.          16.          15.902945\n",
      "  -15.999946   -15.999998    15.946561    15.         -14.999995\n",
      "  -15.999989   -15.          15.999999    -2.4664912   16.\n",
      "  -14.999997   -15.999888    14.999998    14.999728    15.510218\n",
      "   15.99999    -16.          15.999985   -15.          16.\n",
      "   -1.6685224   16.         -16.           1.3989573   15.674095\n",
      "  -15.420789    14.999998   -15.          -1.          16.\n",
      "    1.1035789  -15.999978   -14.999902    15.836675   -15.99995\n",
      "    8.75328      1.8149451   15.864784   -14.999998    15.276979  ]]\n",
      "T 4\n",
      "P 4\n",
      "T [-0.46762191]\n",
      "P [[-0.8912412]]\n",
      "[[-16.08027    -16.999998    16.999996   -16.90658    -16.\n",
      "   16.          16.33597     16.999924   -16.998821   -17.\n",
      "   17.          -1.          16.878584    17.         -17.\n",
      "  -16.791157    15.999959    16.99989     -0.99370706  17.\n",
      "  -16.          15.999992    16.809324   -15.999984   -17.\n",
      "   16.          17.          17.          17.         -16.240946\n",
      "  -16.163298   -16.          -0.9999999   16.999996   -17.\n",
      "   15.999976    16.999977   -16.999744    15.999938    16.311584\n",
      "  -16.999187    -0.9999695   17.         -16.140627   -15.999994\n",
      "   16.999947   -16.          16.         -15.999993    -1.7866027\n",
      "   16.734766    16.958368   -16.99994     16.552006     0.99999905\n",
      "   15.9999      15.999989    17.          17.          16.902945\n",
      "  -16.999945   -16.999998    16.94656     16.         -15.999994\n",
      "  -16.999989   -16.          17.          -1.8950446   17.\n",
      "  -15.999997   -16.99989     15.999998    15.999726    16.510218\n",
      "   16.99999    -17.          16.999985   -16.          17.\n",
      "   -2.1431441   17.         -17.           1.4667367   16.674095\n",
      "  -16.420788    15.999998   -16.          -0.9376979   17.\n",
      "   -0.9818596  -16.999977   -15.9999      16.836674   -16.99995\n",
      "    8.422889     1.5524898   16.864784   -15.999998    16.276978  ]]\n",
      "T 0\n",
      "P 0\n",
      "T [0.68834323]\n",
      "P [[-0.87329876]]\n",
      "[[-17.08027    -17.999998    17.999996   -17.90658    -17.\n",
      "   17.          17.33597     17.999922   -17.998814   -18.\n",
      "   18.          -0.99764436  17.878584    18.         -18.\n",
      "  -17.791157    16.999952    17.99989     -1.          18.\n",
      "  -17.          16.999992    17.809288   -16.999985   -18.\n",
      "   17.          18.          18.          18.         -17.240946\n",
      "  -17.163298   -17.          -0.9990613   17.999996   -18.\n",
      "   16.999975    17.999977   -17.99974     16.999928    17.311584\n",
      "  -17.999187     0.38001218  18.         -17.140627   -16.999971\n",
      "   17.999947   -17.          17.         -16.999992    -1.4092162\n",
      "   17.734766    17.958368   -17.99994     17.552006     1.2366402\n",
      "   16.999895    16.999989    18.          18.          17.902945\n",
      "  -17.99988    -17.999998    17.94656     17.         -16.999987\n",
      "  -17.999989   -17.          18.          -0.9999798   18.\n",
      "  -16.999996   -17.99989     16.999998    16.999722    17.510218\n",
      "   17.99999    -18.          17.999985   -17.          18.\n",
      "   -3.1431437   18.         -18.           1.6590204   17.674095\n",
      "  -17.420788    16.999998   -17.          -1.1331561   18.\n",
      "    0.99882025 -17.999971   -16.99985     17.836674   -17.99995\n",
      "    3.9150138    1.873007    17.864784   -16.999998    17.276978  ]]\n",
      "T 10\n",
      "P 10\n",
      "T [-1.20663811]\n",
      "P [[-1.0002865]]\n",
      "[[-18.08027    -18.999998    18.999996   -18.90658    -18.\n",
      "   18.          18.33597     18.999914   -18.998812   -19.\n",
      "   19.          -1.          18.878578    19.         -19.\n",
      "  -18.791157    17.999952    18.99989      0.3946638   19.\n",
      "  -18.          17.999992    18.809286   -17.999985   -19.\n",
      "   18.          19.          19.          19.         -18.240946\n",
      "  -18.163298   -18.          -1.2062457   18.999996   -19.\n",
      "   17.999975    18.999977   -18.999739    17.999924    18.311584\n",
      "  -18.999186    -0.8389847   19.         -18.140627   -17.999966\n",
      "   18.999947   -18.          18.         -17.999992    -0.77296126\n",
      "   18.734766    18.958368   -18.99994     18.552006     0.9866045\n",
      "   17.999893    17.999989    19.          19.          18.902945\n",
      "  -18.999874   -18.999998    18.94656     18.         -17.999987\n",
      "  -18.999989   -18.          19.          -1.78687     19.\n",
      "  -17.999996   -18.99989     17.999998    17.999718    18.510218\n",
      "   18.99999    -19.          18.999985   -18.          19.\n",
      "   -2.923183    19.         -19.           2.5266752   18.674095\n",
      "  -18.420788    17.999998   -18.          -0.97052723  19.\n",
      "    0.32786337 -18.999971   -17.99985     18.836674   -18.99995\n",
      "    4.9149466    2.4223418   18.864784   -17.999998    18.276974  ]]\n",
      "T 11\n",
      "P 11\n",
      "T [-1.99069737]\n",
      "P [[-1.0135745]]\n",
      "[[-19.08027    -19.999998    19.999996   -19.90658    -19.\n",
      "   19.          19.33597     19.999905   -19.998802   -20.\n",
      "   20.          -0.99621105  19.878569    20.         -20.\n",
      "  -19.791157    18.999947    19.99989     -1.          20.\n",
      "  -19.          18.999992    19.394331   -18.999983   -20.\n",
      "   19.          20.          20.          20.         -19.240946\n",
      "  -19.163298   -19.          -0.99831975  19.999996   -20.\n",
      "   18.999971    19.99997    -19.999733    18.99991     19.311584\n",
      "  -19.999184    -0.85463774  20.         -19.140627   -18.999966\n",
      "   19.999947   -19.          19.         -18.999992    -1.1479686\n",
      "   19.734766    19.958368   -19.999939    19.552006     0.9985011\n",
      "   18.999866    18.999989    20.          20.          19.902945\n",
      "  -19.999866   -19.999998    19.94656     19.         -18.99998\n",
      "  -19.999989   -19.          20.          -1.1890042   20.\n",
      "  -18.999996   -19.999887    18.999998    18.999704    19.510218\n",
      "   19.99999    -20.          19.999983   -19.          20.\n",
      "   -2.8296094   20.         -20.           2.0303106   19.674095\n",
      "  -19.420788    18.999998   -19.          -1.1997119   20.\n",
      "    0.9999505  -19.99996    -18.999823    19.836674   -19.999939\n",
      "    5.23918      2.841984    19.864784   -18.999998    19.276972  ]]\n",
      "T 8\n",
      "P 10\n",
      "T [-2.11225579]\n",
      "P [[-0.9343554]]\n",
      "[[-20.08027    -20.999998    20.999996   -20.90658    -20.\n",
      "   20.          20.33597     20.999903   -20.9988     -21.\n",
      "   21.          -0.99964267  20.878563    21.         -21.\n",
      "  -20.791157    19.999947    20.999687    -0.9260053   21.\n",
      "  -20.          19.999992    20.394327   -19.999983   -21.\n",
      "   20.          21.          21.          21.         -20.240946\n",
      "  -20.163298   -20.          -0.9999999   20.999996   -20.999998\n",
      "   19.99997     20.99997    -20.999731    19.99991     20.311584\n",
      "  -20.999184    -1.2544152   21.         -20.140627   -19.999966\n",
      "   20.999947   -20.          20.         -19.999992    -0.99991935\n",
      "   20.734766    20.958368   -20.999939    20.552006     0.948687\n",
      "   19.999863    19.999989    21.          21.          20.902945\n",
      "  -20.999865   -20.999998    20.94656     20.         -19.99998\n",
      "  -20.999989   -20.          21.          -1.942758    21.\n",
      "  -19.999996   -20.999886    19.999998    19.999691    20.510218\n",
      "   20.99999    -21.          20.99998    -20.          21.\n",
      "   -2.2027311   21.         -21.           1.2533152   20.674095\n",
      "  -20.420788    19.999998   -20.          -0.999992    21.\n",
      "    1.8502305  -20.99996    -19.999819    20.836674   -20.999931\n",
      "    6.23918      1.9920948   20.864784   -19.999998    20.276972  ]]\n",
      "T 3\n",
      "P 3\n",
      "T [0.28383083]\n",
      "P [[-0.94045365]]\n",
      "[[-21.08027    -21.999998    21.999996   -21.90658    -21.\n",
      "   21.          21.33597     21.999903   -21.9988     -22.\n",
      "   22.           0.2954328   21.878546    22.         -22.\n",
      "  -21.791157    20.999945    21.999683    -1.          22.\n",
      "  -21.          20.999992    21.394308   -20.999983   -22.\n",
      "   21.          22.          22.          22.         -21.240946\n",
      "  -21.163298   -21.          -1.4405289   21.999996   -21.999998\n",
      "   20.99997     21.99997    -21.999723    20.999908    21.311584\n",
      "  -21.999184    -1.1473356   22.         -21.140627   -20.999966\n",
      "   21.999947   -21.          21.         -20.999992    -0.99999976\n",
      "   21.734766    21.958368   -21.999939    21.552006     0.9957464\n",
      "   20.999859    20.999989    22.          22.          21.902945\n",
      "  -21.999859   -21.999998    21.94656     21.         -20.99998\n",
      "  -21.999989   -21.          22.          -2.10151     22.\n",
      "  -20.999996   -21.999886    20.999998    20.999685    21.510218\n",
      "   21.99999    -22.          21.99998    -21.          22.\n",
      "   -1.8098567   22.         -22.           1.0210973   21.674095\n",
      "  -21.420788    20.999998   -21.          -1.          22.\n",
      "    2.4929004  -21.99996    -20.999807    21.836674   -21.999928\n",
      "    5.538904     1.8192075   21.864784   -20.999998    21.276972  ]]\n",
      "T 1\n",
      "P 1\n",
      "T [0.36179087]\n",
      "P [[-0.9049951]]\n",
      "[[-22.08027    -22.999998    22.999996   -22.90658    -22.\n",
      "   22.          22.33597     22.999903   -22.9988     -23.\n",
      "   23.          -0.9999831   22.878546    23.         -23.\n",
      "  -22.791157    21.999943    22.999598     0.17701322  23.\n",
      "  -22.          21.999992    22.394308   -21.999983   -23.\n",
      "   22.          23.          23.          23.         -22.240946\n",
      "  -22.163298   -22.          -1.5416603   22.999996   -22.999998\n",
      "   21.999968    22.999968   -22.999712    21.999908    22.311584\n",
      "  -22.999184    -0.99952376  23.         -22.140627   -21.999966\n",
      "   22.999945   -22.          22.         -21.999992    -0.99999154\n",
      "   22.734766    22.958368   -22.999937    22.552006     0.9015361\n",
      "   21.999857    21.999989    23.          23.          22.902945\n",
      "  -22.999859   -22.999998    22.94656     22.         -21.99998\n",
      "  -22.999989   -22.          23.          -2.9102721   23.\n",
      "  -21.999996   -22.999886    21.999998    21.99968     22.510218\n",
      "   22.99999    -23.          22.99998    -22.          23.\n",
      "   -1.2245691   23.         -23.           0.9999002   22.674095\n",
      "  -22.420788    21.999998   -22.          -1.087064    23.\n",
      "    1.3854039  -22.99996    -21.999807    22.836674   -22.999926\n",
      "    6.5389028    0.15315747  22.864784   -21.999998    22.27697   ]]\n",
      "T 15\n",
      "P 2\n",
      "T [-3.46293015]\n",
      "P [[-1.2059983]]\n",
      "[[-23.08027    -23.999998    23.999996   -23.90658    -23.\n",
      "   23.          23.33597     23.999903   -23.9988     -24.\n",
      "   24.          -0.99999934  23.878544    24.         -24.\n",
      "  -23.791157    22.999943    23.999596    -0.98639226  24.\n",
      "  -23.          22.999992    23.394283   -22.999983   -24.\n",
      "   23.          24.          24.          24.         -23.240946\n",
      "  -23.163298   -23.          -1.3387257   23.999996   -23.999998\n",
      "   22.999968    23.999958   -23.999702    22.999899    23.311584\n",
      "  -23.999166    -0.64226663  24.         -23.140627   -22.999966\n",
      "   23.999912   -23.          23.         -22.999992    -0.99747473\n",
      "   23.734766    23.958368   -23.999935    23.552006    -0.14713265\n",
      "   22.999855    22.999989    24.          24.          23.902945\n",
      "  -23.999859   -23.999998    23.94656     23.         -22.99998\n",
      "  -23.999989   -23.          24.          -1.41665     24.\n",
      "  -22.999996   -23.999882    22.999998    22.99965     23.510216\n",
      "   23.999989   -24.          23.99998    -23.          24.\n",
      "   -1.7562271   24.         -24.           1.          23.674095\n",
      "  -23.420788    22.999998   -23.          -1.          24.\n",
      "    1.3413575  -23.999958   -22.999804    23.836672   -23.999922\n",
      "    7.5389028    0.1410812   23.864784   -22.999998    23.27697   ]]\n",
      "T 13\n",
      "P 7\n",
      "T [102.34869459]\n",
      "P [[96.48528]]\n",
      "[[-24.08027    -24.999998    24.999996   -24.90658    -24.\n",
      "   24.          24.33597     24.9999     -24.998758   -25.\n",
      "   25.          -0.9999231   24.878542    25.         -25.\n",
      "  -24.791157    23.999943    24.99959     -0.9470794   25.\n",
      "  -24.          23.99999     24.394283   -23.999983   -25.\n",
      "   24.          25.          25.          25.         -24.240946\n",
      "  -24.163298   -24.          -1.627192    24.999996   -24.999998\n",
      "   23.999968    24.999958   -24.9997      23.999899    24.311584\n",
      "  -24.999166    -0.9999709   25.         -24.140627   -23.999966\n",
      "   24.999912   -24.          24.         -23.999992    -0.99999696\n",
      "   24.734766    24.958368   -24.999935    24.552006     0.99976856\n",
      "   23.999855    23.999987    25.          25.          24.902945\n",
      "  -24.999857   -24.999998    24.94656     24.         -23.99998\n",
      "  -24.999989   -24.          25.          -2.0117493   25.\n",
      "  -23.999996   -24.99988     23.999998    23.999647    24.510216\n",
      "   24.999989   -25.          24.99998    -24.          25.\n",
      "   -1.513752    25.         -25.           0.99687785  24.674095\n",
      "  -24.420788    23.999998   -24.          -0.9999979   25.\n",
      "    0.9998306  -24.999958   -23.999802    24.836672   -24.999922\n",
      "    6.8489823    1.1390685   24.864784   -23.999998    24.27697   ]]\n",
      "T 7\n",
      "P 7\n",
      "T [-2.51278366]\n",
      "P [[-1.4277681]]\n",
      "[[-25.08027    -25.999998    25.999996   -25.90658    -25.\n",
      "   25.          25.33597     25.9999     -25.998758   -26.\n",
      "   26.          -0.995732    25.87854     26.         -26.\n",
      "  -25.791157    24.999939    25.99959     -0.99999785  26.\n",
      "  -25.          24.99999     25.394281   -24.999983   -26.\n",
      "   25.          26.          26.          26.         -25.240946\n",
      "  -25.163298   -25.          -0.99997866  25.999994   -25.999998\n",
      "   24.999968    25.999958   -25.9997      24.999899    25.311584\n",
      "  -25.999166    -1.1790758   26.         -25.140627   -24.999966\n",
      "   25.999912   -25.          25.         -24.999992    -1.5364764\n",
      "   25.734766    25.958368   -25.999935    25.552006     0.9999029\n",
      "   24.999855    24.999987    25.999998    26.          25.902945\n",
      "  -25.999857   -25.999998    25.94656     25.         -24.99998\n",
      "  -25.999989   -25.          26.           0.05119139  26.\n",
      "  -24.999996   -25.999878    24.999998    24.999647    25.510216\n",
      "   25.999989   -26.          25.99998    -25.          26.\n",
      "   -1.8459547   26.         -26.           1.8169935   25.674095\n",
      "  -25.420788    24.999998   -25.          -0.9999946   26.\n",
      "    1.1028956  -25.999958   -24.999802    25.836672   -25.999922\n",
      "    6.1290517    1.4023916   25.864784   -24.999998    25.276968  ]]\n",
      "T 4\n",
      "P 4\n",
      "T [-0.84942066]\n",
      "P [[-0.8917521]]\n",
      "[[-26.08027    -26.999998    26.999996   -26.90658    -26.\n",
      "   26.          26.33597     26.999899   -26.998758   -27.\n",
      "   27.          -1.          26.87854     27.         -27.\n",
      "  -26.791157    25.999939    26.99959     -0.99904925  27.\n",
      "  -26.          25.99999     26.394278   -25.999983   -27.\n",
      "   26.          27.          27.          27.         -26.240946\n",
      "  -26.163298   -26.          -0.9999999   26.999994   -26.999998\n",
      "   25.999966    26.999958   -26.9997      25.999899    26.311584\n",
      "  -26.999166    -1.0223622   27.         -26.140627   -25.999964\n",
      "   26.999912   -26.          26.         -25.999992    -1.6540875\n",
      "   26.734766    26.958368   -26.999935    26.552006     0.9999952\n",
      "   25.999853    25.999987    26.999998    27.          26.902945\n",
      "  -26.999855   -26.999998    26.94656     26.         -25.99998\n",
      "  -26.999989   -26.          27.          -0.97138     27.\n",
      "  -25.999996   -26.999878    25.999998    25.999645    26.510216\n",
      "   26.999989   -27.          26.99998    -26.          27.\n",
      "   -2.5293987   27.         -27.           1.909668    26.674095\n",
      "  -26.420788    25.999998   -26.          -0.9843759   27.\n",
      "   -0.9723417  -26.999958   -25.999798    26.836672   -26.99992\n",
      "    5.718483     1.4372842   26.864784   -25.999998    26.276966  ]]\n",
      "T 3\n",
      "P 3\n",
      "T [0.22376756]\n",
      "P [[-0.87531364]]\n",
      "[[-27.08027    -27.999998    27.999996   -27.90658    -27.\n",
      "   27.          27.33597     27.999899   -27.998743   -28.\n",
      "   28.          -0.9801407   27.87854     28.         -28.\n",
      "  -27.791157    26.999939    27.999588    -1.          28.\n",
      "  -27.          26.99999     27.394238   -26.999983   -28.\n",
      "   27.          28.          28.          28.         -27.240946\n",
      "  -27.163298   -27.          -1.091573    27.999994   -27.999998\n",
      "   26.999966    27.999958   -27.999699    26.999895    27.311584\n",
      "  -27.999166    -1.0347193   28.         -27.140627   -26.999964\n",
      "   27.999912   -27.          27.         -26.999992    -0.99997115\n",
      "   27.734766    27.958368   -27.999935    27.552006     0.9989575\n",
      "   26.999851    26.999987    27.999998    28.          27.902945\n",
      "  -27.999853   -27.999998    27.94656     27.         -26.999979\n",
      "  -27.999989   -27.          28.          -1.2173903   28.\n",
      "  -26.999996   -27.999874    26.999998    26.99964     27.510216\n",
      "   27.999987   -28.          27.99998    -27.          28.\n",
      "   -2.9198544   28.         -28.           1.1664189   27.674095\n",
      "  -27.420788    26.999998   -27.          -1.          28.\n",
      "    0.76521504 -27.999956   -26.999775    27.836672   -27.999918\n",
      "    3.8326683    1.7894294   27.864784   -26.999998    27.276966  ]]\n",
      "T 3\n",
      "P 7\n",
      "T [-0.94255311]\n",
      "P [[-0.89176977]]\n",
      "[[-28.08027    -28.999998    28.999996   -28.90658    -28.\n",
      "   28.          28.33597     28.999899   -28.998743   -29.\n",
      "   29.          -0.4380631   28.878525    29.         -29.\n",
      "  -28.791157    27.999939    28.999584    -1.0437278   29.\n",
      "  -28.          27.99999     28.394209   -27.999983   -29.\n",
      "   28.          29.          29.          29.         -28.240946\n",
      "  -28.163298   -28.          -1.77964     28.999992   -28.999998\n",
      "   27.999966    28.999958   -28.999693    27.999893    28.311584\n",
      "  -28.999166    -1.0665594   29.         -28.140627   -27.999964\n",
      "   28.999912   -28.          28.         -27.999992    -0.99999666\n",
      "   28.734766    28.958368   -28.999935    28.552006     0.9999235\n",
      "   27.999838    27.999987    28.999998    29.          28.902945\n",
      "  -28.999832   -28.999996    28.94656     28.         -27.999979\n",
      "  -28.999989   -28.          29.          -1.6796266   29.\n",
      "  -27.999996   -28.999874    27.999998    27.999628    28.510216\n",
      "   28.999987   -29.          28.99998    -28.          29.\n",
      "   -2.8361027   29.         -29.           0.9999753   28.674095\n",
      "  -28.420788    27.999998   -28.          -0.9999998   29.\n",
      "    1.5582767  -28.999954   -27.99977     28.836672   -28.999912\n",
      "    4.163427     2.4349952   28.864784   -27.999998    28.276966  ]]\n",
      "T 12\n",
      "P 1\n",
      "T [-1.60267903]\n",
      "P [[-0.8841492]]\n",
      "[[-29.08027    -29.999998    29.999996   -29.90658    -29.\n",
      "   29.          29.33597     29.999899   -29.998743   -30.\n",
      "   30.          -0.8204878   29.878517    30.         -30.\n",
      "  -29.791157    28.999933    29.99957     -0.999884    30.\n",
      "  -29.          28.999989    29.394205   -28.999983   -30.\n",
      "   29.          30.          30.          30.         -29.240946\n",
      "  -29.163298   -29.          -1.0648634   29.999992   -29.999998\n",
      "   28.999966    29.999958   -29.99969     28.999893    29.311584\n",
      "  -29.999166    -1.1978447   30.         -29.140627   -28.999964\n",
      "   29.999912   -29.          29.         -28.999992    -1.196274\n",
      "   29.734766    29.958368   -29.999933    29.552006     0.9998227\n",
      "   28.999828    28.999987    29.999998    30.          29.902945\n",
      "  -29.999826   -29.999992    29.94656     29.         -28.999979\n",
      "  -29.999989   -29.          30.          -2.1385212   30.\n",
      "  -28.999996   -29.999874    28.999998    28.999624    29.510216\n",
      "   29.999987   -30.          29.999979   -29.          30.\n",
      "   -1.5053277   30.         -30.           1.3585005   29.674095\n",
      "  -29.420788    28.999998   -29.          -0.99999964  30.\n",
      "    1.7025512  -29.999954   -28.999763    29.836672   -29.999907\n",
      "    4.8951674    1.7715718   29.864784   -28.999998    29.276964  ]]\n",
      "T 4\n",
      "P 10\n",
      "T [-1.22483038]\n",
      "P [[-0.9294642]]\n",
      "[[-30.08027    -30.999998    30.999996   -30.90658    -30.\n",
      "   30.          30.33597     30.999899   -30.998743   -31.\n",
      "   31.          -0.99999714  30.878515    31.         -31.\n",
      "  -30.791157    29.999931    30.99957     -0.99907607  31.\n",
      "  -30.          29.999989    30.394197   -29.999983   -31.\n",
      "   30.          31.          31.          31.         -30.240946\n",
      "  -30.163298   -30.          -1.0536166   30.999992   -30.999998\n",
      "   29.999966    30.999958   -30.999687    29.999893    30.311584\n",
      "  -30.999166    -1.1660285   31.         -30.140627   -29.999962\n",
      "   30.999912   -30.          30.         -29.999992    -1.325728\n",
      "   30.734766    30.958368   -30.999933    30.552006     0.9997772\n",
      "   29.999826    29.999987    30.999998    31.          30.902945\n",
      "  -30.999823   -30.999992    30.94656     30.         -29.999979\n",
      "  -30.999989   -30.          31.          -2.1605966   31.\n",
      "  -29.999996   -30.999874    29.999998    29.999619    30.510216\n",
      "   30.999987   -31.          30.999979   -30.          31.\n",
      "   -1.859366    31.         -31.           1.1476727   30.674095\n",
      "  -30.420788    29.999998   -30.          -0.9999932   31.\n",
      "    1.2584822  -30.999954   -29.99976     30.836672   -30.999905\n",
      "    5.4641676    1.5625907   30.864784   -29.999998    30.276962  ]]\n",
      "T 1\n",
      "P 11\n",
      "T [-1.77076474]\n",
      "P [[-0.8824111]]\n",
      "[[-31.08027    -31.999998    31.999996   -31.90658    -31.\n",
      "   31.          31.33597     31.999899   -31.998743   -32.\n",
      "   32.          -0.9679513   31.878513    32.         -32.\n",
      "  -31.791157    30.999928    31.999502    -0.9996168   32.\n",
      "  -31.          30.999989    31.394194   -30.999983   -32.\n",
      "   31.          32.          32.          32.         -31.240946\n",
      "  -31.163298   -31.          -0.99999815  31.999992   -31.999998\n",
      "   30.999966    31.999958   -31.999676    30.999893    31.311584\n",
      "  -31.999166    -1.4454404   32.         -31.140627   -30.999962\n",
      "   31.999912   -31.          31.         -30.999992    -1.3584027\n",
      "   31.734766    31.958368   -31.999931    31.552006    -0.42237145\n",
      "   30.999823    30.999987    31.999998    32.          31.902945\n",
      "  -31.999817   -31.999992    31.94656     31.         -30.999979\n",
      "  -31.999989   -31.          32.          -2.2710738   32.\n",
      "  -30.999996   -31.999874    30.999998    30.999613    31.510216\n",
      "   31.999987   -32.          31.999979   -31.          32.\n",
      "   -2.2715712   32.         -32.           0.9999843   31.674095\n",
      "  -31.420788    30.999998   -31.          -1.          32.\n",
      "    1.6970518  -31.999952   -30.999758    31.836672   -31.999895\n",
      "    5.7782307    1.4836121   31.864784   -30.999998    31.276957  ]]\n",
      "T 12\n",
      "P 2\n",
      "T [-0.98610088]\n",
      "P [[-0.96766174]]\n",
      "[[-32.08027    -32.999996    32.999996   -32.906578   -32.\n",
      "   32.          32.335968    32.9999     -32.99874    -33.\n",
      "   33.          -0.98483217  32.878513    33.         -33.\n",
      "  -32.791157    31.999922    32.999493    -0.99159896  33.\n",
      "  -32.          31.999989    32.39419    -31.999983   -33.\n",
      "   32.          33.          33.          33.         -32.240944\n",
      "  -32.1633     -32.          -1.2629147   32.999992   -32.999996\n",
      "   31.999964    32.999954   -32.99967     31.999893    32.311584\n",
      "  -32.999165    -1.0291665   33.         -32.140625   -31.999962\n",
      "   32.999912   -32.          32.         -31.999992    -1.0300541\n",
      "   32.734764    32.958366   -32.999928    32.552006     0.9999803\n",
      "   31.99982     31.999985    33.          33.          32.902943\n",
      "  -32.999817   -32.999992    32.94656     32.         -31.999979\n",
      "  -32.99999    -32.          33.          -2.2433045   33.\n",
      "  -31.999996   -32.99987     31.999998    31.99961     32.510216\n",
      "   32.999985   -33.          32.999977   -32.          33.\n",
      "   -1.0608009   33.         -33.           1.3202693   32.674095\n",
      "  -32.420788    31.999998   -32.          -0.999983    33.\n",
      "    1.0374161  -32.99995    -31.99975     32.83667    -32.999893\n",
      "    5.132251    -0.25261867  32.864784   -31.999998    32.276955  ]]\n",
      "T 1\n",
      "P 12\n",
      "T [-1.75730952]\n",
      "P [[-1.0609931]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-33.08027    -33.999996    33.999996   -33.906578   -33.\n",
      "   33.          33.335968    33.9999     -33.99874    -33.999996\n",
      "   34.          -0.99767065  33.878513    34.         -34.\n",
      "  -33.791157    32.99992     33.99949     -0.9998137   34.\n",
      "  -33.          32.99999     33.39419    -32.999985   -34.\n",
      "   33.          34.          34.          34.         -33.240944\n",
      "  -33.1633     -33.          -1.4072325   33.999992   -33.999996\n",
      "   32.99996     33.999954   -33.999664    32.999893    33.311584\n",
      "  -33.999165    -1.1607417   34.         -33.140625   -32.99996\n",
      "   33.999912   -33.          33.         -32.999992    -1.1353154\n",
      "   33.734764    33.958366   -33.99991     33.552006    -0.13092557\n",
      "   32.99982     32.999985    34.          34.          33.902943\n",
      "  -33.99981    -33.999992    33.94656     33.         -32.999977\n",
      "  -33.99999    -33.          34.          -1.8626256   34.\n",
      "  -32.999996   -33.99987     33.          32.99961     33.510216\n",
      "   33.999985   -34.          33.999977   -33.          34.\n",
      "   -1.3777577   34.         -34.           0.9999985   33.674095\n",
      "  -33.420788    32.999996   -33.          -1.          34.\n",
      "    1.3035204  -33.99995    -32.99975     33.83667    -33.999886\n",
      "    4.280186     0.8834677   33.864784   -33.          33.276955  ]]\n",
      "T 4\n",
      "P 4\n",
      "T [-1.3300907]\n",
      "P [[-1.0391203]]\n",
      "[[-34.08027    -34.999996    34.999996   -34.906578   -34.\n",
      "   34.          34.335968    34.9999     -34.99874    -34.999996\n",
      "   35.          -0.99998796  34.87851     35.         -35.\n",
      "  -34.791157    33.99992     34.99949     -0.99996513  35.\n",
      "  -34.          33.99999     34.394188   -33.999985   -35.\n",
      "   34.          35.          35.          35.         -34.240944\n",
      "  -34.1633     -34.          -1.1728296   34.999992   -34.999996\n",
      "   33.99996     34.999954   -34.99966     33.999893    34.311584\n",
      "  -34.999165    -1.3821372   35.         -34.140625   -33.99996\n",
      "   34.999912   -34.          34.         -33.999992    -1.4672787\n",
      "   34.734764    34.958366   -34.99991     34.552006     0.9999973\n",
      "   33.99982     33.999985    35.          35.          34.902943\n",
      "  -34.99981    -34.999992    34.94656     34.         -33.999977\n",
      "  -34.99999    -34.          35.          -1.7499361   35.\n",
      "  -33.999996   -34.99987     34.          33.999607    34.510216\n",
      "   34.999985   -35.          34.999977   -34.          35.\n",
      "   -2.0099552   35.         -35.           1.1476536   34.674095\n",
      "  -34.420788    33.999996   -34.          -0.9999938   35.\n",
      "    1.3225571  -34.99995    -33.999744    34.83667    -34.999886\n",
      "    4.875115     1.2611707   34.864784   -34.          34.27695   ]]\n",
      "T 4\n",
      "P 4\n",
      "T [-0.22174503]\n",
      "P [[-0.89426434]]\n",
      "[[-35.08027    -35.999996    35.999996   -35.906578   -35.\n",
      "   35.          35.335968    35.9999     -35.998734   -35.999996\n",
      "   36.          -0.99996823  35.878506    36.         -36.\n",
      "  -35.791157    34.99992     35.99949     -0.99998236  36.\n",
      "  -35.          34.99999     35.394142   -34.999985   -36.\n",
      "   35.          36.          36.          36.         -35.240944\n",
      "  -35.1633     -35.          -0.9999718   35.999992   -35.999996\n",
      "   34.99996     35.999954   -35.999657    34.99989     35.311584\n",
      "  -35.999165    -1.7142913   36.         -35.140625   -34.999958\n",
      "   35.999912   -35.          35.         -34.999992    -1.8410802\n",
      "   35.734764    35.958366   -35.99991     35.552006     0.99729514\n",
      "   34.999817    34.999985    36.          36.          35.902943\n",
      "  -35.999794   -35.999992    35.94656     35.         -34.999977\n",
      "  -35.99999    -35.          36.          -1.5955842   36.\n",
      "  -34.999996   -35.99987     35.          34.999603    35.510216\n",
      "   35.999985   -36.          35.999977   -35.          36.\n",
      "   -2.7027209   36.         -36.           0.9999702   35.674095\n",
      "  -35.420788    34.999996   -35.          -0.9999996   36.\n",
      "    1.5890325  -35.99995    -34.999733    35.83667    -35.99988\n",
      "    5.5347657    1.8547816   35.864784   -35.          35.276947  ]]\n",
      "T 11\n",
      "P 11\n",
      "T [-0.02150348]\n",
      "P [[-0.88227856]]\n",
      "[[-36.08027    -36.999996    36.999996   -36.906578   -36.\n",
      "   36.          36.335968    36.99978    -36.998714   -36.999996\n",
      "   37.          -0.99999976  36.878498    37.         -37.\n",
      "  -36.791157    35.999916    36.999477    -0.9924881   37.\n",
      "  -36.          35.99999     36.394093   -35.999985   -37.\n",
      "   36.          37.          37.          37.         -36.240944\n",
      "  -36.1633     -36.          -1.1720765   36.999992   -36.999996\n",
      "   35.999958    36.99995    -36.999622    35.99988     36.311584\n",
      "  -36.999157    -2.014909    37.         -36.140625   -35.999958\n",
      "   36.999912   -36.          36.         -35.999992    -0.90773004\n",
      "   36.734764    36.958366   -36.99991     36.552006     0.9997534\n",
      "   35.999783    35.999985    37.          37.          36.902943\n",
      "  -36.999695   -36.999992    36.94656     36.         -35.999977\n",
      "  -36.99999    -36.          37.          -2.2500608   37.\n",
      "  -35.999996   -36.99987     36.          35.999596    36.510216\n",
      "   36.999985   -37.          36.999977   -36.          37.\n",
      "   -2.3828573   37.         -37.           0.97598994  36.674095\n",
      "  -36.420788    35.999996   -36.          -0.88105077  37.\n",
      "    0.8534261  -36.99993    -35.99972     36.83667    -36.999866\n",
      "    4.366255     2.4264574   36.864784   -36.          36.27694   ]]\n",
      "T 2\n",
      "P 2\n",
      "T [-1.44544906]\n",
      "P [[-0.9271432]]\n",
      "[[-37.08027    -37.999996    37.999996   -37.906578   -37.\n",
      "   37.          37.335968    37.99978    -37.998714   -37.999996\n",
      "   38.          -0.99997     37.878494    38.         -38.\n",
      "  -37.791157    36.999916    37.999474    -0.9999921   38.\n",
      "  -37.          36.99999     37.39409    -36.999985   -38.\n",
      "   37.          38.          38.          38.         -37.240944\n",
      "  -37.1633     -37.          -1.3137765   37.999992   -37.999996\n",
      "   36.999958    37.99995    -37.99961     36.99988     37.311584\n",
      "  -37.999157    -1.7466428   38.         -37.140625   -36.999958\n",
      "   37.999912   -37.          37.         -36.999992    -1.3602462\n",
      "   37.734764    37.958366   -37.99991     37.552006     0.9888542\n",
      "   36.99978     36.999985    38.          38.          37.902943\n",
      "  -37.999695   -37.999992    37.94656     37.         -36.999977\n",
      "  -37.99999    -37.          38.          -2.1749082   38.\n",
      "  -36.999996   -37.999866    37.          36.99959     37.510216\n",
      "   37.999985   -38.          37.999977   -37.          38.\n",
      "   -1.4563972   38.         -38.           1.3030316   37.674095\n",
      "  -37.420788    36.999996   -37.          -0.97478396  38.\n",
      "    1.0924163  -37.99993    -36.999718    37.83667    -37.999866\n",
      "    4.004041     2.6644733   37.864784   -37.          37.27694   ]]\n",
      "T 15\n",
      "P 4\n",
      "T [-1.86711124]\n",
      "P [[-0.90241563]]\n",
      "[[-38.08027   -38.999996   38.999996  -38.906578  -38.         38.\n",
      "   38.335968   38.99978   -38.998714  -38.999996   39.         -1.\n",
      "   38.87849    39.        -39.        -38.791157   37.999916   38.999474\n",
      "   -0.2742563  39.        -38.         37.99999    38.394085  -37.999985\n",
      "  -39.         38.         39.         39.         39.        -38.240944\n",
      "  -38.1633    -38.         -1.         38.999992  -38.999996   37.999958\n",
      "   38.99995   -38.999607   37.99988    38.311584  -38.999153   -0.9794986\n",
      "   39.        -38.140625  -37.999958   38.999912  -38.         38.\n",
      "  -37.999992   -1.2661891  38.734764   38.958366  -38.999905   38.552006\n",
      "    0.9884279  37.999775   37.999985   39.         39.         38.902943\n",
      "  -38.999695  -38.999992   38.94656    38.        -37.999977  -38.99999\n",
      "  -38.         39.         -1.5063286  39.        -37.999996  -38.999866\n",
      "   38.         37.999577   38.510216   38.999985  -39.         38.999977\n",
      "  -38.         39.         -1.8658408  39.        -39.          1.5539472\n",
      "   38.674095  -38.420788   37.999996  -38.         -0.9971486  39.\n",
      "   -0.9381588 -38.99993   -37.999718   38.83667   -38.99986     4.8083067\n",
      "    2.6957788  38.864784  -38.         38.27694  ]]\n",
      "T 2\n",
      "P 2\n",
      "T [100.00115863]\n",
      "P [[68.25426]]\n",
      "[[-39.08027    -39.999996    39.999996   -39.906578   -39.\n",
      "   39.          39.335968    39.99978    -39.998714   -39.999996\n",
      "   40.          -0.99389744  39.87849     40.         -40.\n",
      "  -39.791157    38.999916    39.999474    -1.          40.\n",
      "  -39.          38.99999     39.39408    -38.999985   -40.\n",
      "   39.          40.          40.          40.         -39.240944\n",
      "  -39.1633     -39.          -0.9999225   39.999992   -39.999996\n",
      "   38.999958    39.99995    -39.999607    38.99988     39.311584\n",
      "  -39.999153    -1.3000138   40.         -39.140625   -38.999958\n",
      "   39.999912   -39.          39.         -38.999992    -2.1312864\n",
      "   39.734764    39.958366   -39.999905    39.552006     0.9979753\n",
      "   38.99977     38.999985    40.          40.          39.902943\n",
      "  -39.999695   -39.999992    39.94656     39.         -38.999977\n",
      "  -39.99999    -39.          40.          -0.22945172  40.\n",
      "  -38.999996   -39.999863    39.          38.999577    39.510216\n",
      "   39.999985   -40.          39.999977   -39.          40.\n",
      "   -2.1389065   40.         -40.           1.8988328   39.674095\n",
      "  -39.420788    38.999996   -39.          -0.99998325  40.\n",
      "    0.86488336 -39.99993    -38.999718    39.83667    -39.99986\n",
      "    4.5118966    3.074789    39.864784   -39.          39.27694   ]]\n",
      "T 6\n",
      "P 8\n",
      "T [-0.11367241]\n",
      "P [[-0.874061]]\n",
      "[[-40.08027    -40.999996    40.999996   -40.906578   -40.\n",
      "   40.          40.335968    40.99978    -40.998714   -40.999996\n",
      "   41.          -0.99993044  40.87849     41.         -41.\n",
      "  -40.791157    39.999916    40.999466    -0.9999278   41.\n",
      "  -40.          39.99999     40.394073   -39.999985   -41.\n",
      "   40.          41.          41.          41.         -40.240944\n",
      "  -40.1633     -40.          -1.0710142   40.999992   -40.999996\n",
      "   39.999958    40.99995    -40.999603    39.99988     40.311584\n",
      "  -40.999153    -1.9435592   41.         -40.140625   -39.999958\n",
      "   40.999912   -40.          40.         -39.999992    -1.2412543\n",
      "   40.734764    40.958366   -40.999905    40.552006    -0.5302321\n",
      "   39.999763    39.999985    41.          41.          40.902943\n",
      "  -40.999695   -40.999992    40.94656     40.         -39.999977\n",
      "  -40.99999    -40.          41.          -1.2120082   41.\n",
      "  -39.999996   -40.999863    40.          39.999565    40.510216\n",
      "   40.999985   -41.          40.999977   -40.          41.\n",
      "   -2.4699001   41.         -41.           0.99922293  40.674095\n",
      "  -40.420788    39.999996   -40.          -0.99999994  41.\n",
      "    1.2937622  -40.99993    -39.999718    40.83667    -40.99985\n",
      "    4.6896253    2.0502958   40.864784   -40.          40.27694   ]]\n",
      "T 12\n",
      "P 5\n",
      "T [-1.49337206]\n",
      "P [[-0.8971373]]\n",
      "[[-41.08027    -41.999996    41.999996   -41.906578   -41.\n",
      "   41.          41.335968    41.99978    -41.998714   -41.999996\n",
      "   42.          -0.9917291   41.87849     42.         -42.\n",
      "  -41.791157    40.999916    41.999466    -0.9993378   42.\n",
      "  -41.          40.99999     41.39407    -40.999985   -42.\n",
      "   41.          42.          42.          42.         -41.240944\n",
      "  -41.1633     -41.          -1.2501409   41.999992   -41.999996\n",
      "   40.999958    41.99995    -41.9996      40.99988     41.311584\n",
      "  -41.999153    -1.0192986   42.         -41.140625   -40.999958\n",
      "   41.999912   -41.          41.         -40.999992    -1.2042538\n",
      "   41.734764    41.958366   -41.9999      41.552006     0.9999499\n",
      "   40.99976     40.999985    42.          42.          41.902943\n",
      "  -41.999695   -41.99999     41.94656     41.         -40.999977\n",
      "  -41.99999    -41.          42.          -1.5211576   42.\n",
      "  -40.999996   -41.999863    41.          40.999565    41.510216\n",
      "   41.999985   -42.          41.999977   -41.          42.\n",
      "   -1.670979    42.         -42.           1.1299372   41.674095\n",
      "  -41.420788    40.999996   -41.          -0.9999958   42.\n",
      "    0.99661744 -41.99993    -40.999702    41.83667    -41.99985\n",
      "    4.6628714    0.65702957  41.864784   -41.          41.276936  ]]\n",
      "T 12\n",
      "P 12\n",
      "T [-1.75543112]\n",
      "P [[-0.97066104]]\n",
      "[[-42.08027    -42.999996    42.999996   -42.906578   -42.\n",
      "   42.          42.335968    42.99978    -42.998714   -42.999996\n",
      "   43.          -0.9970244   42.87849     43.         -43.\n",
      "  -42.791157    41.999912    42.999466    -0.99996823  43.\n",
      "  -42.          41.99999     42.39407    -41.999985   -43.\n",
      "   42.          43.          43.          43.         -42.240944\n",
      "  -42.1633     -42.          -1.0111609   42.999992   -42.999996\n",
      "   41.999958    42.99995    -42.9996      41.99988     42.311584\n",
      "  -42.999153    -0.8822522   43.         -42.140625   -41.999958\n",
      "   42.999912   -42.          42.         -41.999992    -1.1391786\n",
      "   42.734764    42.958366   -42.999897    42.552006     0.9999915\n",
      "   41.999756    41.999985    43.          43.          42.902943\n",
      "  -42.999695   -42.99999     42.94656     42.         -41.999977\n",
      "  -42.99999    -42.          43.          -1.1320708   43.\n",
      "  -41.999996   -42.999863    42.          41.999565    42.510216\n",
      "   42.999985   -43.          42.999977   -42.          43.\n",
      "   -1.7017802   43.         -43.           1.8218012   42.674095\n",
      "  -42.420788    41.999996   -42.          -0.9998625   43.\n",
      "    0.9287545  -42.99993    -41.999702    42.83667    -42.999847\n",
      "    3.8650882    1.1481253   42.864784   -42.          42.276936  ]]\n",
      "T 3\n",
      "P 3\n",
      "T [-1.5677602]\n",
      "P [[-0.89248097]]\n",
      "[[-43.08027    -43.999996    43.999996   -43.906578   -43.\n",
      "   43.          43.335968    43.99978    -43.998714   -43.999996\n",
      "   44.          -0.9995929   43.87849     44.         -44.\n",
      "  -43.791157    42.999912    43.999466    -0.9999994   44.\n",
      "  -43.          42.99999     43.394062   -42.999985   -44.\n",
      "   43.          44.          44.          44.         -43.240944\n",
      "  -43.1633     -43.          -1.5303733   43.999992   -43.999996\n",
      "   42.999958    43.99995    -43.999596    42.99988     43.311584\n",
      "  -43.999153    -0.9999345   44.         -43.140625   -42.999958\n",
      "   43.999912   -43.          43.         -42.999992    -0.9999885\n",
      "   43.734764    43.958366   -43.999897    43.552006     0.99984944\n",
      "   42.999756    42.999985    44.          44.          43.902943\n",
      "  -43.999695   -43.99999     43.94656     43.         -42.999977\n",
      "  -43.99999    -43.          44.          -1.4405415   44.\n",
      "  -42.999996   -43.999863    43.          42.99956     43.510216\n",
      "   43.999985   -44.          43.999977   -43.          44.\n",
      "   -1.9175172   44.         -44.           1.2240998   43.674095\n",
      "  -43.420788    42.999996   -43.          -0.99999917  44.\n",
      "    1.1687965  -43.99993    -42.9997      43.83667    -43.999847\n",
      "    3.1569552    0.47692627  43.864784   -43.          43.276936  ]]\n",
      "T 10\n",
      "P 10\n",
      "T [-1.25482428]\n",
      "P [[-0.9014207]]\n",
      "[[-44.08027    -44.999996    44.999996   -44.906578   -44.\n",
      "   44.          44.335968    44.999775   -44.998714   -44.999996\n",
      "   45.          -0.9999552   44.878487    45.         -45.\n",
      "  -44.791157    43.999912    44.999466    -0.9998711   45.\n",
      "  -44.          43.99999     44.394062   -43.999985   -45.\n",
      "   44.          45.          45.          45.         -44.240944\n",
      "  -44.1633     -44.          -1.1410843   44.999992   -44.999996\n",
      "   43.999958    44.999947   -44.99959     43.999878    44.311584\n",
      "  -44.99915      0.0860343   45.         -44.140625   -43.999958\n",
      "   44.999912   -44.          44.         -43.999992    -0.9999935\n",
      "   44.734764    44.958366   -44.999897    44.552006     0.9530728\n",
      "   43.999752    43.999985    45.          45.          44.902943\n",
      "  -44.999695   -44.99999     44.94656     44.         -43.99997\n",
      "  -44.99999    -44.          45.          -1.384978    45.\n",
      "  -43.999996   -44.999855    44.          43.99954     44.510216\n",
      "   44.999985   -45.          44.999977   -44.          45.\n",
      "   -2.149651    45.         -45.           2.0360022   44.674095\n",
      "  -44.420788    43.999996   -44.          -0.99930507  45.\n",
      "    1.1512799  -44.99993    -43.999695    44.83667    -44.999847\n",
      "    4.1546097    1.4082506   44.864784   -44.          44.27693   ]]\n",
      "T 4\n",
      "P 11\n",
      "T [-1.05918824]\n",
      "P [[-0.97671425]]\n",
      "[[-45.08027    -45.999996    45.999996   -45.906578   -45.\n",
      "   45.          45.335968    45.999775   -45.998707   -45.999996\n",
      "   46.          -0.9999999   45.878475    46.         -46.\n",
      "  -45.791157    44.999912    45.999466    -0.9924801   46.\n",
      "  -45.          44.99999     45.39399    -44.999985   -46.\n",
      "   45.          46.          46.          46.         -45.240944\n",
      "  -45.1633     -45.          -1.016856    45.999992   -45.999996\n",
      "   44.999958    45.999947   -45.999588    44.999874    45.311584\n",
      "  -45.99915     -0.96788937  46.         -45.140625   -44.999954\n",
      "   45.999912   -45.          45.         -44.999992    -1.1127838\n",
      "   45.734764    45.958366   -45.999897    45.552006     0.99955153\n",
      "   44.999752    44.999985    46.          46.          45.902943\n",
      "  -45.99967    -45.99999     45.94656     45.         -44.99997\n",
      "  -45.99999    -45.          46.          -1.6878772   46.\n",
      "  -44.999996   -45.999855    45.          44.999535    45.510216\n",
      "   45.999985   -46.          45.999977   -45.          46.\n",
      "   -2.7857134   46.         -46.           1.1821132   45.674095\n",
      "  -45.420788    44.999996   -45.          -0.9999324   46.\n",
      "    0.6183938  -45.99993    -44.99969     45.83667    -45.999844\n",
      "    5.154485     1.7716267   45.864784   -45.          45.276924  ]]\n",
      "T 4\n",
      "P 11\n",
      "T [-0.51303436]\n",
      "P [[-0.87950623]]\n",
      "[[-46.08027    -46.999996    46.999996   -46.906578   -46.\n",
      "   46.          46.335968    46.999775   -46.998703   -46.999996\n",
      "   47.          -0.9999229   46.87847     47.         -47.\n",
      "  -46.791157    45.999912    46.999466    -0.999986    47.\n",
      "  -46.          45.99999     46.393925   -45.999985   -47.\n",
      "   46.          47.          47.          47.         -46.240944\n",
      "  -46.1633     -46.          -0.99997884  46.999992   -46.999996\n",
      "   45.999958    46.999947   -46.999584    45.999866    46.311584\n",
      "  -46.99915     -1.3879743   47.         -46.140625   -45.99995\n",
      "   46.999912   -46.          46.         -45.999992    -1.630687\n",
      "   46.734764    46.958366   -46.999897    46.552006     0.99373275\n",
      "   45.99975     45.999985    47.          47.          46.902943\n",
      "  -46.99964    -46.99999     46.94656     46.         -45.99997\n",
      "  -46.99999    -46.          47.          -1.4741195   47.\n",
      "  -45.999996   -46.999855    46.          45.99953     46.510216\n",
      "   46.999985   -47.          46.999977   -46.          47.\n",
      "   -3.279622    47.         -47.           0.99999106  46.674095\n",
      "  -46.420788    45.999996   -46.          -0.9999999   47.\n",
      "    1.2913997  -46.99993    -45.999676    46.83667    -46.999836\n",
      "    5.7577977    2.5220613   46.864784   -46.          46.27692   ]]\n",
      "T 6\n",
      "P 11\n",
      "T [-2.22353075]\n",
      "P [[-0.88140833]]\n",
      "[[-47.08027    -47.999996    47.999996   -47.906578   -47.\n",
      "   47.          47.335968    47.999767   -47.9987     -47.999996\n",
      "   48.          -1.          47.87847     48.         -48.\n",
      "  -47.791157    46.999912    47.999466    -0.99845356  48.\n",
      "  -47.          46.99999     47.39391    -46.999985   -48.\n",
      "   47.          48.          48.          48.         -47.240944\n",
      "  -47.1633     -47.          -1.599068    47.999992   -47.999996\n",
      "   46.999954    47.999947   -47.999573    46.999866    47.311584\n",
      "  -47.999126    -2.3057668   48.         -47.140625   -46.99995\n",
      "   47.999912   -47.          47.         -46.999992    -0.99907535\n",
      "   47.734764    47.958366   -47.999893    47.552006    -0.09432443\n",
      "   46.99973     46.999985    48.          48.          47.902943\n",
      "  -47.999634   -47.99999     47.94656     47.         -46.99997\n",
      "  -47.999985   -47.          48.          -2.220007    48.\n",
      "  -46.999996   -47.999855    47.          46.999523    47.510216\n",
      "   47.999985   -48.          47.999977   -47.          48.\n",
      "   -3.679548    48.         -48.           0.94669896  47.674095\n",
      "  -47.420788    46.999996   -47.          -0.7667457   48.\n",
      "    0.94690585 -47.999928   -46.999672    47.83667    -47.999825\n",
      "    3.8714533    1.5860429   47.864784   -47.          47.27691   ]]\n",
      "T 2\n",
      "P 7\n",
      "T [-0.87244846]\n",
      "P [[-0.8778969]]\n",
      "[[-48.08027    -48.999996    48.999996   -48.906578   -48.\n",
      "   48.          48.335968    48.999767   -48.998695   -48.999996\n",
      "   49.          -0.703987    48.878456    49.         -49.\n",
      "  -48.791157    47.999912    48.99946     -1.          49.\n",
      "  -48.          47.99999     48.393883   -47.999985   -49.\n",
      "   48.          49.          49.          49.         -48.240944\n",
      "  -48.1633     -48.          -1.3447915   48.99999    -48.999996\n",
      "   47.999954    48.999947   -48.999535    47.999863    48.311584\n",
      "  -48.999126    -2.6079907   49.         -48.140625   -47.99995\n",
      "   48.999912   -48.          48.         -47.999992    -1.5313587\n",
      "   48.734764    48.958366   -48.999893    48.552006     0.999667\n",
      "   47.999702    47.99998     49.          49.          48.902943\n",
      "  -48.999634   -48.99999     48.94656     48.         -47.99997\n",
      "  -48.999985   -48.          49.          -1.8307843   49.\n",
      "  -47.999996   -48.999775    48.          47.9995      48.510216\n",
      "   48.999985   -49.          48.999977   -48.          49.\n",
      "   -3.399781    49.         -49.           0.9999998   48.674095\n",
      "  -48.420788    47.999996   -48.          -0.96325445  49.\n",
      "    1.5588834  -48.999924   -47.99966     48.83667    -48.999825\n",
      "    3.6130624    1.7325737   48.864784   -48.          48.276886  ]]\n",
      "T 10\n",
      "P 7\n",
      "T [-1.008979]\n",
      "P [[-0.86961997]]\n",
      "[[-49.08027    -49.999996    49.999996   -49.906578   -49.\n",
      "   49.          49.335968    49.999763   -49.998646   -49.999996\n",
      "   50.          -0.998517    49.878452    50.         -50.\n",
      "  -49.791157    48.999912    49.99944     -0.99906075  50.\n",
      "  -49.          48.99999     49.39388    -48.999985   -50.\n",
      "   49.          50.          50.          50.         -49.240944\n",
      "  -49.1633     -49.          -0.99859226  49.99999    -49.999996\n",
      "   48.999954    49.999947   -49.99951     48.999855    49.311584\n",
      "  -49.999123    -2.4501352   50.         -49.140625   -48.99995\n",
      "   49.999912   -49.          49.         -48.999992    -1.2243056\n",
      "   49.734764    49.958366   -49.999893    49.552006    -0.16281739\n",
      "   48.9997      48.99998     50.          50.          49.902943\n",
      "  -49.99963    -49.99999     49.94656     49.         -48.99997\n",
      "  -49.999985   -49.          50.          -2.5183985   50.\n",
      "  -48.999996   -49.999752    49.          48.999454    49.510216\n",
      "   49.999985   -50.          49.999977   -49.          50.\n",
      "   -1.9445305   50.         -50.           1.463083    49.674095\n",
      "  -49.420788    48.999996   -49.          -0.9999932   50.\n",
      "    2.1389174  -49.999924   -48.999657    49.83667    -49.99982\n",
      "    4.575371     2.1111007   49.864784   -49.          49.27688   ]]\n",
      "T 8\n",
      "P 15\n",
      "T [-0.49375141]\n",
      "P [[-0.9501244]]\n",
      "[[-50.08027    -50.999996    50.999996   -50.906578   -50.\n",
      "   50.          50.335968    50.99975    -50.998615   -50.999996\n",
      "   51.          -0.98553246  50.878445    51.         -51.\n",
      "  -50.791157    49.999912    50.999126    -0.99149495  51.\n",
      "  -50.          49.99999     50.393856   -49.999985   -51.\n",
      "   50.          51.          51.          51.         -50.240944\n",
      "  -50.1633     -50.          -0.9999956   50.99999    -50.999992\n",
      "   49.99995     50.999947   -50.999493    49.999855    50.311584\n",
      "  -50.999123    -2.1704216   51.         -50.140625   -49.99995\n",
      "   50.999912   -50.          50.         -49.999992    -0.9999685\n",
      "   50.734764    50.958366   -50.99989     50.552006     0.97669417\n",
      "   49.999683    49.99998     51.          51.          50.902943\n",
      "  -50.999626   -50.99999     50.94656     50.         -49.99997\n",
      "  -50.999985   -50.          51.          -3.2492135   51.\n",
      "  -49.999996   -50.99975     50.          49.999424    50.510216\n",
      "   50.999985   -51.          50.999973   -50.          51.\n",
      "   -1.7833226   51.         -51.           0.9996581   50.674095\n",
      "  -50.420788    49.999996   -50.          -0.9999853   51.\n",
      "    3.1386874  -50.99992    -49.99962     50.83667    -50.999798\n",
      "    5.57537      1.578085    50.864784   -50.          50.276875  ]]\n",
      "T 15\n",
      "P 15\n",
      "T [-0.24693167]\n",
      "P [[-0.9270016]]\n",
      "[[-51.08027    -51.999996    51.999996   -51.906578   -51.\n",
      "   51.          51.335968    51.99975    -51.998615   -51.999996\n",
      "   52.          -1.          51.87844     52.         -52.\n",
      "  -51.791157    50.999912    51.999126     0.18693464  52.\n",
      "  -51.          50.99999     51.39385    -50.999985   -52.\n",
      "   51.          52.          52.          52.         -51.240944\n",
      "  -51.1633     -51.          -0.9999999   51.99999    -51.999992\n",
      "   50.99995     51.999947   -51.99949     50.99985     51.311584\n",
      "  -51.999115     0.38262802  52.         -51.140625   -50.99995\n",
      "   51.999912   -51.          51.         -50.999992    -0.9947463\n",
      "   51.734764    51.958366   -51.99988     51.552006     0.88392264\n",
      "   50.99968     50.99998     52.          52.          51.902943\n",
      "  -51.999626   -51.99999     51.94656     51.         -50.99997\n",
      "  -51.999985   -51.          52.          -2.0148377   52.\n",
      "  -50.999996   -51.99975     51.          50.999393    51.510216\n",
      "   51.999985   -52.          51.999973   -51.          52.\n",
      "   -2.0002465   52.         -52.           1.1730226   51.674095\n",
      "  -51.420788    50.999996   -51.          -0.9984657   52.\n",
      "   -0.7837812  -51.999916   -50.999615    51.83667    -51.99978\n",
      "    6.4312387    2.0534706   51.864784   -51.          51.276875  ]]\n",
      "T 2\n",
      "P 2\n",
      "T [100.91643487]\n",
      "P [[101.57259]]\n",
      "[[-52.08027    -52.999996    52.999996   -52.906578   -52.\n",
      "   52.          52.335968    52.99975    -52.998615   -52.999996\n",
      "   53.          -0.8073947   52.878418    53.         -53.\n",
      "  -52.791157    51.999912    52.99912     -1.          53.\n",
      "  -52.          51.99999     52.39383    -51.999985   -53.\n",
      "   52.          53.          53.          53.         -52.240944\n",
      "  -52.1633     -52.          -1.1897731   52.999985   -52.999992\n",
      "   51.99995     52.999947   -52.99948     51.999847    52.311584\n",
      "  -52.999115    -0.7698232   53.         -52.140625   -51.99995\n",
      "   52.999912   -52.          52.         -51.999992    -1.5599349\n",
      "   52.734764    52.958366   -52.99988     52.552006     0.9916085\n",
      "   51.999676    51.99998     53.          53.          52.902943\n",
      "  -52.999626   -52.99999     52.94656     52.         -51.99997\n",
      "  -52.999985   -52.          53.          -1.1014479   53.\n",
      "  -51.999996   -52.99974     52.          51.999386    52.510216\n",
      "   52.999985   -53.          52.999973   -52.          53.\n",
      "   -2.3032758   53.         -53.           1.4176332   52.674095\n",
      "  -52.420788    51.999996   -52.          -1.          53.\n",
      "    0.51756227 -52.999916   -51.999615    52.83667    -52.99978\n",
      "    7.164872     2.9148831   52.864784   -52.          52.27687   ]]\n",
      "T 7\n",
      "P 7\n",
      "T [-0.21319151]\n",
      "P [[-0.9138516]]\n",
      "[[-53.08027    -53.999996    53.999996   -53.906578   -53.\n",
      "   53.          53.335968    53.99975    -53.998615   -53.999996\n",
      "   54.          -0.9989583   53.878418    54.         -54.\n",
      "  -53.791157    52.999905    53.999115    -0.99955696  54.\n",
      "  -53.          52.999985    53.393826   -52.999985   -54.\n",
      "   53.          54.          54.          54.         -53.240944\n",
      "  -53.1633     -53.          -0.9999989   53.999985   -53.999992\n",
      "   52.99995     53.999947   -53.99948     52.999847    53.311584\n",
      "  -53.999115    -1.3464949   54.         -53.140625   -52.99995\n",
      "   53.999912   -53.          53.         -52.999992    -2.1627703\n",
      "   53.734764    53.958366   -53.999878    53.552006     0.99970615\n",
      "   52.999672    52.99998     53.999996    54.          53.902943\n",
      "  -53.999626   -53.99999     53.94656     53.         -52.99997\n",
      "  -53.999985   -53.          54.          -1.2691319   54.\n",
      "  -52.999996   -53.999737    53.          52.999382    53.510216\n",
      "   53.999985   -54.          53.99997    -53.          54.\n",
      "   -1.4013994   54.         -54.           2.2227006   53.674095\n",
      "  -53.420788    52.999996   -53.          -1.084022    54.\n",
      "    1.0730917  -53.999916   -52.999615    53.83667    -53.99978\n",
      "    7.0406313    1.4074018   53.864784   -53.          53.276855  ]]\n",
      "T 6\n",
      "P 4\n",
      "T [-2.09273078]\n",
      "P [[-0.8687898]]\n",
      "[[-54.08027    -54.999996    54.999996   -54.906578   -54.\n",
      "   54.          54.335968    54.99975    -54.998615   -54.999996\n",
      "   55.          -0.9999988   54.878418    55.         -55.\n",
      "  -54.791157    53.999905    54.999115    -0.999996    55.\n",
      "  -54.          53.999985    54.393826   -53.999985   -55.\n",
      "   54.          55.          55.          55.         -54.240944\n",
      "  -54.1633     -54.          -0.9999438   54.999985   -54.999992\n",
      "   53.99995     54.999947   -54.99948     53.999847    54.311584\n",
      "  -54.999115    -1.6952708   55.         -54.140625   -53.99995\n",
      "   54.999912   -54.          54.         -53.999992    -1.688134\n",
      "   54.734764    54.958366   -54.999878    54.552006     0.40052783\n",
      "   53.999672    53.99998     54.999996    55.          54.902943\n",
      "  -54.999626   -54.99999     54.94656     54.         -53.99997\n",
      "  -54.999985   -54.          55.          -1.701024    55.\n",
      "  -53.999996   -54.999737    54.          53.99938     54.510216\n",
      "   54.999985   -55.          54.99997    -54.          55.\n",
      "   -2.2661338   55.         -55.           1.9388525   54.674095\n",
      "  -54.420788    53.999996   -54.          -1.1438348   55.\n",
      "    0.9145511  -54.999916   -53.999615    54.83667    -54.999775\n",
      "    4.3946724    1.0648302   54.864784   -54.          54.276855  ]]\n",
      "T 3\n",
      "P 3\n",
      "T [-1.67689365]\n",
      "P [[-0.8743216]]\n",
      "[[-55.08027    -55.999996    55.999996   -55.906578   -55.\n",
      "   55.          55.335968    55.99975    -55.998608   -55.999996\n",
      "   56.          -0.9986083   55.878418    56.         -56.\n",
      "  -55.791157    54.999905    55.999115    -0.99999785  56.\n",
      "  -55.          54.999985    55.393814   -54.999985   -56.\n",
      "   55.          56.          56.          56.         -55.240944\n",
      "  -55.1633     -55.          -1.521891    55.999985   -55.999992\n",
      "   54.99995     55.999947   -55.99948     54.999847    55.311584\n",
      "  -55.999115    -1.0271734   56.         -55.140625   -54.99995\n",
      "   55.999912   -55.          55.         -54.999992    -0.99996686\n",
      "   55.734764    55.958366   -55.999878    55.552006     0.99970436\n",
      "   54.999672    54.99998     55.999996    56.          55.902943\n",
      "  -55.999626   -55.99999     55.94656     55.         -54.99997\n",
      "  -55.999985   -55.          56.          -1.8063525   56.\n",
      "  -54.999996   -55.999737    55.          54.999374    55.510216\n",
      "   55.999985   -56.          55.99997    -55.          56.\n",
      "   -2.3193054   56.         -56.           0.9998927   55.674095\n",
      "  -55.420788    54.999996   -55.          -0.9999986   56.\n",
      "    1.2181088  -55.999916   -54.999607    55.83667    -55.999775\n",
      "    3.8727412    0.8299264   55.864784   -55.          55.276855  ]]\n",
      "T 5\n",
      "P 3\n",
      "T [-2.06076827]\n",
      "P [[-0.8918973]]\n",
      "[[-56.08027    -56.999996    56.999996   -56.906578   -56.\n",
      "   56.          56.335968    56.999744   -56.99857    -56.999996\n",
      "   57.          -0.9999728   56.878418    57.         -57.\n",
      "  -56.791157    55.999905    56.99911     -0.9999801   57.\n",
      "  -56.          55.999985    56.393806   -55.999985   -57.\n",
      "   56.          57.          57.          57.         -56.240944\n",
      "  -56.1633     -56.          -1.5971512   56.999985   -56.999992\n",
      "   55.99995     56.999947   -56.999462    55.999847    56.311584\n",
      "  -56.999115    -1.261091    57.         -56.140625   -55.99995\n",
      "   56.999912   -56.          56.         -55.999992    -1.601204\n",
      "   56.734764    56.958366   -56.999874    56.552006     0.65905786\n",
      "   55.999664    55.99998     56.999996    57.          56.902943\n",
      "  -56.9996     -56.99999     56.94656     56.         -55.99997\n",
      "  -56.999985   -56.          57.          -1.7744635   57.\n",
      "  -55.999996   -56.999737    56.          55.999344    56.510216\n",
      "   56.999985   -57.          56.99997    -56.          57.\n",
      "   -1.8844826   57.         -57.           1.1643895   56.674095\n",
      "  -56.420788    55.999996   -56.          -0.9050041   57.\n",
      "    1.0992211  -56.999916   -55.999603    56.83667    -56.99977\n",
      "    4.745984     1.777638    56.864784   -56.          56.27685   ]]\n",
      "T 12\n",
      "P 12\n",
      "T [-1.78163994]\n",
      "P [[-0.89093864]]\n",
      "[[-57.08027    -57.999996    57.999996   -57.906578   -57.\n",
      "   57.          57.335968    57.999744   -57.99857    -57.999996\n",
      "   58.          -0.9995619   57.878418    58.         -58.\n",
      "  -57.791157    56.9999      57.99911     -0.9999944   58.\n",
      "  -57.          56.999985    57.393806   -56.999985   -58.\n",
      "   57.          58.          58.          58.         -57.240944\n",
      "  -57.1633     -57.          -0.9999938   57.999985   -57.999992\n",
      "   56.99995     57.999947   -57.999462    56.999847    57.311584\n",
      "  -57.999115    -0.99589616  58.         -57.140625   -56.99995\n",
      "   57.999912   -57.          57.         -56.999992    -1.4186844\n",
      "   57.734764    57.958366   -57.999874    57.552006     0.999998\n",
      "   56.999664    56.99998     57.999996    58.          57.902943\n",
      "  -57.9996     -57.99999     57.94656     57.         -56.99997\n",
      "  -57.999985   -57.          58.          -1.0469799   58.\n",
      "  -56.999996   -57.999737    57.          56.999344    57.510216\n",
      "   57.999985   -58.          57.99997    -57.          58.\n",
      "   -2.0476778   58.         -58.           1.9250944   57.674095\n",
      "  -57.420788    56.999996   -57.          -0.9998065   58.\n",
      "    0.9494493  -57.999916   -56.9996      57.83667    -57.99977\n",
      "    3.732289     0.99913096  57.864784   -57.          57.27685   ]]\n",
      "T 3\n",
      "P 3\n",
      "T [-0.38490665]\n",
      "P [[-0.88989174]]\n",
      "[[-58.08027    -58.999996    58.999996   -58.906578   -58.\n",
      "   58.          58.335968    58.999744   -58.99857    -58.999996\n",
      "   59.          -0.6592521   58.878414    59.         -59.\n",
      "  -58.791157    57.9999      58.99911     -1.          59.\n",
      "  -58.          57.999985    58.393795   -57.999985   -59.\n",
      "   58.          59.          59.          59.         -58.240944\n",
      "  -58.1633     -58.          -1.2428281   58.999985   -58.999992\n",
      "   57.99995     58.999947   -58.999462    57.999847    58.311584\n",
      "  -58.999115    -1.2713479   59.         -58.140625   -57.99995\n",
      "   58.999912   -58.          58.         -57.999992    -0.99999994\n",
      "   58.734764    58.958366   -58.999874    58.552006     0.99797785\n",
      "   57.99966     57.99998     58.999996    59.          58.902943\n",
      "  -58.9996     -58.99999     58.94656     58.         -57.99997\n",
      "  -58.999985   -58.          59.          -1.4434522   59.\n",
      "  -57.999996   -58.999737    58.          57.99934     58.510216\n",
      "   58.999985   -59.          58.99997    -58.          59.\n",
      "   -2.1674848   59.         -59.           1.2471      58.674095\n",
      "  -58.420788    57.999996   -58.          -1.          59.\n",
      "    1.6866027  -58.999916   -57.999596    58.83667    -58.999767\n",
      "    2.9400406    1.1841677   58.864784   -58.          58.27685   ]]\n",
      "T 7\n",
      "P 1\n",
      "T [-1.18090302]\n",
      "P [[-0.89343584]]\n",
      "[[-59.08027    -59.999996    59.999996   -59.906578   -59.\n",
      "   59.          59.335968    59.999744   -59.99857    -59.999996\n",
      "   60.          -0.9891714   59.8784      60.         -60.\n",
      "  -59.791157    58.999893    59.999092    -0.99987596  60.\n",
      "  -59.          58.999985    59.39378    -58.999985   -60.\n",
      "   59.          60.          60.          60.         -59.240944\n",
      "  -59.1633     -59.          -0.99999905  59.999977   -59.999992\n",
      "   58.99995     59.999947   -59.99945     58.999847    59.311584\n",
      "  -59.999115    -1.584657    60.         -59.140625   -58.99995\n",
      "   59.999912   -59.          59.         -58.999992    -1.591644\n",
      "   59.734764    59.958366   -59.999874    59.552006     0.9907472\n",
      "   58.999657    58.99998     59.999996    60.          59.902943\n",
      "  -59.9996     -59.999985    59.94656     59.         -58.99997\n",
      "  -59.999985   -59.          60.          -2.1529212   60.\n",
      "  -58.999996   -59.999737    59.          58.999332    59.510216\n",
      "   59.999985   -60.          59.99997    -59.          60.\n",
      "   -1.7842672   60.         -60.           1.7539179   59.674095\n",
      "  -59.420788    58.999996   -59.          -1.          60.\n",
      "    2.0792158  -59.999916   -58.999596    59.83667    -59.999767\n",
      "    3.9384701    1.1715673   59.864784   -59.          59.276848  ]]\n",
      "T 3\n",
      "P 3\n",
      "T [-0.33259667]\n",
      "P [[-0.87274635]]\n",
      "[[-60.08027    -60.999996    60.999996   -60.906578   -60.\n",
      "   60.          60.335968    60.999744   -60.99856    -60.999996\n",
      "   61.          -0.94543386  60.878395    61.         -61.\n",
      "  -60.791157    59.999893    60.999077    -0.9999995   61.\n",
      "  -60.          59.999985    60.393723   -59.999985   -61.\n",
      "   60.          61.          61.          61.         -60.240944\n",
      "  -60.1633     -60.          -1.1570892   60.999977   -60.999992\n",
      "   59.99995     60.999947   -60.999447    59.999847    60.311584\n",
      "  -60.999115    -1.7681965   61.         -60.140625   -59.99995\n",
      "   60.999912   -60.          60.         -59.999992    -0.9999918\n",
      "   60.734764    60.958366   -60.999874    60.552006     0.9990688\n",
      "   59.999653    59.99998     60.999996    61.          60.902943\n",
      "  -60.999596   -60.999985    60.94656     60.         -59.99997\n",
      "  -60.999985   -60.          61.          -3.1515467   61.\n",
      "  -59.999996   -60.999737    60.          59.99933     60.510216\n",
      "   60.999985   -61.          60.99997    -60.          61.\n",
      "   -2.0386837   61.         -61.           1.0942785   60.674095\n",
      "  -60.420788    59.999996   -60.          -1.          61.\n",
      "    2.980674   -60.999912   -59.99958     60.83667    -60.999763\n",
      "    3.9953732    1.1602339   60.864784   -60.          60.276848  ]]\n",
      "T 6\n",
      "P 1\n",
      "T [-0.93772802]\n",
      "P [[-0.87351835]]\n",
      "[[-61.08027    -61.999996    61.999996   -61.906578   -61.\n",
      "   61.          61.335968    61.999744   -61.99856    -61.999996\n",
      "   62.          -0.99999994  61.878395    62.         -62.\n",
      "  -61.791157    60.999893    61.999077    -0.9939737   62.\n",
      "  -61.          60.999985    61.393715   -60.999985   -62.\n",
      "   61.          62.          62.          62.         -61.240944\n",
      "  -61.1633     -61.          -1.697682    61.999977   -61.999992\n",
      "   60.99995     61.999947   -61.999443    60.999847    61.311584\n",
      "  -61.999115    -2.0679674   62.         -61.140625   -60.99995\n",
      "   61.999912   -61.          61.         -60.999992    -0.9999426\n",
      "   61.734764    61.958366   -61.99987     61.552006    -0.47219357\n",
      "   60.999645    60.99998     61.999996    62.          61.902943\n",
      "  -61.99959    -61.999985    61.94656     61.         -60.99997\n",
      "  -61.999985   -61.          62.          -4.1515465   62.\n",
      "  -60.999996   -61.999737    61.          60.999325    61.510216\n",
      "   61.999985   -62.          61.99997    -61.          62.\n",
      "   -2.040496    62.         -62.           0.9884942   61.674095\n",
      "  -61.420788    60.999996   -61.          -0.9999982   62.\n",
      "    0.5901444  -61.99991    -60.99958     61.83667    -61.999744\n",
      "    3.5103679    1.3756558   61.864784   -61.          61.276848  ]]\n",
      "T 7\n",
      "P 7\n",
      "T [-0.60143798]\n",
      "P [[-1.149362]]\n",
      "[[-62.08027    -62.999996    62.999996   -62.906578   -62.\n",
      "   62.          62.335968    62.999744   -62.99856    -62.999996\n",
      "   63.          -0.87960804  62.87838     63.         -63.\n",
      "  -62.791157    61.99988     62.999077    -0.99999994  63.\n",
      "  -62.          61.99998     62.393707   -61.999985   -63.\n",
      "   62.          63.          63.          63.         -62.240944\n",
      "  -62.1633     -62.          -1.2436959   62.99996    -62.999992\n",
      "   61.99995     62.999947   -62.99944     61.999847    62.311584\n",
      "  -62.999115    -2.394011    63.         -62.140625   -61.99995\n",
      "   62.999912   -62.          62.         -61.999992    -1.6283133\n",
      "   62.734764    62.958366   -62.99987     62.552006     0.99997526\n",
      "   61.99964     61.999977    62.999996    63.          62.902943\n",
      "  -62.99959    -62.999985    62.94656     62.         -61.99997\n",
      "  -62.999985   -62.          63.          -2.5715852   63.\n",
      "  -61.999996   -62.99969     62.          61.999325    62.510216\n",
      "   62.999985   -63.          62.99997    -62.          63.\n",
      "   -2.6377773   63.         -63.           1.5148702   62.674095\n",
      "  -62.420788    61.999996   -62.          -1.          63.\n",
      "    1.1737231  -62.99991    -61.999577    62.83667    -62.999744\n",
      "    4.20204      1.1853006   62.864784   -62.          62.276825  ]]\n",
      "T 9\n",
      "P 3\n",
      "T [0.28373422]\n",
      "P [[-0.8733572]]\n",
      "[[-6.3080269e+01 -6.3999996e+01  6.3999996e+01 -6.3906578e+01\n",
      "  -6.3000000e+01  6.3000000e+01  6.3335968e+01  6.3999741e+01\n",
      "  -6.3998562e+01 -6.3999996e+01  6.4000000e+01 -9.9999803e-01\n",
      "   6.3878380e+01  6.4000000e+01 -6.4000000e+01 -6.3791157e+01\n",
      "   6.2999882e+01  6.3999039e+01 -9.9997795e-01  6.4000000e+01\n",
      "  -6.3000000e+01  6.2999981e+01  6.3393665e+01 -6.2999985e+01\n",
      "  -6.4000000e+01  6.3000000e+01  6.4000000e+01  6.4000000e+01\n",
      "   6.4000000e+01 -6.3240944e+01 -6.3163300e+01 -6.3000000e+01\n",
      "  -1.0413136e+00  6.3999962e+01 -6.3999992e+01  6.2999947e+01\n",
      "   6.3999947e+01 -6.3999420e+01  6.2999844e+01  6.3311584e+01\n",
      "  -6.3999115e+01 -3.2353454e+00  6.4000000e+01 -6.3140625e+01\n",
      "  -6.2999924e+01  6.3999912e+01 -6.3000000e+01  6.3000000e+01\n",
      "  -6.2999992e+01 -1.0526919e+00  6.3734764e+01  6.3958366e+01\n",
      "  -6.3999866e+01  6.3552006e+01  9.9947864e-01  6.2999638e+01\n",
      "   6.2999977e+01  6.3999996e+01  6.4000000e+01  6.3902943e+01\n",
      "  -6.3999580e+01 -6.3999985e+01  6.3946560e+01  6.3000000e+01\n",
      "  -6.2999969e+01 -6.3999985e+01 -6.3000000e+01  6.4000000e+01\n",
      "  -2.9511347e+00  6.4000000e+01 -6.2999996e+01 -6.3999691e+01\n",
      "   6.3000000e+01  6.2999325e+01  6.3510216e+01  6.3999985e+01\n",
      "  -6.4000000e+01  6.3999969e+01 -6.3000000e+01  6.4000000e+01\n",
      "  -2.4028730e+00  6.4000000e+01 -6.4000000e+01 -2.0859703e-02\n",
      "   6.3674095e+01 -6.3420788e+01  6.2999996e+01 -6.3000000e+01\n",
      "  -9.9999928e-01  6.4000000e+01 -6.6609573e-01 -6.3999905e+01\n",
      "  -6.2999561e+01  6.3836670e+01 -6.3999718e+01  3.7811801e+00\n",
      "   1.2283083e+00  6.3864784e+01 -6.3000000e+01  6.3276814e+01]]\n",
      "T 14\n",
      "P 14\n",
      "T [-68.58160795]\n",
      "P [[-70.18871]]\n",
      "[[-64.08027   -65.         65.        -64.90658   -64.         64.\n",
      "   64.33597    64.99974   -64.99856   -65.         65.         -0.9949267\n",
      "   64.87837    65.        -65.        -64.79115    63.999874   64.99904\n",
      "   -0.9999938  65.        -64.         63.99998    64.39365   -63.999985\n",
      "  -65.         64.         65.         65.         65.        -64.240944\n",
      "  -64.1633    -64.         -1.2979128  64.99996   -64.99999    63.999947\n",
      "   64.99994   -64.999405   63.999844   64.311584  -64.999115   -1.8461665\n",
      "   65.        -64.140625  -63.999924   64.99991   -64.         64.\n",
      "  -63.999992   -1.2131572  64.734764   64.95837   -64.99986    64.552\n",
      "    0.9971709  63.999634   63.999977   65.         65.         64.90294\n",
      "  -64.99958   -64.999985   64.94656    64.        -63.99997   -64.999985\n",
      "  -64.         65.         -1.2377871  65.        -63.999996  -64.999596\n",
      "   64.         63.99932    64.510216   64.999985  -65.         64.99997\n",
      "  -64.         65.         -3.1323245  65.        -65.          0.9869785\n",
      "   64.674095  -64.42079    63.999996  -64.         -1.         65.\n",
      "    0.7248954 -64.9999    -63.999554   64.83667   -64.99972     3.4080868\n",
      "    1.2341479  64.864784  -64.         64.27681  ]]\n",
      "T 4\n",
      "P 12\n",
      "T [-0.03132631]\n",
      "P [[-1.4888054]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-65.08027   -66.         66.        -65.90658   -65.         65.\n",
      "   65.33597    65.99974   -65.99854   -66.         66.         -0.9999999\n",
      "   65.87837    66.        -66.        -65.79115    64.99987    65.99904\n",
      "   -0.8457094  66.        -65.         64.99998    65.39364   -64.999985\n",
      "  -66.         65.         66.         66.         66.        -65.240944\n",
      "  -65.1633    -65.         -1.4080774  65.99996   -65.99999    64.99994\n",
      "   65.99994   -65.999405   64.99984    65.311584  -65.999115   -0.9998942\n",
      "   66.        -65.140625  -64.999916   65.99991   -65.         65.\n",
      "  -64.99999    -1.1496072  65.734764   65.95837   -65.99986    65.552\n",
      "    0.9997805  64.99963    64.99998    66.         66.         65.90294\n",
      "  -65.99958   -65.999985   65.94656    65.        -64.99996   -65.999985\n",
      "  -65.         66.         -1.4496361  66.        -64.99999   -65.999596\n",
      "   65.         64.99931    65.510216   65.999985  -66.         65.99997\n",
      "  -65.         66.         -2.4244175  66.        -66.          1.0407819\n",
      "   65.674095  -65.42079    64.99999   -65.         -0.9995008  66.\n",
      "    0.0783236 -65.9999    -64.99955    65.83667   -65.99972     4.408055\n",
      "    1.8261704  65.864784  -65.         65.27681  ]]\n",
      "T 9\n",
      "P 11\n",
      "T [-0.06228149]\n",
      "P [[-0.88615906]]\n",
      "[[-66.08027   -67.         67.        -66.90658   -66.         66.\n",
      "   66.33597    66.99974   -66.99854   -67.         67.         -0.9213466\n",
      "   66.878365   67.        -67.        -66.79115    65.99987    66.998985\n",
      "   -1.         67.        -66.         65.99998    66.39353   -65.999985\n",
      "  -67.         66.         67.         67.         67.        -66.240944\n",
      "  -66.1633    -66.         -1.4301095  66.99996   -66.99999    65.99994\n",
      "   66.99994   -66.999374   65.99984    66.311584  -66.999115   -1.5766535\n",
      "   67.        -66.140625  -65.99991    66.99991   -66.         66.\n",
      "  -65.99999    -1.1002924  66.734764   66.95837   -66.99986    66.552\n",
      "    0.9998558  65.99962    65.99998    67.         67.         66.90294\n",
      "  -66.99956   -66.999985   66.94656    66.        -65.99996   -66.999985\n",
      "  -66.         67.         -1.2325835  67.        -65.99999   -66.999596\n",
      "   66.         65.999306   66.510216   66.999985  -67.         66.99997\n",
      "  -66.         67.         -3.1380193  67.        -67.          1.0536681\n",
      "   66.674095  -66.42079    65.99999   -66.         -1.         67.\n",
      "    1.0402273 -66.9999    -65.99953    66.83667   -66.99971     4.3616724\n",
      "    2.3896415  66.864784  -66.         66.276794 ]]\n",
      "T 12\n",
      "P 12\n",
      "T [-70.73160293]\n",
      "P [[-70.49989]]\n",
      "[[-67.08027    -68.          68.         -67.90658    -67.\n",
      "   67.          67.33597     67.99974    -67.99854    -68.\n",
      "   68.          -0.44483683  67.87836     68.         -68.\n",
      "  -67.79115     66.99986     67.99897     -0.99993557  68.\n",
      "  -67.          66.99998     67.393524   -66.999985   -68.\n",
      "   67.          68.          68.          68.         -67.240944\n",
      "  -67.1633     -67.          -1.0223832   67.99996    -67.99999\n",
      "   66.99994     67.99994    -67.99937     66.99984     67.311584\n",
      "  -67.999115    -1.5076295   68.         -67.140625   -66.99991\n",
      "   67.99991    -67.          67.         -66.99999     -1.041907\n",
      "   67.734764    67.95837    -67.999855    67.552        0.9997751\n",
      "   66.99961     66.99998     68.          68.          67.90294\n",
      "  -67.99956    -67.999985    67.94656     67.         -66.99996\n",
      "  -67.999985   -67.          68.          -1.5976667   68.\n",
      "  -66.99999    -67.999596    67.          66.999306    67.510216\n",
      "   67.999985   -68.          67.99997    -67.          68.\n",
      "   -2.1547954   68.         -68.           1.2800027   67.674095\n",
      "  -67.42079     66.99999    -67.          -0.90782326  68.\n",
      "    1.5677171  -67.9999     -66.99952     67.83667    -67.99971\n",
      "    4.8605514    1.6318407   67.864784   -67.          67.276794  ]]\n",
      "T 2\n",
      "P 12\n",
      "T [-1.68392849]\n",
      "P [[-0.9707593]]\n",
      "[[-68.08027    -69.          69.         -68.90658    -68.\n",
      "   68.          68.33597     68.99974    -68.998535   -69.\n",
      "   69.          -0.9999329   68.87836     69.         -69.\n",
      "  -68.79115     67.99986     68.998924    -0.98792154  69.\n",
      "  -68.          67.99998     68.39352    -67.999985   -69.\n",
      "   68.          69.          69.          69.         -68.240944\n",
      "  -68.1633     -68.          -1.30857     68.99996    -68.99999\n",
      "   67.99994     68.99994    -68.999344    67.99984     68.311584\n",
      "  -68.999115    -1.0134248   69.         -68.140625   -67.99991\n",
      "   68.99991    -68.          68.         -67.99999     -0.9999985\n",
      "   68.734764    68.95837    -68.999855    68.552        0.9978545\n",
      "   67.9996      67.99998     69.          69.          68.90294\n",
      "  -68.99956    -68.999985    68.94656     68.         -67.99996\n",
      "  -68.999985   -68.          69.          -2.2126446   69.\n",
      "  -67.99999    -68.999596    68.          67.99929     68.510216\n",
      "   68.999985   -69.          68.99997    -68.          69.\n",
      "   -1.1682876   69.         -69.           1.1229366   68.674095\n",
      "  -68.42079     67.99999    -68.          -0.99939394  69.\n",
      "    1.5370388  -68.9999     -67.99951     68.83667    -68.99971\n",
      "    4.4135566    0.36338502  68.864784   -68.          68.276794  ]]\n",
      "T 3\n",
      "P 3\n",
      "T [0.65825721]\n",
      "P [[-0.8893329]]\n",
      "[[-69.08027    -70.          70.         -69.90658    -69.\n",
      "   69.          69.33597     69.99974    -69.99853    -70.\n",
      "   70.          -0.94647354  69.87836     70.         -70.\n",
      "  -69.79115     68.99986     69.998924    -0.99999803  70.\n",
      "  -69.          68.99998     69.39351    -68.999985   -70.\n",
      "   69.          70.          70.          70.         -69.240944\n",
      "  -69.1633     -69.          -1.6348159   69.99996    -69.99999\n",
      "   68.99994     69.99994    -69.999344    68.99984     69.311584\n",
      "  -69.999115    -0.9989122   70.         -69.140625   -68.99991\n",
      "   69.99991    -69.          69.         -68.99999     -0.9999979\n",
      "   69.734764    69.95837    -69.999855    69.552        0.9997568\n",
      "   68.9996      68.99998     70.          70.          69.90294\n",
      "  -69.99956    -69.999985    69.94656     69.         -68.99996\n",
      "  -69.999985   -69.          70.          -2.1291637   70.\n",
      "  -68.99999    -69.999596    69.          68.99929     69.510216\n",
      "   69.999985   -70.          69.99997    -69.          70.\n",
      "   -1.282514    70.         -70.           0.9999979   69.674095\n",
      "  -69.42079     68.99999    -69.          -0.99999905  70.\n",
      "    1.649706   -69.9999     -68.999504    69.83667    -69.99971\n",
      "    3.7899961    1.2896736   69.864784   -69.          69.276794  ]]\n",
      "T 7\n",
      "P 3\n",
      "T [0.19104078]\n",
      "P [[-0.8950902]]\n",
      "[[-70.08027    -71.          71.         -70.90658    -70.\n",
      "   70.          70.33597     70.99974    -70.99853    -71.\n",
      "   71.          -0.99557894  70.87836     71.         -71.\n",
      "  -70.79115     69.99986     70.998924    -0.9991843   71.\n",
      "  -70.          69.99998     70.39351    -69.999985   -71.\n",
      "   70.          71.          71.          71.         -70.240944\n",
      "  -70.1633     -70.          -1.7636282   70.99996    -70.99999\n",
      "   69.99994     70.99994    -70.999344    69.99984     70.311584\n",
      "  -70.999115    -1.0459207   71.         -70.140625   -69.99991\n",
      "   70.99991    -70.          70.         -69.99999     -1.275305\n",
      "   70.734764    70.95837    -70.999855    70.552        0.9996192\n",
      "   69.9996      69.99998     71.          71.          70.90294\n",
      "  -70.99956    -70.999985    70.94656     70.         -69.99996\n",
      "  -70.999985   -70.          71.          -2.1378977   71.\n",
      "  -69.99999    -70.99959     70.          69.99929     70.510216\n",
      "   70.999985   -71.          70.99997    -70.          71.\n",
      "   -1.4281373   71.         -71.           1.4683983   70.674095\n",
      "  -70.42079     69.99999    -70.          -0.99999917  71.\n",
      "    1.2605163  -70.9999     -69.999504    70.83667    -70.99971\n",
      "    4.789967     0.6256242   70.864784   -70.          70.276794  ]]\n",
      "T 4\n",
      "P 4\n",
      "T [-1.24223839]\n",
      "P [[-0.91363657]]\n",
      "[[-71.08027    -72.          72.         -71.90658    -71.\n",
      "   71.          71.33597     71.99974    -71.99853    -72.\n",
      "   72.          -0.99999994  71.87836     72.         -72.\n",
      "  -71.79115     70.99986     71.998924    -0.99804884  72.\n",
      "  -71.          70.99998     71.3935     -70.999985   -72.\n",
      "   71.          72.          72.          72.         -71.240944\n",
      "  -71.1633     -71.          -1.38552     71.99996    -71.99999\n",
      "   70.99994     71.99994    -71.999344    70.99984     71.311584\n",
      "  -71.999115    -1.3702068   72.         -71.140625   -70.99991\n",
      "   71.99991    -71.          71.         -70.99999     -1.5436436\n",
      "   71.734764    71.95837    -71.999855    71.552        0.99994034\n",
      "   70.9996      70.99998     72.          72.          71.90294\n",
      "  -71.99954    -71.999985    71.94656     71.         -70.99996\n",
      "  -71.999985   -71.          72.          -1.919615    72.\n",
      "  -70.99999    -71.99959     71.          70.99929     71.510216\n",
      "   71.999985   -72.          71.99997    -71.          72.\n",
      "   -1.7635512   72.         -72.           1.0710903   71.674095\n",
      "  -71.42079     70.99999    -71.          -0.9999405   72.\n",
      "   -0.50210327 -71.9999     -70.999504    71.83667    -71.99971\n",
      "    5.416976     1.4690701   71.864784   -71.          71.276794  ]]\n",
      "T 14\n",
      "P 14\n",
      "T [-1.20409116]\n",
      "P [[-0.96621835]]\n",
      "[[-72.08027    -73.          73.         -72.90658    -72.\n",
      "   72.          72.33597     72.99974    -72.99853    -73.\n",
      "   73.          -1.          72.87836     73.         -73.\n",
      "  -72.79115     71.999855    72.998924    -0.99857444  73.\n",
      "  -72.          71.99998     72.393486   -71.999985   -73.\n",
      "   72.          73.          73.          73.         -72.240944\n",
      "  -72.1633     -72.          -1.5992924   72.99996    -72.99999\n",
      "   71.99994     72.99993    -72.99933     71.99984     72.311584\n",
      "  -72.999115    -1.5951563   73.         -72.140625   -71.99987\n",
      "   72.99991    -72.          72.         -71.99999     -1.233727\n",
      "   72.734764    72.95837    -72.999855    72.552        0.9986266\n",
      "   71.9996      71.99998     73.          73.          72.90294\n",
      "  -72.99954    -72.999985    72.94656     72.         -71.99996\n",
      "  -72.999985   -72.          73.          -1.2732197   73.\n",
      "  -71.99999    -72.99958     72.          71.99929     72.510216\n",
      "   72.999985   -73.          72.99997    -72.          73.\n",
      "   -2.5134559   73.         -73.           1.6531372   72.674095\n",
      "  -72.42079     71.99999    -72.          -0.9256209   73.\n",
      "    0.9971094  -72.99989    -71.9995      72.83667    -72.99971\n",
      "    3.800671     1.3522146   72.864784   -72.          72.27679   ]]\n",
      "T 13\n",
      "P 14\n",
      "T [-1.05398216]\n",
      "P [[-0.9184445]]\n",
      "[[-73.08027    -74.          74.         -73.90658    -73.\n",
      "   73.          73.33597     73.99974    -73.99852    -74.\n",
      "   74.          -0.9981625   73.87836     74.         -74.\n",
      "  -73.79115     72.999855    73.99891     -0.9999944   74.\n",
      "  -73.          72.99998     73.39348    -72.999985   -74.\n",
      "   73.          74.          74.          74.         -73.240944\n",
      "  -73.1633     -73.          -0.99983996  73.99996    -73.99999\n",
      "   72.99994     73.99993    -73.99933     72.99984     73.311584\n",
      "  -73.999115    -1.2340775   74.         -73.140625   -72.99987\n",
      "   73.99991    -73.          73.         -72.99999     -1.4098971\n",
      "   73.734764    73.95837    -73.999855    73.552        0.95357865\n",
      "   72.9996      72.99998     74.          74.          73.90294\n",
      "  -73.99953    -73.999985    73.94656     73.         -72.99996\n",
      "  -73.999985   -73.          74.          -1.637368    74.\n",
      "  -72.99999    -73.99958     73.          72.99927     73.510216\n",
      "   73.999985   -74.          73.99997    -73.          74.\n",
      "   -2.714789    74.         -74.           1.3653282   73.674095\n",
      "  -73.42079     72.99999    -73.          -1.          74.\n",
      "    1.3344082  -73.99989    -72.99949     73.83667    -73.9997\n",
      "    3.7356482    1.5612082   73.864784   -73.          73.27679   ]]\n",
      "T 1\n",
      "P 1\n",
      "T [-2.88906585]\n",
      "P [[-0.9375709]]\n",
      "[[-74.08027   -75.         75.        -74.90658   -74.         74.\n",
      "   74.33597    74.99974   -74.99852   -75.         75.         -0.9981926\n",
      "   74.87836    75.        -75.        -74.79115    73.999855   74.99884\n",
      "   -0.9753364  75.        -74.         73.99998    74.39348   -73.999985\n",
      "  -75.         74.         75.         75.         75.        -74.240944\n",
      "  -74.1633    -74.         -1.2555288  74.99996   -74.99999    73.99994\n",
      "   74.99993   -74.99931    73.99984    74.311584  -74.999115   -0.9988094\n",
      "   75.        -74.140625  -73.99987    74.99991   -74.         74.\n",
      "  -73.99999    -0.9999985  74.734764   74.95837   -74.999855   74.552\n",
      "   -0.4430343  73.9996     73.99998    75.         75.         74.90294\n",
      "  -74.99953   -74.999985   74.94656    74.        -73.99996   -74.999985\n",
      "  -74.         75.         -1.7879875  75.        -73.99999   -74.99958\n",
      "   74.         73.99926    74.510216   74.999985  -75.         74.99997\n",
      "  -74.         75.         -1.9482586  75.        -75.          0.9999932\n",
      "   74.674095  -74.42079    73.99999   -74.         -1.073734   75.\n",
      "    1.3230557 -74.99989   -73.99949    74.83667   -74.9997      3.953845\n",
      "    1.0269817  74.864784  -74.         74.27679  ]]\n",
      "T 12\n",
      "P 2\n",
      "T [-1.71244015]\n",
      "P [[-1.064946]]\n",
      "[[-75.08027    -76.          76.         -75.90658    -75.\n",
      "   75.          75.33597     75.99974    -75.99852    -76.\n",
      "   76.          -0.99359137  75.87836     76.         -76.\n",
      "  -75.79115     74.99985     75.99884     -0.9999804   76.\n",
      "  -75.          74.99998     75.39348    -74.999985   -76.\n",
      "   75.          76.          76.          76.         -75.240944\n",
      "  -75.1633     -75.          -1.0268623   75.99996    -75.99999\n",
      "   74.99994     75.99993    -75.99931     74.99984     75.311584\n",
      "  -75.999115    -1.0094317   76.         -75.140625   -74.99987\n",
      "   75.99991    -75.          75.         -74.99999     -1.2191577\n",
      "   75.734764    75.95837    -75.999855    75.552        0.99999976\n",
      "   74.9996      74.99998     75.999985    76.          75.90294\n",
      "  -75.99953    -75.999985    75.94656     75.         -74.99996\n",
      "  -75.999985   -75.          76.          -1.3388679   76.\n",
      "  -74.99999    -75.99958     75.          74.99926     75.510216\n",
      "   75.999985   -76.          75.99997    -75.          76.\n",
      "   -1.748822    76.         -76.           1.7103198   75.674095\n",
      "  -75.42079     74.99999    -75.          -0.9994202   76.\n",
      "    0.9614051  -75.99989    -74.99949     75.83667    -75.9997\n",
      "    3.3394015    1.1066003   75.864784   -75.          75.27679   ]]\n",
      "T 4\n",
      "P 3\n",
      "T [0.53182731]\n",
      "P [[-0.9006003]]\n",
      "[[-76.08027    -77.          77.         -76.90658    -76.\n",
      "   76.          76.33597     76.99974    -76.99852    -77.\n",
      "   77.          -0.9999906   76.87836     77.         -77.\n",
      "  -76.79115     75.99985     76.99884     -0.999993    77.\n",
      "  -76.          75.99998     76.39347    -75.999985   -77.\n",
      "   76.          77.          77.          77.         -76.240944\n",
      "  -76.1633     -76.          -0.99999845  76.99996    -76.99999\n",
      "   75.99994     76.99993    -76.99931     75.99984     76.311584\n",
      "  -76.999115    -1.2306086   77.         -76.140625   -75.99987\n",
      "   76.99991    -76.          76.         -75.99999     -1.6364388\n",
      "   76.734764    76.95837    -76.999855    76.552        0.9991749\n",
      "   75.9996      75.99998     76.999985    77.          76.90294\n",
      "  -76.99953    -76.999985    76.94656     76.         -75.99996\n",
      "  -76.999985   -76.          77.          -1.2429305   77.\n",
      "  -75.99999    -76.99958     76.          75.99925     76.510216\n",
      "   76.999985   -77.          76.99997    -76.          77.\n",
      "   -2.1918726   77.         -77.           1.2101654   76.674095\n",
      "  -76.42079     75.99999    -76.          -0.9999992   77.\n",
      "    1.2094203  -76.99989    -75.99949     76.83667    -76.9997\n",
      "    3.957861     1.3778778   76.864784   -76.          76.27679   ]]\n",
      "T 5\n",
      "P 4\n",
      "T [-0.69034083]\n",
      "P [[-0.89351857]]\n",
      "[[-77.08027    -78.          78.         -77.90658    -77.\n",
      "   77.          77.33597     77.99973    -77.998405   -78.\n",
      "   78.          -0.99999964  77.87836     78.         -78.\n",
      "  -77.79115     76.99985     77.99883     -0.9997695   78.\n",
      "  -77.          76.99998     77.39346    -76.999985   -78.\n",
      "   77.          78.          78.          78.         -77.240944\n",
      "  -77.1633     -77.          -1.1073397   77.99996    -77.99999\n",
      "   76.99994     77.99993    -77.99929     76.99984     77.311584\n",
      "  -77.999115    -1.6079818   78.         -77.140625   -76.99986\n",
      "   77.99991    -77.          77.         -76.99999     -1.8669392\n",
      "   77.734764    77.95837    -77.999855    77.552        0.7126096\n",
      "   76.999596    76.99998     77.999985    78.          77.90294\n",
      "  -77.99952    -77.999985    77.94656     77.         -76.99996\n",
      "  -77.999985   -77.          78.          -1.6484805   78.\n",
      "  -76.99999    -77.99958     77.          76.99924     77.510216\n",
      "   77.999985   -78.          77.99997    -77.          78.\n",
      "   -2.1520388   78.         -78.           1.0521178   77.674095\n",
      "  -77.42079     76.99999    -77.          -0.82770246  78.\n",
      "    0.9785088  -77.99989    -76.99948     77.83667    -77.9997\n",
      "    4.3241816    1.6515118   77.864784   -77.          77.27678   ]]\n",
      "T 5\n",
      "P 12\n",
      "T [-0.43303818]\n",
      "P [[-0.89418995]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-78.08027    -79.          79.         -78.90658    -78.\n",
      "   78.          78.33597     78.999725   -78.99836    -79.\n",
      "   79.          -0.999999    78.87836     79.         -79.\n",
      "  -78.79115     77.99985     78.99883     -0.99999285  79.\n",
      "  -78.          77.99998     78.39346    -77.999985   -79.\n",
      "   78.          79.          79.          79.         -78.240944\n",
      "  -78.1633     -78.          -1.2426271   78.99996    -78.99999\n",
      "   77.99994     78.99993    -78.999275    77.99984     78.311584\n",
      "  -78.999115    -1.5354989   79.         -78.140625   -77.999855\n",
      "   78.99991    -78.          78.         -77.99999     -2.206059\n",
      "   78.734764    78.95837    -78.999855    78.552        0.89116895\n",
      "   77.999596    77.99998     78.999985    79.          78.90294\n",
      "  -78.99952    -78.999985    78.94656     78.         -77.99996\n",
      "  -78.999985   -78.          79.          -1.6271411   79.\n",
      "  -77.99999    -78.99958     78.          77.99923     78.510216\n",
      "   78.999985   -79.          78.99997    -78.          79.\n",
      "   -2.2476208   79.         -79.           1.285347    78.674095\n",
      "  -78.42079     77.99999    -78.          -0.88116497  79.\n",
      "    0.9979818  -78.99989    -77.99947     78.83667    -78.9997\n",
      "    4.5516686    1.6294584   78.864784   -78.          78.27678   ]]\n",
      "T 0\n",
      "P 12\n",
      "T [-0.08237483]\n",
      "P [[-0.8759707]]\n",
      "[[-79.08027   -80.         80.        -79.90658   -79.         79.\n",
      "   79.33597    79.99972   -79.99833   -80.         80.         -0.9769436\n",
      "   79.87835    80.        -80.        -79.79115    78.99985    79.99883\n",
      "   -1.         80.        -79.         78.99998    79.39344   -78.999985\n",
      "  -80.         79.         80.         80.         80.        -79.240944\n",
      "  -79.1633    -79.         -1.034868   79.99996   -79.99999    78.99994\n",
      "   79.99993   -79.99925    78.99984    79.311584  -79.999115   -1.4553957\n",
      "   80.        -79.140625  -78.99984    79.99991   -79.         79.\n",
      "  -78.99999    -0.9974845  79.734764   79.95837   -79.999855   79.552\n",
      "    0.9999638  78.999596   78.99998    79.999985   80.         79.90294\n",
      "  -79.999504  -79.999985   79.94656    79.        -78.99996   -79.999985\n",
      "  -79.         80.         -1.7338412  80.        -78.99999   -79.99958\n",
      "   79.         78.99923    79.510216   79.999985  -80.         79.99997\n",
      "  -79.         80.         -3.1991727  80.        -80.          1.0238391\n",
      "   79.674095  -79.42079    78.99999   -79.         -0.9999919  80.\n",
      "    1.278111  -79.99989   -78.99946    79.83667   -79.9997      4.0947847\n",
      "    1.6095836  79.864784  -79.         79.27678  ]]\n",
      "T 6\n",
      "P 6\n",
      "T [-1.28112306]\n",
      "P [[-0.88219607]]\n",
      "[[-80.08027    -81.          81.         -80.90658    -80.\n",
      "   80.          80.33597     80.99972    -80.99832    -81.\n",
      "   81.          -0.9999907   80.87835     81.         -81.\n",
      "  -80.79115     79.99985     80.99883     -0.99600005  81.\n",
      "  -80.          79.99998     80.39343    -79.999985   -81.\n",
      "   80.          81.          81.          81.         -80.240944\n",
      "  -80.1633     -80.          -1.4874841   80.99996    -80.99999\n",
      "   79.99994     80.99993    -80.999245    79.99984     80.311584\n",
      "  -80.9991      -1.0473499   81.         -80.140625   -79.99984\n",
      "   80.9999     -80.          80.         -79.99999     -0.9999688\n",
      "   80.734764    80.95837    -80.999855    80.552       -0.6992359\n",
      "   79.99958     79.99998     80.999985    81.          80.90294\n",
      "  -80.999504   -80.999985    80.94656     80.         -79.999954\n",
      "  -80.99998    -80.          81.          -2.4261358   81.\n",
      "  -79.99999    -80.99957     80.          79.99921     80.51021\n",
      "   80.999985   -81.          80.99997    -80.          81.\n",
      "   -2.6894796   81.         -81.           0.99992687  80.674095\n",
      "  -80.42079     79.99999    -80.          -0.9999978   81.\n",
      "    0.9965924  -80.99989    -79.99945     80.83667    -80.9997\n",
      "    3.6904285    0.08738446  80.864784   -80.          80.27678   ]]\n",
      "T 11\n",
      "P 11\n",
      "T [-0.25529143]\n",
      "P [[-0.87604964]]\n",
      "[[-81.08027    -82.          82.         -81.90658    -81.\n",
      "   81.          81.33597     81.99965    -81.99832    -82.\n",
      "   82.          -0.99998957  81.87834     82.         -82.\n",
      "  -81.79115     80.99985     81.99883     -0.99997324  82.\n",
      "  -81.          80.99998     81.39343    -80.999985   -82.\n",
      "   81.          82.          82.          82.         -81.240944\n",
      "  -81.1633     -81.          -1.9283477   81.99996    -81.99999\n",
      "   80.99994     81.99993    -81.99924     80.99984     81.311584\n",
      "  -81.9991      -1.3614254   82.         -81.140625   -80.99984\n",
      "   81.9999     -81.          81.         -80.99999     -0.9909652\n",
      "   81.734764    81.95837    -81.999855    81.552        0.9999999\n",
      "   80.99957     80.99998     81.999985    82.          81.90294\n",
      "  -81.99948    -81.999985    81.94656     81.         -80.999954\n",
      "  -81.99998    -81.          82.          -2.469215    82.\n",
      "  -80.99999    -81.99957     81.          80.99921     81.51021\n",
      "   81.999985   -82.          81.99997    -81.          82.\n",
      "   -2.3968515   82.         -82.           1.0758841   81.674095\n",
      "  -81.42079     80.99999    -81.          -0.9488056   82.\n",
      "    0.9997894  -81.99989    -80.99945     81.83667    -81.9997\n",
      "    3.2418275    1.087384    81.864784   -81.          81.27677   ]]\n",
      "T 1\n",
      "P 2\n",
      "T [-2.37611601]\n",
      "P [[-0.91919625]]\n",
      "[[-82.08027   -83.         83.        -82.90658   -82.         82.\n",
      "   82.33597    82.99965   -82.99832   -83.         83.         -0.6133915\n",
      "   82.87834    83.        -83.        -82.79115    81.99985    82.99875\n",
      "   -0.9999868  83.        -82.         81.99998    82.39343   -81.999985\n",
      "  -83.         82.         83.         83.         83.        -82.240944\n",
      "  -82.1633    -82.         -1.129713   82.99996   -82.99999    81.99994\n",
      "   82.99993   -82.99922    81.99984    82.311584  -82.9991     -1.5137233\n",
      "   83.        -82.140625  -81.99984    82.9999    -82.         82.\n",
      "  -81.99999    -1.3504908  82.734764   82.95837   -82.999855   82.552\n",
      "   -0.6686261  81.99957    81.99998    82.999985   83.         82.90294\n",
      "  -82.99947   -82.999985   82.94656    82.        -81.999954  -82.99998\n",
      "  -82.         83.         -2.1850004  83.        -81.99999   -82.99957\n",
      "   82.         81.9992     82.51021    82.999985  -83.         82.99997\n",
      "  -82.         83.         -2.1392035  83.        -83.          0.9999986\n",
      "   82.674095  -82.42079    81.99999   -82.         -1.1695368  83.\n",
      "    1.5832324 -82.99989   -81.99945    82.83667   -82.99969     4.236186\n",
      "    1.3580484  82.864784  -82.         82.276764 ]]\n",
      "T 2\n",
      "P 2\n",
      "T [-1.1969603]\n",
      "P [[-0.9510244]]\n",
      "[[-83.08027    -84.          84.         -83.90658    -83.\n",
      "   83.          83.33597     83.99965    -83.99832    -84.\n",
      "   84.          -0.99990106  83.87834     84.         -84.\n",
      "  -83.79115     82.99985     83.99874     -0.9996244   84.\n",
      "  -83.          82.99998     83.39343    -82.999985   -84.\n",
      "   83.          84.          84.          84.         -83.240944\n",
      "  -83.1633     -83.          -0.9999994   83.99996    -83.99999\n",
      "   82.99994     83.99993    -83.999214    82.99984     83.311584\n",
      "  -83.9991      -1.5261719   84.         -83.140625   -82.99984\n",
      "   83.9999     -83.          83.         -82.99999     -1.6744224\n",
      "   83.734764    83.95837    -83.999855    83.552        0.9999993\n",
      "   82.999565    82.99998     83.99998     84.          83.90294\n",
      "  -83.99947    -83.999985    83.94656     83.         -82.999954\n",
      "  -83.99998    -83.          84.          -2.7214136   84.\n",
      "  -82.99999    -83.999565    83.          82.99919     83.51021\n",
      "   83.999985   -84.          83.99997    -83.          84.\n",
      "   -1.3994375   84.         -84.           1.538043    83.674095\n",
      "  -83.42079     82.99999    -83.          -0.6647079   84.\n",
      "    1.2099845  -83.99989    -82.99945     83.83667    -83.99969\n",
      "    3.367917     1.083688    83.864784   -83.          83.27676   ]]\n",
      "T 8\n",
      "P 8\n",
      "T [-0.66791527]\n",
      "P [[-0.872646]]\n",
      "[[-84.08027    -85.          85.         -84.90658    -84.\n",
      "   84.          84.33597     84.99965    -84.99832    -85.\n",
      "   85.          -0.9991915   84.87834     85.         -85.\n",
      "  -84.79115     83.99985     84.99874     -0.999991    85.\n",
      "  -84.          83.99998     84.39343    -83.999985   -85.\n",
      "   84.          85.          85.          85.         -84.240944\n",
      "  -84.1633     -84.          -0.9999918   84.99996    -84.99999\n",
      "   83.99994     84.99993    -84.999214    83.99984     84.311584\n",
      "  -84.9991       0.5301426   85.         -84.140625   -83.99984\n",
      "   84.9999     -84.          84.         -83.99999     -1.7872276\n",
      "   84.734764    84.95837    -84.999855    84.552        0.94030637\n",
      "   83.99956     83.99998     84.99998     85.          84.90294\n",
      "  -84.99947    -84.999985    84.94656     84.         -83.999954\n",
      "  -84.99998    -84.          85.          -1.668135    85.\n",
      "  -83.99999    -84.999565    84.          83.99918     84.51021\n",
      "   84.999985   -85.          84.99997    -84.          85.\n",
      "   -1.5240302   85.         -85.           1.5519471   84.674095\n",
      "  -84.42079     83.99999    -84.          -1.0552427   85.\n",
      "    1.432613   -84.99989    -83.99944     84.83667    -84.999664\n",
      "    2.9301949    1.4957124   84.864784   -84.          84.27676   ]]\n",
      "T 1\n",
      "P 1\n",
      "T [-0.04520754]\n",
      "P [[-0.890283]]\n",
      "[[-85.08027    -86.          86.         -85.90658    -85.\n",
      "   85.          85.33597     85.99965    -85.99832    -86.\n",
      "   86.          -0.9999828   85.87834     86.         -86.\n",
      "  -85.79115     84.99985     85.9987      -0.8229458   86.\n",
      "  -85.          84.99998     85.39343    -84.999985   -86.\n",
      "   85.          86.          86.          86.         -85.240944\n",
      "  -85.1633     -85.          -1.4073123   85.99996    -85.99999\n",
      "   84.99994     85.99993    -85.999214    84.99984     85.311584\n",
      "  -85.9991      -0.9999999   86.         -85.140625   -84.99984\n",
      "   85.9999     -85.          85.         -84.99999     -0.99999666\n",
      "   85.734764    85.95837    -85.999855    85.552        0.6259397\n",
      "   84.99956     84.99998     85.99998     86.          85.90294\n",
      "  -85.99947    -85.999985    85.94656     85.         -84.999954\n",
      "  -85.99998    -85.          86.          -1.6479799   86.\n",
      "  -84.99999    -85.999565    85.          84.99918     85.51021\n",
      "   85.999985   -86.          85.99997    -85.          86.\n",
      "   -1.7506332   86.         -86.           1.1271377   85.674095\n",
      "  -85.42079     84.99999    -85.          -1.1990123   86.\n",
      "    0.9993508  -85.99989    -84.99944     85.83667    -85.999664\n",
      "    3.6063452    1.0430889   85.864784   -85.          85.27676   ]]\n",
      "T 2\n",
      "P 2\n",
      "T [-1.63611092]\n",
      "P [[-0.9968499]]\n",
      "[[-86.08027    -87.          87.         -86.90658    -86.\n",
      "   86.          86.33597     86.99965    -86.998314   -87.\n",
      "   87.          -0.98564243  86.87834     87.         -87.\n",
      "  -86.79115     85.99985     86.99867     -0.9999797   87.\n",
      "  -86.          85.99998     86.39342    -85.999985   -87.\n",
      "   86.          87.          87.          87.         -86.240944\n",
      "  -86.1633     -86.          -1.3180622   86.99996    -86.99999\n",
      "   85.99994     86.99993    -86.99919     85.99984     86.311584\n",
      "  -86.9991      -1.1902575   87.         -86.140625   -85.99984\n",
      "   86.9999     -86.          86.         -85.99999     -1.2439803\n",
      "   86.734764    86.95837    -86.999855    86.552        0.97601783\n",
      "   85.99955     85.99998     86.99998     87.          86.90294\n",
      "  -86.99947    -86.999985    86.94656     86.         -85.999954\n",
      "  -86.99998    -86.          87.          -1.5431068   87.\n",
      "  -85.99999    -86.99954     86.          85.99917     86.51021\n",
      "   86.999985   -87.          86.99997    -86.          87.\n",
      "   -1.4900334   87.         -87.           1.0846202   86.674095\n",
      "  -86.42079     85.99999    -86.          -0.9999834   87.\n",
      "    1.5061417  -86.99989    -85.999435    86.83667    -86.999664\n",
      "    3.9764524    1.7434883   86.864784   -86.          86.27676   ]]\n",
      "T 13\n",
      "P 3\n",
      "T [0.2183545]\n",
      "P [[-0.878307]]\n",
      "[[-87.08027    -88.          88.         -87.90658    -87.\n",
      "   87.          87.33597     87.99965    -87.99827    -88.\n",
      "   88.          -0.999653    87.87834     88.         -88.\n",
      "  -87.79115     86.99985     87.998665    -0.92914224  88.\n",
      "  -87.          86.99998     87.39342    -86.999985   -88.\n",
      "   87.          88.          88.          88.         -87.240944\n",
      "  -87.1633     -87.          -1.5535667   87.99996    -87.99999\n",
      "   86.99994     87.99993    -87.99919     86.99984     87.311584\n",
      "  -87.9991      -0.9994159   88.         -87.140625   -86.99984\n",
      "   87.9999     -87.          87.         -86.99999     -1.0737163\n",
      "   87.734764    87.95837    -87.999855    87.552        0.9943372\n",
      "   86.99955     86.99998     87.99998     88.          87.90294\n",
      "  -87.99947    -87.999985    87.94656     87.         -86.999954\n",
      "  -87.99998    -87.          88.          -2.1843567   88.\n",
      "  -86.99999    -87.99954     87.          86.99916     87.51021\n",
      "   87.999985   -88.          87.99997    -87.          88.\n",
      "   -1.1013348   88.         -88.           1.0568366   87.674095\n",
      "  -87.42079     86.99999    -87.          -0.9999928   88.\n",
      "    1.1789446  -87.99989    -86.999435    87.83667    -87.999664\n",
      "    3.6301565    2.7290416   87.864784   -87.          87.27676   ]]\n",
      "T 0\n",
      "P 7\n",
      "T [-0.98671531]\n",
      "P [[-0.9528121]]\n",
      "[[-88.08027    -89.          89.         -88.90658    -88.\n",
      "   88.          88.33597     88.99965    -88.99827    -89.\n",
      "   89.          -0.99853945  88.87834     89.         -89.\n",
      "  -88.79115     87.99984     88.998665    -1.          89.\n",
      "  -88.          87.99998     88.39342    -87.999985   -89.\n",
      "   88.          89.          89.          89.         -88.240944\n",
      "  -88.1633     -88.          -1.2968279   88.99996    -88.99999\n",
      "   87.99994     88.99993    -88.99919     87.99984     88.311584\n",
      "  -88.9991      -0.94518346  89.         -88.140625   -87.99984\n",
      "   88.9999     -88.          88.         -87.99999     -0.9969878\n",
      "   88.734764    88.95837    -88.999855    88.552        1.\n",
      "   87.99955     87.99998     88.99998     89.          88.90294\n",
      "  -88.99947    -88.999985    88.94656     88.         -87.999954\n",
      "  -88.99998    -88.          89.          -1.6760787   89.\n",
      "  -87.99999    -88.99954     88.          87.99916     88.51021\n",
      "   88.999985   -89.          88.99997    -88.          89.\n",
      "   -1.9326694   89.         -89.           1.3292503   88.674095\n",
      "  -88.42079     87.99999    -88.          -0.90132505  89.\n",
      "    0.8008923  -88.99989    -87.99943     88.83667    -88.999664\n",
      "    2.7401295    2.4934042   88.864784   -88.          88.27676   ]]\n",
      "T 10\n",
      "P 10\n",
      "T [-1.62489163]\n",
      "P [[-0.88458145]]\n",
      "[[-89.08027    -90.          90.         -89.90658    -89.\n",
      "   89.          89.33597     89.99965    -89.99827    -90.\n",
      "   90.          -0.9999993   89.87834     90.         -90.\n",
      "  -89.79115     88.99984     89.998665    -0.99858016  90.\n",
      "  -89.          88.99998     89.39342    -88.999985   -90.\n",
      "   89.          90.          90.          90.         -89.240944\n",
      "  -89.1633     -89.          -0.9999826   89.99996    -89.99999\n",
      "   88.99994     89.99993    -89.99919     88.99984     89.311584\n",
      "  -89.9991      -0.2995925   90.         -89.140625   -88.99984\n",
      "   89.9999     -89.          89.         -88.99999     -1.0043697\n",
      "   89.734764    89.95837    -89.999855    89.552        0.9698778\n",
      "   88.99954     88.99998     89.99998     90.          89.90294\n",
      "  -89.99947    -89.999985    89.94656     89.         -88.999954\n",
      "  -89.99998    -89.          90.          -1.7433949   90.\n",
      "  -88.99999    -89.99954     89.          88.99915     89.51021\n",
      "   89.999985   -90.          89.99997    -89.          90.\n",
      "   -2.1128745   90.         -90.           2.3283334   89.674095\n",
      "  -89.42079     88.99999    -89.          -0.99482846  90.\n",
      "    0.6143122  -89.99989    -88.99943     89.83667    -89.999664\n",
      "    3.7396274    2.452231    89.864784   -89.          89.27676   ]]\n",
      "T 11\n",
      "P 11\n",
      "T [-1.8868307]\n",
      "P [[-0.94192207]]\n",
      "[[-90.08027    -91.          91.         -90.90658    -90.\n",
      "   90.          90.33597     90.999626   -90.99826    -91.\n",
      "   91.          -1.          90.878334    91.         -91.\n",
      "  -90.79115     89.99984     90.998665    -0.99160284  91.\n",
      "  -90.          89.99998     90.39337    -89.999985   -91.\n",
      "   90.          91.          91.          91.         -90.240944\n",
      "  -90.1633     -90.          -1.003119    90.99996    -90.99999\n",
      "   89.99994     90.99993    -90.99919     89.99983     90.311584\n",
      "  -90.9991      -1.1296799   91.         -90.140625   -89.99984\n",
      "   90.9999     -90.          90.         -89.99999     -0.98224056\n",
      "   90.734764    90.95837    -90.999855    90.552        0.9985033\n",
      "   89.999535    89.99998     90.99998     91.          90.90294\n",
      "  -90.999435   -90.999985    90.94656     90.         -89.999954\n",
      "  -90.99998    -90.          91.          -2.2213008   91.\n",
      "  -89.99999    -90.99954     90.          89.99915     90.51021\n",
      "   90.999985   -91.          90.99997    -90.          91.\n",
      "   -1.9585669   91.         -91.           1.5907277   90.674095\n",
      "  -90.42079     89.99999    -90.          -0.9970673   91.\n",
      "    0.8885258  -90.99989    -89.99943     90.83667    -90.99966\n",
      "    4.318055     2.9908109   90.864784   -90.          90.27676   ]]\n",
      "T 6\n",
      "P 2\n",
      "T [-1.00997454]\n",
      "P [[-0.93128216]]\n",
      "[[-91.08027    -92.          92.         -91.90658    -91.\n",
      "   91.          91.33597     91.999626   -91.99826    -92.\n",
      "   92.          -0.99930125  91.878334    92.         -92.\n",
      "  -91.79115     90.99984     91.998665    -0.9999989   92.\n",
      "  -91.          90.99998     91.393364   -90.999985   -92.\n",
      "   91.          92.          92.          92.         -91.240944\n",
      "  -91.1633     -91.          -1.4162197   91.99996    -91.99999\n",
      "   90.99994     91.99993    -91.99919     90.99983     91.311584\n",
      "  -91.9991      -1.6159792   92.         -91.140625   -90.99984\n",
      "   91.9999     -91.          91.         -90.99999     -0.9999994\n",
      "   91.734764    91.95837    -91.999855    91.552       -0.72584987\n",
      "   90.999535    90.99998     91.99998     92.          91.90294\n",
      "  -91.999435   -91.999985    91.94656     91.         -90.999954\n",
      "  -91.99998    -91.          92.          -2.2211838   92.\n",
      "  -90.99999    -91.999535    91.          90.999146    91.51021\n",
      "   91.999985   -92.          91.99997    -91.          92.\n",
      "   -2.3893182   92.         -92.           1.1185268   91.674095\n",
      "  -91.42079     90.99999    -91.          -1.          92.\n",
      "    1.188575   -91.99989    -90.99943     91.83667    -91.99966\n",
      "    4.3802185    2.05236     91.864784   -91.          91.27676   ]]\n",
      "T 8\n",
      "P 12\n",
      "T [-1.4397241]\n",
      "P [[-0.95458186]]\n",
      "[[-92.08027   -93.         93.        -92.90658   -92.         92.\n",
      "   92.33597    92.999596  -92.99825   -93.         93.         -0.9999859\n",
      "   92.878334   93.        -93.        -92.79115    91.99984    92.99866\n",
      "   -0.9974529  93.        -92.         91.99998    92.393364  -91.999985\n",
      "  -93.         92.         93.         93.         93.        -92.240944\n",
      "  -92.1633    -92.         -1.5182872  92.99996   -92.99999    91.99994\n",
      "   92.99993   -92.99918    91.99983    92.311584  -92.9991     -1.9766864\n",
      "   93.        -92.140625  -91.99984    92.9999    -92.         92.\n",
      "  -91.99999    -0.9982514  92.734764   92.95837   -92.99985    92.552\n",
      "    0.9996803  91.99953    91.99998    92.99998    93.         92.90294\n",
      "  -92.999435  -92.999985   92.94656    92.        -91.999954  -92.99998\n",
      "  -92.         93.         -2.572154   93.        -91.99999   -92.99952\n",
      "   92.         91.99914    92.51021    92.999985  -93.         92.99997\n",
      "  -92.         93.         -1.9523437  93.        -93.          1.0101066\n",
      "   92.674095  -92.42079    91.99999   -92.         -0.9256211  93.\n",
      "    1.3279749 -92.999886  -91.99942    92.83667   -92.99965     3.9236584\n",
      "    1.1704905  92.864784  -92.         92.27675  ]]\n",
      "T 2\n",
      "P 2\n",
      "T [-2.55762875]\n",
      "P [[-0.9509336]]\n",
      "[[-93.08027    -94.          94.         -93.90658    -93.\n",
      "   93.          93.33597     93.999596   -93.99825    -94.\n",
      "   94.          -0.14403987  93.878334    94.         -94.\n",
      "  -93.79115     92.99984     93.99864     -1.          94.\n",
      "  -93.          92.99998     93.39336    -92.999985   -94.\n",
      "   93.          94.          94.          94.         -93.240944\n",
      "  -93.1633     -93.          -1.0453963   93.99996    -93.99999\n",
      "   92.99994     93.99993    -93.999176    92.99983     93.311584\n",
      "  -93.9991      -1.8562421   94.         -93.140625   -92.99984\n",
      "   93.9999     -93.          93.         -92.99999     -1.4890243\n",
      "   93.734764    93.95837    -93.99985     93.552        0.9369773\n",
      "   92.99953     92.99998     93.99998     94.          93.90294\n",
      "  -93.999435   -93.999985    93.94656     93.         -92.999954\n",
      "  -93.99998    -93.          94.          -1.7352808   94.\n",
      "  -92.99999    -93.99948     93.          92.99912     93.51021\n",
      "   93.999985   -94.          93.99997    -93.          94.\n",
      "   -1.8326237   94.         -94.           1.2320192   93.674095\n",
      "  -93.42079     92.99999    -93.          -0.9999998   94.\n",
      "    2.0508037  -93.999886   -92.99942     93.83667    -93.99965\n",
      "    3.8614383    1.6981945   93.864784   -93.          93.27675   ]]\n",
      "T 16\n",
      "P 7\n",
      "T [-2.4527493]\n",
      "P [[-0.8769952]]\n",
      "[[-94.08027    -95.          95.         -94.90658    -94.\n",
      "   94.          94.33597     94.999596   -94.99825    -95.\n",
      "   95.          -0.9999988   94.878334    95.         -95.\n",
      "  -94.79115     93.99983     94.99864     -0.96303684  95.\n",
      "  -94.          93.99998     94.39336    -93.999985   -95.\n",
      "   94.          95.          95.          95.         -94.240944\n",
      "  -94.1633     -94.          -0.9999995   94.99996    -94.99999\n",
      "   93.99994     94.99993    -94.999176    93.99983     94.311584\n",
      "  -94.9991      -0.9984637   95.         -94.140625   -93.99984\n",
      "   94.9999     -94.          94.         -93.99999     -1.373584\n",
      "   94.734764    94.95837    -94.99985     94.552        0.9930414\n",
      "   93.99952     93.99998     94.99998     95.          94.90294\n",
      "  -94.999435   -94.999985    94.94656     94.         -93.999954\n",
      "  -94.99998    -94.          95.          -2.2037346   95.\n",
      "  -93.99999    -94.99948     94.          93.999115    94.51021\n",
      "   94.999985   -95.          94.99997    -94.          95.\n",
      "   -0.9999988   95.         -95.           1.8121388   94.674095\n",
      "  -94.42079     93.99999    -94.          -1.0715252   95.\n",
      "    0.47597793 -94.999886   -93.99942     94.83667    -94.99965\n",
      "    3.4056125    1.3583639   94.864784   -94.          94.27675   ]]\n",
      "T 4\n",
      "P 4\n",
      "T [1.42916069]\n",
      "P [[-0.8711425]]\n",
      "[[-95.08027    -96.          96.         -95.90658    -95.\n",
      "   95.          95.33597     95.999596   -95.99825    -96.\n",
      "   96.          -0.9999993   95.878334    96.         -96.\n",
      "  -95.79115     94.99983     95.99864     -0.99982303  96.\n",
      "  -95.          94.99998     95.39336    -94.999985   -96.\n",
      "   95.          96.          96.          96.         -95.240944\n",
      "  -95.1633     -95.          -1.2119555   95.99996    -95.99999\n",
      "   94.99994     95.99993    -95.999176    94.99983     95.311584\n",
      "  -95.9991      -0.9987212   96.         -95.140625   -94.99984\n",
      "   95.9999     -95.          95.         -94.99999     -1.8162805\n",
      "   95.734764    95.95837    -95.99985     95.552        0.993413\n",
      "   94.99952     94.99998     95.99998     96.          95.90294\n",
      "  -95.999435   -95.999985    95.94656     95.         -94.999954\n",
      "  -95.99998    -95.          96.          -1.2165473   96.\n",
      "  -94.99999    -95.99948     95.          94.999115    95.51021\n",
      "   95.999985   -96.          95.99997    -95.          96.\n",
      "   -1.5698185   96.         -96.           1.2458863   95.674095\n",
      "  -95.42079     94.99999    -95.          -0.9999986   96.\n",
      "    0.92490995 -95.999886   -94.99942     95.83667    -95.99965\n",
      "    4.072225     2.1019592   95.864784   -95.          95.27675   ]]\n",
      "T 11\n",
      "P 11\n",
      "T [-1.67479438]\n",
      "P [[-0.8951441]]\n",
      "[[-96.08027    -97.          97.         -96.90658    -96.\n",
      "   96.          96.33597     96.999596   -96.99824    -97.\n",
      "   97.          -0.99999213  96.878334    97.         -97.\n",
      "  -96.79115     95.99983     96.99863     -0.99611855  97.\n",
      "  -96.          95.99998     96.39333    -95.999985   -97.\n",
      "   96.          97.          97.          97.         -96.240944\n",
      "  -96.1633     -96.          -1.4914045   96.99996    -96.99999\n",
      "   95.99994     96.99993    -96.99917     95.99983     96.311584\n",
      "  -96.99909     -1.0270597   97.         -96.140625   -95.99984\n",
      "   96.9999     -96.          96.         -95.99999     -0.9787555\n",
      "   96.734764    96.95837    -96.99985     96.552        0.9999776\n",
      "   95.99951     95.99998     96.99998     97.          96.90294\n",
      "  -96.999435   -96.999985    96.94656     96.         -95.999954\n",
      "  -96.99998    -96.          97.          -1.5449789   97.\n",
      "  -95.99999    -96.99948     96.          95.99911     96.51021\n",
      "   96.999985   -97.          96.99997    -96.          97.\n",
      "   -1.9035695   97.         -97.           1.0889523   96.674095\n",
      "  -96.42079     95.99999    -96.          -0.99263614  97.\n",
      "    0.99941015 -96.999886   -95.99941     96.83667    -96.99965\n",
      "    4.33937      3.020632    96.864784   -96.          96.27675   ]]\n",
      "T 13\n",
      "P 13\n",
      "T [-0.98410713]\n",
      "P [[-0.9234706]]\n",
      "[[-97.08027    -98.          98.         -97.90658    -97.\n",
      "   97.          97.33597     97.999596   -97.99822    -98.\n",
      "   98.          -0.99931145  97.878334    98.         -98.\n",
      "  -97.79115     96.99983     97.99862     -0.9930552   98.\n",
      "  -97.          96.99998     97.39333    -96.999985   -98.\n",
      "   97.          98.          98.          98.         -97.240944\n",
      "  -97.1633     -97.          -1.6696882   97.99996    -97.99999\n",
      "   96.99994     97.99993    -97.99917     96.99983     97.311584\n",
      "  -97.99909     -0.983807    98.         -97.140625   -96.99984\n",
      "   97.9999     -97.          97.         -96.99999     -0.9999997\n",
      "   97.734764    97.95837    -97.99985     97.552        0.93038297\n",
      "   96.99951     96.99998     97.99998     98.          97.90294\n",
      "  -97.999435   -97.999985    97.94656     97.         -96.999954\n",
      "  -97.99998    -97.          98.          -1.944333    98.\n",
      "  -96.99999    -97.99948     97.          96.9991      97.51021\n",
      "   97.999985   -98.          97.99997    -97.          98.\n",
      "   -1.3013655   98.         -98.           0.99956554  97.674095\n",
      "  -97.42079     96.99999    -97.          -0.9999997   98.\n",
      "    1.0578206  -97.999886   -96.999405    97.83667    -97.99964\n",
      "    4.0179276    4.016844    97.864784   -97.          97.27675   ]]\n",
      "T 15\n",
      "P 7\n",
      "T [0.08296338]\n",
      "P [[-0.9663695]]\n",
      "[[-98.08027    -99.          99.         -98.90658    -98.\n",
      "   98.          98.33597     98.999596   -98.99822    -99.\n",
      "   99.          -1.          98.878334    99.         -99.\n",
      "  -98.79115     97.99983     98.99862     -0.8118398   99.\n",
      "  -98.          97.99998     98.39333    -97.999985   -99.\n",
      "   98.          99.          99.          99.         -98.240944\n",
      "  -98.1633     -98.          -1.1031536   98.99996    -98.99999\n",
      "   97.99994     98.99993    -98.99917     97.99983     98.311584\n",
      "  -98.99909     -0.9845194   99.         -98.140625   -97.99984\n",
      "   98.9999     -98.          98.         -97.99999     -0.8239529\n",
      "   98.734764    98.95837    -98.99985     98.552        0.9997998\n",
      "   97.99951     97.99998     98.99998     99.          98.90294\n",
      "  -98.999435   -98.999985    98.94656     98.         -97.999954\n",
      "  -98.99998    -98.          99.          -1.2996604   99.\n",
      "  -97.99999    -98.99948     98.          97.999084    98.51021\n",
      "   98.999985   -99.          98.99997    -98.          99.\n",
      "   -2.0647628   99.         -99.           1.3908827   98.674095\n",
      "  -98.42079     97.99999    -98.          -0.91128194  99.\n",
      "   -0.27244863 -98.999886   -97.999405    98.83667    -98.99964\n",
      "    4.5964594    4.0794926   98.864784   -98.          98.27675   ]]\n",
      "T 11\n",
      "P 2\n",
      "T [100.53188323]\n",
      "P [[61.176395]]\n",
      "[[ -99.08027    -100.          100.          -99.90658     -99.\n",
      "    99.           99.33597      99.999596    -99.99822    -100.\n",
      "   100.           -0.9998264    99.87833     100.         -100.\n",
      "   -99.79115      98.99983      99.99862      -0.9999966   100.\n",
      "   -99.           98.99998      99.39332     -98.999985   -100.\n",
      "    99.          100.          100.          100.          -99.240944\n",
      "   -99.1633      -99.           -0.9999972    99.99996     -99.99999\n",
      "    98.99994      99.99993     -99.99917      98.99983      99.311584\n",
      "   -99.99909      -0.8758663   100.          -99.140625    -98.99984\n",
      "    99.9999      -99.           99.          -98.99999      -1.1064718\n",
      "    99.734764     99.95837     -99.99985      99.552         0.9998648\n",
      "    98.99951      98.99998      99.99998     100.           99.90294\n",
      "   -99.999435    -99.999985     99.94656      99.          -98.999954\n",
      "   -99.99998     -99.          100.           -1.2014662   100.\n",
      "   -98.99999     -99.99948      99.           98.999084     99.51021\n",
      "    99.999985   -100.           99.99997     -99.          100.\n",
      "    -2.1229813   100.         -100.            1.5575784    99.674095\n",
      "   -99.42079      98.99999     -99.           -1.1407862   100.\n",
      "     0.99945676  -99.999886    -98.999405     99.83667     -99.99964\n",
      "     4.4126062     5.058916     99.864784    -99.           99.27675   ]]\n",
      "T 10\n",
      "P 10\n",
      "T [-1.27473255]\n",
      "P [[-0.9473988]]\n",
      "--------------------------------------------\n",
      "[[-0.8757372  -0.70949     0.5920515  -0.9994324  -0.6183929  -0.875769\n",
      "   0.90123624 -0.6229813   0.7642444  -0.946447    0.8503308   0.44736013\n",
      "   0.6089026   0.7760033   0.5521765  -0.5466058  -0.33641982  0.90274715\n",
      "  -0.9519847   0.9574736  -0.95309764 -0.02377559  0.5895442  -0.7154179\n",
      "  -0.89635354  0.90568435 -0.73961157 -0.59381366  0.9756496  -0.9012679\n",
      "  -0.68886006 -0.932363    0.39349553  0.8234683   0.1078395   0.7270003\n",
      "   0.46642143 -0.75608695  0.32485175 -0.5947331  -0.3677905   0.8928681\n",
      "   0.5430531  -0.63380456  0.8845386   0.9054201  -0.809409    0.7271538\n",
      "  -0.6805362   0.991798    0.62774503  0.44926596 -0.87682956  0.76317996\n",
      "   0.9959996   0.6737565   0.8477109  -0.774227    0.998501    0.76014227\n",
      "   0.47946382  0.5407193   0.9225221  -0.9411392   0.79843825 -0.9241924\n",
      "  -0.90581477  0.90847343 -0.9447924   0.8007508  -0.5939723  -0.84182423\n",
      "  -0.68188846  0.7659966   0.863592    0.8874932  -0.80161923  0.82345617\n",
      "  -0.77844137  0.9966618  -0.9479087  -0.20236652  0.2944538   0.844996\n",
      "   0.9667753  -0.76642644  0.79269373 -0.8809794   0.90584546  0.98838586\n",
      "  -0.68641675 -0.35461888 -0.6066192   0.82104874 -0.90798265 -0.18263529\n",
      "   0.78061557  0.8063111  -0.7166463   0.8280225 ]]\n",
      "T 10\n",
      "P 10\n",
      "T [-0.58778325]\n",
      "P [[-0.95605767]]\n",
      "[[-1.8757355  -1.7094861   1.5917001  -1.7873623  -1.618393    0.1856268\n",
      "   1.9012358   0.37691718 -0.23124838 -1.9452294   1.8502319  -0.78217465\n",
      "   1.6087344   1.7760029  -0.44782352 -1.5466058   0.66356504  1.9025785\n",
      "  -1.0967972   1.957473   -1.9530971   0.9761383   1.5892216  -1.715369\n",
      "  -1.8963535   1.9056844   0.26038748  0.40618634  1.9756482  -1.9012666\n",
      "  -1.68886    -1.9323554  -0.94825256  1.8233927  -0.8920908   1.7269971\n",
      "   1.4664034  -1.7560755   1.3244395   0.40526688 -1.3676616  -0.30201948\n",
      "   1.311649   -1.6338029  -0.11540371  1.9053739  -1.809409    1.7271538\n",
      "  -1.6805122  -0.63317895  1.625499    1.449266   -1.876829    1.7631729\n",
      "  -0.5242897   1.6736498   1.8477108   0.22577298  1.9985011   1.7601421\n",
      "  -0.52032304 -0.45927948  1.9225209   0.05886078 -0.20156151 -1.9228014\n",
      "  -1.9058146   1.9084724  -1.7118262   1.8007507  -1.5939722  -1.8413956\n",
      "   0.31811154  1.7628334   1.8633204   1.4023273  -1.8016193   1.8234558\n",
      "  -1.778441    1.9966618  -1.5497307   0.79763335 -0.7055462   1.8447593\n",
      "   1.9665627  -1.7664264   1.7926937  -1.8809794  -0.09415424  1.9883859\n",
      "   0.55957556 -1.3546178  -1.6061797   1.8210486  -1.9063497  -1.0340662\n",
      "   1.7340641   1.8063111  -1.7166092   1.8280151 ]]\n",
      "T 6\n",
      "P 6\n",
      "T [-1.66879421]\n",
      "P [[-1.0969285]]\n",
      "[[-2.8757355  -2.709486    2.5916996  -2.7873623  -2.618393    1.1856267\n",
      "   2.9012358   1.3769166  -1.2312455  -2.9452295   2.850232   -0.9999903\n",
      "   2.6087317   2.776003   -1.4478235  -2.5466058   1.6635647   2.9024978\n",
      "  -0.89720213  2.957473   -2.953097    1.9761384   2.589169   -2.715368\n",
      "  -2.8963535   2.9056845   1.2603874   1.4061863   2.9756482  -2.9012666\n",
      "  -2.68886    -2.9323554  -0.9999943   2.8233929  -1.8920906   2.7269964\n",
      "   2.4664032  -2.7560725   2.324439    1.4052668  -2.367603   -1.2705956\n",
      "   2.3116488  -2.633803   -1.1154037   2.9053688  -2.8094091   2.7271538\n",
      "  -2.680512   -0.96864104  2.625499    2.449266   -2.8768291   2.7631729\n",
      "   0.859937    2.6736248   2.8477106   1.225773    2.998501    2.760142\n",
      "  -1.5203223  -1.4592795   2.9225206   1.0588608  -1.2015615  -2.9228005\n",
      "  -2.9058146   2.9084725  -2.7118263   2.8007507  -2.593972   -2.8413868\n",
      "   1.3181115   2.7627637   2.863317    2.4023147  -2.8016193   2.8234556\n",
      "  -2.778441    2.9966617  -2.5497308   1.7976334  -1.7055461   0.63409615\n",
      "   2.9665623  -2.7664266   2.7926936  -2.8809795  -0.99994004  2.988386\n",
      "   1.1630235  -2.3546178  -2.6061625   2.8210487  -2.9063468   0.09096819\n",
      "  -0.01348416  2.8063111  -2.716609    2.8280034 ]]\n",
      "T 5\n",
      "P 12\n",
      "T [-0.96311349]\n",
      "P [[-0.90904105]]\n",
      "[[-3.8757355  -3.709486    3.5916982  -3.7873623  -3.618393    2.1856267\n",
      "   3.9012358   2.376904   -2.2288275  -3.9452295   3.850232   -0.91493905\n",
      "   3.608728    3.776003   -2.4478235  -3.5466058   2.6635642   3.9023962\n",
      "  -0.9999982   3.957473   -3.953097    2.9761384   3.589126   -3.715367\n",
      "  -3.8963535   3.9056845   2.2603874   2.4061863   3.9756482  -3.9012666\n",
      "  -3.68886    -3.9323554  -0.99465364  3.8233929  -2.8920903   3.7269957\n",
      "   3.466403   -3.7560449   3.3244376   2.4052668  -3.3675988  -1.6370826\n",
      "   3.3116488  -3.633803   -2.1154025   3.9053688  -3.8094091   3.7271538\n",
      "  -3.680512   -1.7441597   3.625499    3.449266   -3.876829    3.7631729\n",
      "   0.01446051  3.673616    3.8477101   2.2257729   3.998501    3.760142\n",
      "  -2.520297   -2.4592795   3.9225206   2.0588608  -2.2015615  -3.922787\n",
      "  -3.9058146   3.9084725  -3.1328816   3.8007507  -3.5939717  -3.8413868\n",
      "   2.3181114   3.7627087   3.863317    3.402307   -3.8016193   3.8234553\n",
      "  -3.778441    3.9966617  -2.5408795   2.7976334  -2.7055461   0.9986608\n",
      "   3.9665618  -3.7664266   3.7926936  -3.8809795  -1.          3.988386\n",
      "   1.9435925  -3.3546174  -3.6060996   3.8210487  -3.9063327   1.0872455\n",
      "   0.9864934   3.8063111  -3.716609    3.8279924 ]]\n",
      "T 15\n",
      "P 15\n",
      "T [-1.29934994]\n",
      "P [[-0.90220106]]\n",
      "[[-4.8757353  -4.709486    4.591698   -4.787362   -4.618393    3.1856267\n",
      "   4.9012356   3.376904   -3.228827   -4.9452295   4.850232   -1.\n",
      "   4.6087265   4.776003   -3.4478235  -4.546606    3.663564    4.9023933\n",
      "   0.99839     4.957473   -4.9530973   3.9761384   4.5891204  -4.715367\n",
      "  -4.8963532   4.9056845   3.2603874   3.4061863   4.975648   -4.9012666\n",
      "  -4.68886    -4.9323554  -1.1742083   4.823393   -3.8920903   4.7269945\n",
      "   4.466401   -4.7560267   4.324435    3.4052668  -4.3672285  -0.9995598\n",
      "   4.311649   -4.633803   -3.1154022   4.9053216  -4.809409    4.727154\n",
      "  -4.680511    0.8429039   4.625499    4.449266   -4.876828    4.763173\n",
      "   0.999423    4.6736126   4.8477097   3.2257729   4.998501    4.760142\n",
      "  -3.520297   -3.4592795   4.92252     3.0588608  -3.2015615  -4.9227867\n",
      "  -4.9058146   4.9084725  -3.5809171   4.8007507  -4.5939713  -4.841385\n",
      "   3.3181105   4.7626767   4.8633146   4.4023066  -4.8016195   4.8234553\n",
      "  -4.778441    4.9966617  -2.450725    3.7976334  -3.7055461   0.99906605\n",
      "   4.966562   -4.7664266   4.7926936  -4.8809795  -0.7594249   4.988386\n",
      "  -0.81128174 -4.354615   -4.6060977   4.8210487  -4.906332    2.0872455\n",
      "  -0.33709985  4.806311   -4.7166085   4.827991  ]]\n",
      "T 13\n",
      "P 13\n",
      "T [100.35202769]\n",
      "P [[100.78824]]\n",
      "[[-5.875735   -5.709486    5.5916977  -5.787362   -5.618393    4.185627\n",
      "   5.9012356   4.3769035  -4.2286654  -5.9452286   5.850232    0.90873635\n",
      "   5.608721    5.776003   -4.4478235  -5.546606    4.6635637   5.9023933\n",
      "  -0.80615544  5.957473   -5.9530973   4.9761314   5.589112   -5.715366\n",
      "  -5.8963532   5.9056845   4.2603874   4.406186    5.975648   -5.9012666\n",
      "  -5.68886    -5.9323554   0.4594466   5.823393   -4.89209     5.726993\n",
      "   5.4664006  -5.756026    5.324422    4.405267   -5.3672285   0.40499485\n",
      "   5.311649   -5.633803   -4.115402    5.9053216  -5.809409    5.727154\n",
      "  -5.680511   -0.24049914  5.625499    5.449266   -5.8768215   5.763173\n",
      "  -0.812296    5.673611    5.847709    4.225773    5.998501    5.760142\n",
      "  -4.5201955  -4.459275    5.92252     4.058861   -4.2015605  -5.922785\n",
      "  -5.905814    5.9084725  -1.0262823   5.8007507  -5.5939713  -5.841369\n",
      "   4.3181105   5.7626486   5.8633146   5.4022875  -5.8016195   5.823453\n",
      "  -5.778441    5.9966617  -0.8217244   4.797633   -4.7055464   1.\n",
      "   5.966562   -5.7664266   5.792692   -5.8809795  -1.          5.988386\n",
      "   0.6351204  -5.3546147  -5.606089    5.8210483  -5.9063      2.4897666\n",
      "   0.66290015  5.806311   -5.7166085   5.827991  ]]\n",
      "T 2\n",
      "P 11\n",
      "T [-1.53237124]\n",
      "P [[-1.3521005]]\n",
      "[[-6.875735   -6.709486    6.5916977  -6.787362   -6.618393    5.185627\n",
      "   6.9012356   5.3769035  -5.2286654  -6.9452286   6.850232   -1.\n",
      "   6.6087203   6.776003   -5.447823   -6.546606    5.663563    6.9023924\n",
      "  -0.16521214  6.957473   -6.9530973   5.9761314   6.589112   -6.715366\n",
      "  -6.8963532   6.9056845   5.2603874   5.406186    6.975648   -6.9012666\n",
      "  -6.68886    -6.9323554  -0.5854748   6.823393   -5.89209     6.726993\n",
      "   6.4664     -6.756025    6.324422    5.4052625  -6.3672285  -0.91880065\n",
      "   6.311649   -6.633803   -5.115402    6.9053216  -6.809409    6.727154\n",
      "  -6.6805105  -0.99373513  6.625499    6.449266   -6.8768215   6.763173\n",
      "   1.          6.6736107   6.8477087   5.225773    6.998501    6.760142\n",
      "  -5.520195   -5.459275    6.92252     5.058861   -5.2015605  -6.922785\n",
      "  -6.905814    6.9084725  -2.0262823   6.8007507  -6.5939713  -6.8413687\n",
      "   5.3181105   6.7626486   6.8633146   6.4022875  -6.8016195   6.823453\n",
      "  -6.778441    6.9966617  -1.5039661   5.797633   -5.7055464   0.07943174\n",
      "   6.966562   -6.7664266   6.792692   -6.8809795  -0.24209368  6.988386\n",
      "   0.9009233  -6.3546147  -6.606089    6.821048   -6.9063      2.7475877\n",
      "   1.2145      6.806311   -6.7166085   6.8279834 ]]\n",
      "T 4\n",
      "P 15\n",
      "T [-1.2318122]\n",
      "P [[-0.8794857]]\n",
      "[[-7.8757343  -7.709486    7.5916977  -7.787362   -7.618393    6.185627\n",
      "   7.9012356   6.3769035  -6.2286654  -7.9452286   7.850232   -0.9526236\n",
      "   7.6087184   7.776003   -6.447823   -7.546606    6.663563    7.9023924\n",
      "  -1.          7.957473   -7.9530973   6.9761314   7.5891056  -7.715366\n",
      "  -7.8963532   7.9056845   6.2603874   6.406186    7.975648   -7.9012666\n",
      "  -7.68886    -7.9323554  -0.83240044  7.823393   -6.89209     7.7269926\n",
      "   7.4664     -7.756025    7.32442     6.4052625  -7.3672285  -0.36589283\n",
      "   7.311649   -7.633803   -6.115402    7.9053216  -7.809409    7.727154\n",
      "  -7.6805105  -1.9937351   7.625499    7.449266   -7.8768206   7.763173\n",
      "   0.9958564   7.673609    7.8477087   6.225773    7.998501    7.760142\n",
      "  -6.520194   -6.4592724   7.92252     6.058861   -6.2015505  -7.922785\n",
      "  -7.905814    7.9084725   0.96410537  7.8007507  -7.5939713  -7.8413687\n",
      "   6.3181105   7.7626476   7.8633146   7.4022875  -7.8016195   7.823453\n",
      "  -7.778441    7.9966617   0.2676612   6.7976327  -6.7055464   1.0141892\n",
      "   7.966562   -7.7664266   7.792692   -7.8809795  -1.0413802   7.988386\n",
      "   0.99991655 -7.3546143  -7.6060815   7.821048   -7.9062953   1.6192311\n",
      "   2.2145      7.806311   -7.7166085   7.8279834 ]]\n",
      "T 16\n",
      "P 3\n",
      "T [-1.5470788]\n",
      "P [[-0.8834995]]\n",
      "[[-8.875734   -8.709486    8.591698   -8.787362   -8.618393    7.185627\n",
      "   8.901236    7.3769035  -7.228665   -8.945229    8.850232   -1.\n",
      "   8.608717    8.776003   -7.447823   -8.546606    7.6635623   8.902386\n",
      "   0.8128781   8.957473   -8.953097    7.9761305   8.589101   -8.715365\n",
      "  -8.896353    8.905684    7.2603874   7.406186    8.975648   -8.901266\n",
      "  -8.68886    -8.932356   -1.1830395   8.823393   -7.89209     8.726993\n",
      "   8.4664     -8.756018    8.324419    7.4052625  -8.367228   -1.\n",
      "   8.311649   -8.633802   -7.115398    8.905321   -8.809409    8.727154\n",
      "  -8.6805105  -0.6895616   8.625499    8.449266   -8.876821    8.763173\n",
      "   0.9999127   8.673607    8.847709    7.225773    8.998501    8.760141\n",
      "  -7.520194   -7.4592724   8.92252     7.058861   -7.2015505  -8.922785\n",
      "  -8.905814    8.908472   -0.03589463  8.800751   -8.59397    -8.841364\n",
      "   7.3181105   8.762644    8.863315    8.4022875  -8.80162     8.823453\n",
      "  -8.77844     8.996662   -0.7323388   7.7976327  -7.7055464   1.5525281\n",
      "   8.966561   -8.766426    8.792692   -8.88098    -0.77413225  8.988386\n",
      "   0.90484184 -8.354613   -8.606079    8.821048   -8.906295    2.2938483\n",
      "  -0.43325025  8.806311   -8.716608    8.827971  ]]\n",
      "T 7\n",
      "P 7\n",
      "T [-2.44998446]\n",
      "P [[-0.964708]]\n",
      "[[-9.875722   -9.709486    9.591698   -9.787362   -9.618393    8.185627\n",
      "   9.901236    8.376904   -8.228664   -9.945228    9.850232    0.9055054\n",
      "   9.60871     9.776003   -8.447823   -9.546606    8.663561    9.902386\n",
      "  -1.          9.957473   -9.953097    8.97613     9.589087   -9.715363\n",
      "  -9.896353    9.905684    8.260387    8.406186    9.975648   -9.901266\n",
      "  -9.68886    -9.932356   -0.11462317  9.823393   -8.89209     9.726993\n",
      "   9.466396   -9.756017    9.324416    8.405262   -9.367228   -0.07915071\n",
      "   9.311649   -9.633802   -8.115398    9.905321   -9.809409    9.727154\n",
      "  -9.6805105  -1.650769    9.625499    9.449266   -9.876819    9.763173\n",
      "  -0.5279543   9.673606    9.847709    8.225773    9.998501    9.760141\n",
      "  -8.520194   -8.4592705   9.92252     8.058861   -8.2015505  -9.922785\n",
      "  -9.905814    9.908472    0.3762443   9.800751   -9.59397    -9.841353\n",
      "   8.31811     9.762643    9.863315    9.4022875  -9.80162     9.823452\n",
      "  -9.77844     9.996662   -0.9656465   8.797632   -8.705546    1.4106884\n",
      "   9.966561   -9.766426    9.792692   -9.88098    -1.          9.988386\n",
      "   1.4841868  -9.354613   -9.606077    9.821043   -9.906295    2.5128434\n",
      "   0.56673014  9.806311   -9.716608    9.82797   ]]\n",
      "T 12\n",
      "P 12\n",
      "T [-0.75125822]\n",
      "P [[-1.0221711]]\n",
      "[[-10.875722   -10.709486    10.591698   -10.787362   -10.618393\n",
      "    9.185627    10.901236     9.376904    -9.228664   -10.945228\n",
      "   10.850232    -1.          10.608709    10.776003    -9.447823\n",
      "  -10.546606     9.663545    10.902371     0.6609304   10.957473\n",
      "  -10.953097     9.976129    10.589087   -10.715363   -10.896353\n",
      "   10.905684     9.260387     9.406186    10.975648   -10.901266\n",
      "  -10.68886    -10.932356    -1.0039841   10.823393    -9.89209\n",
      "   10.726993    10.466396   -10.756016    10.324416     9.405262\n",
      "  -10.367228    -1.0095536   10.311649   -10.633802    -9.115398\n",
      "   10.905321   -10.809409    10.727154   -10.68051     -0.9945258\n",
      "   10.625499    10.449266   -10.876819    10.763173     1.\n",
      "   10.673606    10.847708     9.225773    10.998501    10.760141\n",
      "   -9.520194    -9.4592705   10.92252      9.058861    -9.2015505\n",
      "  -10.922785   -10.905814    10.908472    -0.6237557   10.800751\n",
      "  -10.593968   -10.841353     9.31811     10.762643    10.863315\n",
      "   10.4022875  -10.80162     10.823452   -10.77844     10.996662\n",
      "   -1.5179527    9.797632    -9.705546     2.0211318   10.966561\n",
      "  -10.766426    10.792692   -10.88098     -0.72839546  10.988386\n",
      "   -0.15990022 -10.354613   -10.606077    10.821043   -10.906295\n",
      "    3.5128434   -0.38831636  10.806311   -10.716608    10.827959  ]]\n",
      "T 10\n",
      "P 2\n",
      "T [-1.85827241]\n",
      "P [[-0.94393766]]\n",
      "[[-11.875721   -11.709486    11.591698   -11.787362   -11.618393\n",
      "   10.185627    11.901236    10.376898   -10.228637   -11.945228\n",
      "   11.850232     0.32779655  11.608699    11.776003   -10.447823\n",
      "  -11.546606    10.663538    11.902371    -0.87310416  11.957473\n",
      "  -11.953097    10.976129    11.589081   -11.715362   -11.896353\n",
      "   11.905684    10.260387    10.406186    11.975648   -11.901266\n",
      "  -11.68886    -11.932356     0.38081515  11.823392   -10.89209\n",
      "   11.726991    11.466374   -11.756012    11.32439     10.405262\n",
      "  -11.367225     0.7404331   11.311649   -11.633802   -10.115398\n",
      "   11.905321   -11.809409    11.727154   -11.680508    -1.5037222\n",
      "   11.625499    11.449266   -11.876813    11.763173    -0.8349827\n",
      "   11.673602    11.847708    10.225773    11.998501    11.760141\n",
      "  -10.520193   -10.4592705   11.92252     10.058861   -10.201421\n",
      "  -11.922785   -11.905814    11.908472    -0.95998156  11.800751\n",
      "  -11.593968   -11.84093     10.31811     11.762616    11.863315\n",
      "   11.4022875  -11.80162     11.82345    -11.77844     11.996662\n",
      "   -1.7150807   10.797632   -10.705546     2.598446    11.966561\n",
      "  -11.766426    11.792692   -11.88098     -1.0750172   11.988386\n",
      "    0.9099042  -11.354612   -11.60605     11.821041   -11.906287\n",
      "    1.1284586    0.6999244   11.806311   -11.716608    11.827957  ]]\n",
      "T 10\n",
      "P 11\n",
      "T [-2.20880412]\n",
      "P [[-1.2854213]]\n",
      "[[-12.875721   -12.709486    12.591698   -12.787362   -12.618393\n",
      "   11.185627    12.901236    11.376866   -11.228633   -12.945228\n",
      "   12.850232    -1.          12.608695    12.776003   -11.447823\n",
      "  -12.546606    11.663537    12.90235      0.9813646   12.957473\n",
      "  -12.953097    11.976128    12.589079   -12.715362   -12.896353\n",
      "   12.905684    11.260387    11.406186    12.975648   -12.901266\n",
      "  -12.68886    -12.932356    -1.          12.823391   -11.89209\n",
      "   12.726991    12.466374   -12.756005    12.324389    11.405262\n",
      "  -12.367166    -0.57365364  12.311649   -12.633802   -11.115397\n",
      "   12.905321   -12.809409    12.727154   -12.680507     0.04680468\n",
      "   12.625499    12.449266   -12.876813    12.763173     0.9999999\n",
      "   12.673602    12.847708    11.225773    12.998501    12.760141\n",
      "  -11.520193   -11.4592705   12.92252     11.058861   -11.201421\n",
      "  -12.922785   -12.905814    12.908472    -1.9599816   12.800751\n",
      "  -12.593968   -12.840929    11.31811     12.762607    12.863315\n",
      "   12.4022875  -12.80162     12.82345    -12.77844     12.996662\n",
      "   -2.6303785   11.797632   -11.705546     3.455332    12.96656\n",
      "  -12.766426    12.792692   -12.88098     -0.4460695   12.988386\n",
      "   -0.03477739 -12.354612   -12.606049    12.821041   -12.906287\n",
      "    2.1284585    1.0231344   12.806311   -12.716608    12.827875  ]]\n",
      "T 15\n",
      "P 6\n",
      "T [-2.02906128]\n",
      "P [[-1.1285201]]\n",
      "[[-13.875714   -13.709486    13.591696   -13.787362   -13.618393\n",
      "   12.185627    13.901236    12.376866   -12.228633   -13.945228\n",
      "   13.850232    -0.9549009   13.608637    13.776003   -12.447823\n",
      "  -13.546606    12.663537    13.90235     -0.79983735  13.957473\n",
      "  -13.953097    12.976128    13.588383   -13.715292   -13.896353\n",
      "   13.905684    12.260387    12.406186    13.975647   -13.901266\n",
      "  -13.68886    -13.932356    -0.99576396  13.823391   -12.89209\n",
      "   13.72699     13.466372   -13.7560005   13.324064    12.405262\n",
      "  -13.367163     0.727048    13.311649   -13.633802   -12.115397\n",
      "   13.905321   -13.809409    13.727154   -13.680507    -0.96334463\n",
      "   13.625499    13.449266   -13.876764    13.763173    -0.9998598\n",
      "   13.673589    13.847708    12.225773    13.998501    13.760141\n",
      "  -12.520186   -12.4592705   13.922519    12.058861   -12.201421\n",
      "  -13.922785   -13.905814    13.908472    -1.1816149   13.800751\n",
      "  -13.593968   -13.840929    12.31811     13.762531    13.863315\n",
      "   13.40218    -13.80162     13.823449   -13.77844     13.996662\n",
      "   -2.809429    12.797632   -12.705546     1.          13.96656\n",
      "  -13.766426    13.792692   -13.88098     -1.          13.988386\n",
      "    0.9652215  -13.354608   -13.606021    13.821039   -13.906079\n",
      "    3.1232367    2.023129    13.806311   -13.716608    13.827875  ]]\n",
      "T 7\n",
      "P 7\n",
      "T [99.62266525]\n",
      "P [[100.66313]]\n",
      "[[-14.875714   -14.709486    14.591696   -14.787362   -14.618393\n",
      "   13.185627    14.901236    13.376866   -13.228633   -14.945228\n",
      "   14.850232    -1.          14.608636    14.776003   -13.447823\n",
      "  -14.546606    13.663535    14.90235      0.86774296  14.957473\n",
      "  -14.953097    13.976122    14.588383   -14.715292   -14.896353\n",
      "   14.905684    13.260387    13.406186    14.975647   -14.901266\n",
      "  -14.68886    -14.932356    -1.567752    14.823387   -13.89209\n",
      "   14.72699     14.466372   -14.7560005   14.324064    13.405262\n",
      "  -14.367163    -0.45485777  14.311649   -14.633802   -13.115397\n",
      "   14.905321   -14.809409    14.727154   -14.680506    -0.9922939\n",
      "   14.625499    14.449266   -14.876764    14.763173     1.\n",
      "   14.673589    14.847707    13.225772    14.998501    14.760141\n",
      "  -13.520186   -13.4592705   14.922519    13.058861   -13.201421\n",
      "  -14.922785   -14.905814    14.908472    -2.1816149   14.800751\n",
      "  -14.593968   -14.840929    13.31811     14.762531    14.863315\n",
      "   14.40218    -14.80162     14.823449   -14.77844     14.996662\n",
      "   -2.1650207   13.797632   -13.705546     1.7243894   14.96656\n",
      "  -14.766426    14.792692   -14.88098     -0.96811754  14.988386\n",
      "    0.6517265  -14.354608   -14.606021    14.821039   -14.906079\n",
      "    4.1232357    0.98089784  14.806311   -14.716608    14.827867  ]]\n",
      "T 4\n",
      "P 4\n",
      "T [-0.46762191]\n",
      "P [[-0.8991369]]\n",
      "[[-15.8757105  -15.709486    15.591696   -15.787362   -15.618393\n",
      "   14.185627    15.901236    14.376866   -14.228627   -15.945228\n",
      "   15.850232    -0.9947053   15.608633    15.776003   -14.447823\n",
      "  -15.546606    14.663531    15.90235     -1.          15.957473\n",
      "  -15.953097    14.976122    15.5883665  -15.715292   -15.896353\n",
      "   15.905684    14.260387    14.406186    15.975647   -15.901266\n",
      "  -15.68886    -15.932356     0.1375741   15.823387   -14.89209\n",
      "   15.726989    15.46637    -15.7560005   15.324056    14.405262\n",
      "  -15.367162    -1.141508    15.311649   -15.633802   -14.115397\n",
      "   15.905321   -15.809409    15.727154   -15.680506    -1.9922938\n",
      "   15.625499    15.449266   -15.876763    15.763173     0.9929326\n",
      "   15.673587    15.847707    14.225772    15.998501    15.760141\n",
      "  -14.520184   -14.45927     15.922519    14.058861   -14.201391\n",
      "  -15.922785   -15.905814    15.908472     0.9760641   15.800751\n",
      "  -15.593968   -15.840928    14.31811     15.762529    15.863315\n",
      "   15.40218    -15.80162     15.823449   -15.77844     15.996662\n",
      "   -0.61671555  14.797632   -14.705546     1.6935692   15.96656\n",
      "  -15.766426    15.792692   -15.88098     -1.1346924   15.988386\n",
      "    0.9999569  -15.354607   -15.605979    15.821038   -15.906072\n",
      "    2.534504     1.670115    15.806311   -15.716608    15.827866  ]]\n",
      "T 0\n",
      "P 3\n",
      "T [0.68834323]\n",
      "P [[-0.88813126]]\n",
      "[[-16.87571    -16.709486    16.591696   -16.787361   -16.618393\n",
      "   15.185627    16.901236    15.376825   -15.228624   -16.945229\n",
      "   16.850231    -1.          16.608631    16.776003   -15.447823\n",
      "  -16.546606    15.6635275   16.90235     -0.9826057   16.957474\n",
      "  -16.953098    15.976122    16.588356   -16.715292   -16.896353\n",
      "   16.905685    15.260387    15.406186    16.975647   -16.901266\n",
      "  -16.68886    -16.932356    -1.          16.823387   -15.89209\n",
      "   16.726988    16.46637    -16.755997    16.324055    15.40526\n",
      "  -16.36716     -1.0148724   16.31165    -16.633802   -15.115227\n",
      "   16.905321   -16.80941     16.727154   -16.680506     0.90676636\n",
      "   16.6255      16.449266   -16.876762    16.763172     1.260562\n",
      "   16.673584    16.847706    15.225772    16.9985      16.760141\n",
      "  -15.520167   -15.45927     16.92252     15.058861   -15.201391\n",
      "  -16.922785   -16.905815    16.908472    -0.02393591  16.80075\n",
      "  -16.593966   -16.840927    15.31811     16.762527    16.863316\n",
      "   16.40218    -16.80162     16.823448   -16.77844     16.996662\n",
      "   -1.6167156   15.797632   -15.705546     1.8372765   16.96656\n",
      "  -16.766426    16.792692   -16.88098      0.82704824  16.988386\n",
      "   -0.8296454  -16.354603   -16.605974    16.821037   -16.90607\n",
      "    2.6994634    1.088175    16.80631    -16.716608    16.827862  ]]\n",
      "T 10\n",
      "P 10\n",
      "T [-1.20663811]\n",
      "P [[-0.93966377]]\n",
      "[[-17.87571    -17.709486    17.591694   -17.787361   -17.618393\n",
      "   16.185627    17.901236    16.376825   -16.228622   -17.945219\n",
      "   17.850231    -0.967747    17.608622    17.776003   -16.447823\n",
      "  -17.546606    16.663527    17.90235     -1.          17.957474\n",
      "  -17.953098    16.976122    17.58834    -17.71529    -17.896353\n",
      "   17.905685    16.260387    16.406185    17.975647   -17.901266\n",
      "  -17.68886    -17.932356    -0.9991488   17.823387   -16.89209\n",
      "   17.726988    17.466368   -17.755997    17.32402     16.40526\n",
      "  -17.36716      0.8330871   17.31165    -17.633802   -16.115227\n",
      "   17.905321   -17.80941     17.727154   -17.680506    -0.42371446\n",
      "   17.6255      17.449266   -17.876759    17.763172    -0.9971306\n",
      "   17.673569    17.847706    16.225773    17.9985      17.760141\n",
      "  -16.520151   -16.459269    17.92252     16.05886    -16.201391\n",
      "  -17.922785   -17.905815    17.908472    -1.0108821   17.80075\n",
      "  -17.593966   -17.840906    16.318111    17.76252     17.863316\n",
      "   17.402153   -17.80162     17.823448   -17.77844     17.996662\n",
      "   -1.5467296   16.797632   -16.705547     2.0560997   17.96656\n",
      "  -17.766426    17.792692   -17.88098     -0.5848657   17.988386\n",
      "    0.7345577  -17.354603   -17.605965    17.821037   -17.906063\n",
      "    1.791832     2.088175    17.80631    -17.716608    17.827862  ]]\n",
      "T 11\n",
      "P 11\n",
      "T [-1.99069737]\n",
      "P [[-2.4346824]]\n",
      "[[-18.87571    -18.709486    18.591694   -18.787361   -18.618393\n",
      "   17.185627    18.901236    17.376825   -17.228622   -18.945219\n",
      "   18.850231    -1.          18.60862     18.776003   -17.447823\n",
      "  -18.546606    17.663525    18.90235     -0.48137483  18.957474\n",
      "  -18.953098    17.976122    18.58834    -18.71529    -18.896353\n",
      "   18.905685    17.260387    17.406185    18.975647   -18.901266\n",
      "  -18.68886    -18.932356    -1.3417598   18.823387   -17.89209\n",
      "   18.726988    18.466368   -18.755997    18.32402     17.405254\n",
      "  -18.36716     -1.          18.31165    -18.633802   -17.115227\n",
      "   18.905321   -18.80941     18.727154   -18.680506     0.42209277\n",
      "   18.6255      18.449266   -18.876759    18.763172     0.97477406\n",
      "   18.673567    18.847706    17.22577     18.9985      18.760141\n",
      "  -17.520151   -17.459269    18.92252     17.05886    -17.201391\n",
      "  -18.922785   -18.905815    18.908472    -1.8569348   18.80075\n",
      "  -18.593966   -18.840906    17.318111    18.762516    18.863316\n",
      "   18.402153   -18.80162     18.823448   -18.77844     18.996662\n",
      "   -2.2911272   17.797632   -17.705547     3.0556893   18.96656\n",
      "  -18.766426    18.792692   -18.88098      0.9421713   18.988386\n",
      "    0.7096958  -18.354603   -18.605965    18.821037   -18.906063\n",
      "    2.541114     2.132669    18.80631    -18.716608    18.82786   ]]\n",
      "T 8\n",
      "P 10\n",
      "T [-2.11225579]\n",
      "P [[-0.9298512]]\n",
      "[[-19.87571    -19.709486    19.591694   -19.787361   -19.618393\n",
      "   18.185627    19.901236    18.376825   -18.228619   -19.945211\n",
      "   19.850231     0.9987698   19.60861     19.776003   -18.447823\n",
      "  -19.546606    18.663525    19.902348    -1.          19.957474\n",
      "  -19.953098    18.976122    19.588322   -19.715288   -19.896353\n",
      "   19.905685    18.260387    18.406185    19.975647   -19.901266\n",
      "  -19.68886    -19.932356    -0.85069066  19.823387   -18.892088\n",
      "   19.726988    19.466368   -19.755997    19.324017    18.405254\n",
      "  -19.36716      0.6474352   19.31165    -19.633802   -18.115227\n",
      "   19.905321   -19.80941     19.727154   -19.680506    -0.6720316\n",
      "   19.6255      19.449266   -19.876759    19.763172    -0.9981022\n",
      "   19.673538    19.847706    18.22577     19.9985      19.760141\n",
      "  -18.52015    -18.459269    19.92252     18.05886    -18.201391\n",
      "  -19.922785   -19.905815    19.908472    -1.4224337   19.80075\n",
      "  -19.593966   -19.840906    18.318111    19.762505    19.863316\n",
      "   19.402151   -19.80162     19.823448   -19.77844     19.996662\n",
      "   -1.261673    18.797632   -18.705547     1.          19.96656\n",
      "  -19.766426    19.792692   -19.88098     -0.42542028  19.988386\n",
      "    1.7096958  -19.354603   -19.605936    19.821037   -19.905933\n",
      "    3.2221904    3.132669    19.80631    -19.716608    19.82786   ]]\n",
      "T 3\n",
      "P 3\n",
      "T [0.28383083]\n",
      "P [[-0.9646133]]\n",
      "[[-20.87571    -20.709486    20.591694   -20.787361   -20.618393\n",
      "   19.185627    20.901236    19.376825   -19.228619   -20.945211\n",
      "   20.850231    -0.9999998   20.608597    20.776003   -19.447823\n",
      "  -20.546606    19.663496    20.902332    -0.9903602   20.957474\n",
      "  -20.953098    19.976118    20.588322   -20.715288   -20.896353\n",
      "   20.905685    19.260387    19.406185    20.975647   -20.901266\n",
      "  -20.68886    -20.932356    -1.653578    20.823385   -19.892069\n",
      "   20.726988    20.466368   -20.755991    20.324017    19.405249\n",
      "  -20.36716     -0.8916502   20.31165    -20.633802   -19.115227\n",
      "   20.905321   -20.80941     20.727154   -20.680504    -0.9107282\n",
      "   20.6255      20.449266   -20.876759    20.763172     1.\n",
      "   20.673534    20.847702    19.22577     20.9985      20.760141\n",
      "  -19.520147   -19.459269    20.92252     19.05886    -19.201391\n",
      "  -20.922785   -20.905815    20.908472    -2.4224339   20.80075\n",
      "  -20.593962   -20.840906    19.318111    20.7625      20.863316\n",
      "   20.402151   -20.80162     20.823448   -20.77844     20.996662\n",
      "   -1.422421    19.797632   -19.705547     0.34552425  20.96656\n",
      "  -20.766426    20.792692   -20.88098     -0.9441092   20.988386\n",
      "    1.5154381  -20.354603   -20.605936    20.821037   -20.905933\n",
      "    3.2868915    0.87724805  20.80631    -20.716608    20.827858  ]]\n",
      "T 1\n",
      "P 1\n",
      "T [0.36179087]\n",
      "P [[-0.8684441]]\n",
      "[[-21.87571    -21.709486    21.591694   -21.787361   -21.618393\n",
      "   20.185627    21.901236    20.376825   -20.228619   -21.945204\n",
      "   21.850231     0.819633    21.608595    21.776003   -20.447823\n",
      "  -21.546606    20.663496    21.902327    -0.9999984   21.957474\n",
      "  -21.953098    20.976118    21.588318   -21.715288   -21.896353\n",
      "   21.905685    20.260387    20.406185    21.975647   -21.901266\n",
      "  -21.68886    -21.932356     0.21250963  21.823385   -20.892069\n",
      "   21.726988    21.466366   -21.755987    21.324017    20.405249\n",
      "  -21.36716      0.86695987  21.31165    -21.633802   -20.115227\n",
      "   21.905321   -21.80941     21.727154   -21.680504    -1.6044328\n",
      "   21.6255      21.449266   -21.876757    21.763172    -0.9984325\n",
      "   21.673532    21.847702    20.22577     21.9985      21.760141\n",
      "  -20.520145   -20.459269    21.92252     20.05886    -20.201391\n",
      "  -21.922785   -21.905815    21.908472    -1.7891208   21.80075\n",
      "  -21.593962   -21.840906    20.318111    21.762495    21.863316\n",
      "   21.402147   -21.80162     21.823448   -21.77844     21.996662\n",
      "   -1.4342095   20.797632   -20.705547     1.          21.96656\n",
      "  -21.766426    21.792692   -21.88098     -1.2382874   21.988386\n",
      "    1.6846399  -21.354603   -21.605927    21.821037   -21.905907\n",
      "    2.8489664    1.7659011   21.80631    -21.716608    21.827858  ]]\n",
      "T 15\n",
      "P 12\n",
      "T [-3.46293015]\n",
      "P [[-1.1326853]]\n",
      "[[-22.87571    -22.709486    22.591694   -22.787361   -22.618393\n",
      "   21.185627    22.901236    21.376825   -21.228619   -22.945204\n",
      "   22.850231    -0.9806714   22.608595    22.776003   -21.447823\n",
      "  -22.546606    21.663496    22.902327     0.99999976  22.957474\n",
      "  -22.953098    21.976118    22.588318   -22.715288   -22.896353\n",
      "   22.905685    21.260387    21.406185    22.975647   -22.901266\n",
      "  -22.68886    -22.932356    -0.8140851   22.823385   -21.892069\n",
      "   22.726988    22.466366   -22.755985    22.324017    21.405249\n",
      "  -22.367125    -1.          22.31165    -22.633802   -21.115227\n",
      "   22.905216   -22.80941     22.727154   -22.680504     0.999952\n",
      "   22.6255      22.449266   -22.876757    22.763172     1.\n",
      "   22.673532    22.847702    21.22577     22.9985      22.760141\n",
      "  -21.520145   -21.459269    22.92252     21.05886    -21.201391\n",
      "  -22.922785   -22.905815    22.908472    -2.7891207   22.80075\n",
      "  -22.593962   -22.840906    21.318111    22.762491    22.863316\n",
      "   22.402147   -22.80162     22.823448   -22.77844     22.996662\n",
      "   -2.0105205   21.797632   -21.705547     0.68246824  22.96656\n",
      "  -22.766426    22.792692   -22.88098      0.52549845  22.988386\n",
      "   -0.99661875 -22.354603   -22.605927    22.821037   -22.905907\n",
      "    3.8489664    0.03765124  22.80631    -22.716608    22.827858  ]]\n",
      "T 13\n",
      "P 13\n",
      "T [102.34869459]\n",
      "P [[100.13404]]\n",
      "[[-2.3875698e+01 -2.3709486e+01  2.3591692e+01 -2.3787361e+01\n",
      "  -2.3618393e+01  2.2185627e+01  2.3901236e+01  2.2376825e+01\n",
      "  -2.2228497e+01 -2.3945189e+01  2.3850231e+01  9.9975437e-01\n",
      "   2.3608578e+01  2.3776003e+01 -2.2447823e+01 -2.3546606e+01\n",
      "   2.2663496e+01  2.3902327e+01 -4.4217050e-01  2.3957474e+01\n",
      "  -2.3953098e+01  2.2976105e+01  2.3588263e+01 -2.3715279e+01\n",
      "  -2.3896353e+01  2.3905685e+01  2.2260387e+01  2.2406185e+01\n",
      "   2.3975647e+01 -2.3901266e+01 -2.3688860e+01 -2.3932356e+01\n",
      "   7.2474223e-01  2.3823385e+01 -2.2892067e+01  2.3726988e+01\n",
      "   2.3466366e+01 -2.3755985e+01  2.3323971e+01  2.2405249e+01\n",
      "  -2.3367125e+01  9.9456471e-01  2.3311649e+01 -2.3633802e+01\n",
      "  -2.2115227e+01  2.3905216e+01 -2.3809410e+01  2.3727154e+01\n",
      "  -2.3680504e+01 -4.7981739e-05  2.3625496e+01  2.3449266e+01\n",
      "  -2.3876740e+01  2.3763172e+01 -7.3048401e-01  2.3673531e+01\n",
      "   2.3847702e+01  2.2225771e+01  2.3998501e+01  2.3760141e+01\n",
      "  -2.2519945e+01 -2.2459232e+01  2.3922520e+01  2.2058861e+01\n",
      "  -2.2201389e+01 -2.3922783e+01 -2.3905813e+01  2.3908472e+01\n",
      "  -7.3874539e-01  2.3800751e+01 -2.3593962e+01 -2.3840837e+01\n",
      "   2.2318111e+01  2.2554531e+01  2.3863316e+01  2.3401297e+01\n",
      "  -2.3801620e+01  2.3823442e+01 -2.3778440e+01  2.3996662e+01\n",
      "   6.3643509e-01  2.2797628e+01 -2.2705547e+01  9.1122305e-01\n",
      "   2.3966560e+01 -2.3766426e+01  2.3792685e+01 -2.3880980e+01\n",
      "  -9.5936584e-01  2.3988386e+01  3.6102355e-01 -2.3354603e+01\n",
      "  -2.3605904e+01  2.3821037e+01 -2.3905724e+01  2.2227631e+00\n",
      "   1.0376513e+00  2.3806311e+01 -2.3716608e+01  2.3827858e+01]]\n",
      "T 7\n",
      "P 2\n",
      "T [-2.51278366]\n",
      "P [[-1.2691654]]\n",
      "[[-24.875698   -24.709486    24.591692   -24.787361   -24.618393\n",
      "   23.185602    24.901236    23.376825   -23.228497   -24.945189\n",
      "   24.850231    -0.66992927  24.608578    24.776003   -23.447823\n",
      "  -24.546606    23.663486    24.902327     0.98245484  24.957474\n",
      "  -24.953098    23.97609     24.588263   -24.715279   -24.896353\n",
      "   24.905685    23.260387    23.406185    24.975647   -24.901266\n",
      "  -24.68886    -24.932356    -0.5041214   24.823385   -23.892067\n",
      "   24.726988    24.466366   -24.755985    24.32397     23.405247\n",
      "  -24.367125    -1.          24.31165    -24.633802   -23.115227\n",
      "   24.905216   -24.80941     24.727154   -24.680504    -0.991653\n",
      "   24.625496    24.449266   -24.87674     24.763172     1.\n",
      "   24.67353     24.8477      23.225752    24.9985      24.760141\n",
      "  -23.519945   -23.459232    24.92252     23.05886    -23.20139\n",
      "  -24.922783   -24.905813    24.908472    -1.7387455   24.80075\n",
      "  -24.593962   -24.840837    23.318111    23.554531    24.863316\n",
      "   24.401297   -24.80162     24.823442   -24.77844     24.996662\n",
      "   -0.3635649   23.797628   -23.705547     1.8924074   24.96656\n",
      "  -24.766426    24.792685   -24.88098      0.7788216   24.988386\n",
      "   -0.63880336 -24.354603   -24.605904    24.821037   -24.905724\n",
      "    3.1029515   -0.97477096  24.80631    -24.716608    24.827847  ]]\n",
      "T 4\n",
      "P 4\n",
      "T [-0.84942066]\n",
      "P [[-0.88014066]]\n",
      "[[-2.5875683e+01 -2.5709486e+01  2.5591692e+01 -2.5787355e+01\n",
      "  -2.5618393e+01  2.4185602e+01  2.5901236e+01  2.4376825e+01\n",
      "  -2.4228495e+01 -2.5945187e+01  2.5850231e+01  9.8545343e-01\n",
      "   2.5608574e+01  2.5776003e+01 -2.4447823e+01 -2.5546606e+01\n",
      "   2.4663485e+01  2.5902327e+01 -5.8726764e-01  2.5957474e+01\n",
      "  -2.5953098e+01  2.4976089e+01  2.5588242e+01 -2.5715277e+01\n",
      "  -2.5896353e+01  2.5905685e+01  2.4260387e+01  2.4406185e+01\n",
      "   2.5975647e+01 -2.5901266e+01 -2.5688860e+01 -2.5932356e+01\n",
      "   8.4970438e-01  2.5823385e+01 -2.4892067e+01  2.5726988e+01\n",
      "   2.5466366e+01 -2.5755985e+01  2.5323965e+01  2.4405247e+01\n",
      "  -2.5367125e+01  9.9962795e-01  2.5311649e+01 -2.5633802e+01\n",
      "  -2.4115227e+01  2.5905216e+01 -2.5809410e+01  2.5727154e+01\n",
      "  -2.5680504e+01 -1.9916530e+00  2.5625486e+01  2.5449266e+01\n",
      "  -2.5876738e+01  2.5763172e+01  5.8221459e-02  2.5673529e+01\n",
      "   2.5847700e+01  2.4225752e+01  2.5998501e+01  2.5760141e+01\n",
      "  -2.4519943e+01 -2.4459171e+01  2.5922520e+01  2.4058861e+01\n",
      "  -2.4201361e+01 -2.5922783e+01 -2.5905813e+01  2.5908472e+01\n",
      "   9.9989891e-01  2.5800751e+01 -2.5593962e+01 -2.5840837e+01\n",
      "   2.4318111e+01  2.4554531e+01  2.5863316e+01  2.5401297e+01\n",
      "  -2.5801620e+01  2.5823442e+01 -2.5778440e+01  2.5996662e+01\n",
      "   7.5905442e-01  2.4787024e+01 -2.4705547e+01  1.3232807e+00\n",
      "   2.5966560e+01 -2.5766426e+01  2.5792685e+01 -2.5880980e+01\n",
      "  -3.2317948e-01  2.5988386e+01  7.9108071e-01 -2.5354603e+01\n",
      "  -2.5605892e+01  2.5821037e+01 -2.5905697e+01  2.3449779e-02\n",
      "   2.5229037e-02  2.5806311e+01 -2.5716608e+01  2.5827847e+01]]\n",
      "T 3\n",
      "P 3\n",
      "T [0.22376756]\n",
      "P [[-0.88759506]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.6875683e+01 -2.6709486e+01  2.6591692e+01 -2.6787355e+01\n",
      "  -2.6618393e+01  2.5185585e+01  2.6901236e+01  2.5376823e+01\n",
      "  -2.5228491e+01 -2.6945187e+01  2.6850231e+01 -8.7780166e-01\n",
      "   2.6608574e+01  2.6776003e+01 -2.5447823e+01 -2.6546606e+01\n",
      "   2.5663485e+01  2.6902327e+01  9.3966401e-01  2.6957474e+01\n",
      "  -2.6953098e+01  2.5976089e+01  2.6588240e+01 -2.6715277e+01\n",
      "  -2.6896353e+01  2.6905685e+01  2.5260387e+01  2.5406185e+01\n",
      "   2.6975647e+01 -2.6901266e+01 -2.6688860e+01 -2.6932356e+01\n",
      "  -3.7499422e-01  2.6823385e+01 -2.5892067e+01  2.6726988e+01\n",
      "   2.6466366e+01 -2.6755985e+01  2.6323965e+01  2.5405247e+01\n",
      "  -2.6367123e+01 -1.0000000e+00  2.6311646e+01 -2.6633802e+01\n",
      "  -2.5115225e+01  2.6905216e+01 -2.6809410e+01  2.6727154e+01\n",
      "  -2.6680504e+01  9.9819094e-01  2.6625486e+01  2.6449266e+01\n",
      "  -2.6876738e+01  2.6763172e+01  1.0000000e+00  2.6673529e+01\n",
      "   2.6847700e+01  2.5225752e+01  2.6998501e+01  2.6760141e+01\n",
      "  -2.5519943e+01 -2.5459171e+01  2.6922520e+01  2.5058861e+01\n",
      "  -2.5201361e+01 -2.6922783e+01 -2.6905813e+01  2.6908472e+01\n",
      "  -1.0108948e-04  2.6800751e+01 -2.6593962e+01 -2.6840837e+01\n",
      "   2.5318111e+01  2.5554531e+01  2.6863316e+01  2.6401297e+01\n",
      "  -2.6801620e+01  2.6823442e+01 -2.6778440e+01  2.6996662e+01\n",
      "  -2.4094558e-01  2.5787024e+01 -2.5705547e+01 -3.1030053e-01\n",
      "   2.6966560e+01 -2.6766426e+01  2.6792685e+01 -2.6880980e+01\n",
      "  -5.1175046e-01  2.6988386e+01 -3.2951176e-01 -2.6354603e+01\n",
      "  -2.6605890e+01  2.6821037e+01 -2.6905697e+01  1.0175643e+00\n",
      "  -9.9990213e-01  2.6806311e+01 -2.6716608e+01  2.6827843e+01]]\n",
      "T 3\n",
      "P 7\n",
      "T [-0.94255311]\n",
      "P [[20.725048]]\n",
      "[[-2.7875679e+01 -2.7709486e+01  2.7591690e+01 -2.7787207e+01\n",
      "  -2.7618393e+01  2.6185585e+01  2.7901236e+01  2.6376823e+01\n",
      "  -2.6228485e+01 -2.7945187e+01  2.7850231e+01  9.9999982e-01\n",
      "   2.7608248e+01  2.7776003e+01 -2.6447823e+01 -2.7546606e+01\n",
      "   2.6663485e+01  2.7902327e+01 -6.0335994e-02  2.7957474e+01\n",
      "  -2.7953098e+01  2.6976088e+01  2.7587719e+01 -2.7715231e+01\n",
      "  -2.7896353e+01  2.7905685e+01  2.6260387e+01  2.6406185e+01\n",
      "   2.7975647e+01 -2.7901266e+01 -2.7688860e+01 -2.7932356e+01\n",
      "   9.2724943e-01  2.7823381e+01 -2.6892063e+01  2.7726988e+01\n",
      "   2.7466366e+01 -2.7755985e+01  2.7323875e+01  2.6405247e+01\n",
      "  -2.7367123e+01  3.6502621e-01  2.7311646e+01 -2.7633802e+01\n",
      "  -2.6115225e+01  2.7905216e+01 -2.7809410e+01  2.7727154e+01\n",
      "  -2.7680504e+01 -1.8090606e-03  2.7625486e+01  2.7449266e+01\n",
      "  -2.7876734e+01  2.7763172e+01 -9.0158176e-01  2.7673519e+01\n",
      "   2.7847700e+01  2.6225752e+01  2.7998501e+01  2.7760141e+01\n",
      "  -2.6519531e+01 -2.6458735e+01  2.7922520e+01  2.6058861e+01\n",
      "  -2.6201361e+01 -2.7922783e+01 -2.7905813e+01  2.7908472e+01\n",
      "  -4.2820129e-01  2.7800751e+01 -2.7593962e+01 -2.7840816e+01\n",
      "   2.6318111e+01  2.6554516e+01  2.7863316e+01  2.7401226e+01\n",
      "  -2.7801620e+01  2.7823441e+01 -2.7778440e+01  2.7996662e+01\n",
      "   7.6005024e-01  2.6787024e+01 -2.6705547e+01  8.9120889e-01\n",
      "   2.7966558e+01 -2.7766426e+01  2.7792685e+01 -2.7880980e+01\n",
      "  -1.0210862e+00  2.7988386e+01  6.7048824e-01 -2.7354603e+01\n",
      "  -2.7605841e+01  2.7821037e+01 -2.7905470e+01 -3.4510404e-01\n",
      "   9.7870827e-05  2.7806311e+01 -2.7716608e+01  2.7827843e+01]]\n",
      "T 12\n",
      "P 6\n",
      "T [-1.60267903]\n",
      "P [[-1.1641251]]\n",
      "[[-28.875679   -28.709486    28.59169    -28.787207   -28.618393\n",
      "   27.185585    28.901236    27.376823   -27.228485   -28.945187\n",
      "   28.850231    -0.66694015  28.608246    28.776003   -27.447823\n",
      "  -28.546606    27.663437    28.902327     0.80979955  28.957474\n",
      "  -28.953098    27.976036    28.587719   -28.71523    -28.896353\n",
      "   28.905685    27.260387    27.406185    28.975647   -28.901266\n",
      "  -28.68886    -28.932356    -0.8709188   28.823381   -27.892063\n",
      "   28.726988    28.466366   -28.755985    28.323875    27.405235\n",
      "  -28.367123    -1.          28.311642   -28.633802   -27.115225\n",
      "   28.905216   -28.80941     28.727154   -28.680504    -0.9450753\n",
      "   28.625486    28.449266   -28.876734    28.763172     1.\n",
      "   28.67352     28.847698    27.22574     28.9985      28.760141\n",
      "  -27.519531   -27.458735    28.92252     27.058857   -27.20136\n",
      "  -28.922783   -28.905813    28.908472    -1.4282013   28.80075\n",
      "  -28.593958   -28.840816    27.318111    27.554516    28.863316\n",
      "   28.401226   -28.80162     28.82344    -28.77844     28.996662\n",
      "   -0.23994976  27.787024   -27.705547     0.497185    28.966558\n",
      "  -28.766426    28.792685   -28.88098     -0.55753565  28.988386\n",
      "    0.09764133 -28.354603   -28.60584     28.821037   -28.90547\n",
      "    0.6604848   -0.17399381  28.80631    -28.716608    28.82784   ]]\n",
      "T 4\n",
      "P 4\n",
      "T [-1.22483038]\n",
      "P [[-0.86712706]]\n",
      "[[-29.875675   -29.709486    29.59169    -29.787205   -29.618393\n",
      "   28.185585    29.901236    28.376823   -28.228477   -29.945187\n",
      "   29.850231     0.97016466  29.608212    29.776003   -28.447823\n",
      "  -29.546606    28.663431    29.902327    -0.8094139   29.957474\n",
      "  -29.953098    28.976036    29.587677   -29.715229   -29.896353\n",
      "   29.905685    28.260387    28.406185    29.975647   -29.901266\n",
      "  -29.68886    -29.932356     0.19445834  29.823381   -28.892063\n",
      "   29.726988    29.466366   -29.755985    29.323853    28.405235\n",
      "  -29.367123    -0.9761442   29.311642   -29.633802   -28.115225\n",
      "   29.905216   -29.80941     29.727154   -29.680504    -1.9450753\n",
      "   29.625486    29.449266   -29.876732    29.763172     0.2112626\n",
      "   29.673515    29.847698    28.22574     29.9985      29.760141\n",
      "  -28.519514   -28.458725    29.92252     28.058857   -28.20136\n",
      "  -29.922783   -29.905813    29.908472     0.5172399   29.80075\n",
      "  -29.593958   -29.840816    28.318111    28.55451     29.863316\n",
      "   29.401226   -29.80162     29.82344    -29.77844     29.996662\n",
      "    0.8061764   28.787024   -28.705547     1.          29.966558\n",
      "  -29.766426    29.792685   -29.88098     -1.0488774   29.988386\n",
      "    1.0851713  -29.354603   -29.605795    29.821037   -29.905436\n",
      "   -0.5481487    0.8260062   29.80631    -29.716608    29.82784   ]]\n",
      "T 1\n",
      "P 6\n",
      "T [-1.77076474]\n",
      "P [[-0.9064826]]\n",
      "[[-30.875675   -30.709486    30.59169    -30.787205   -30.618391\n",
      "   29.185585    30.901236    29.37682    -29.228477   -30.945187\n",
      "   30.850231    -1.          30.608212    30.776003   -29.447823\n",
      "  -30.546606    29.66341     30.901794     0.9983859   30.957474\n",
      "  -30.953098    29.976032    30.587677   -30.715229   -30.896353\n",
      "   30.905685    29.260387    29.406185    30.975647   -30.901266\n",
      "  -30.68886    -30.932356    -1.          30.823381   -29.892061\n",
      "   30.726988    30.466366   -30.75598     30.323853    29.405222\n",
      "  -30.367123    -1.          30.311434   -30.633802   -29.115225\n",
      "   30.905216   -30.80941     30.727154   -30.680504    -0.28160957\n",
      "   30.625486    30.449266   -30.876732    30.763172     1.0023787\n",
      "   30.673515    30.847698    29.22574     30.9985      30.760141\n",
      "  -29.519512   -29.458725    30.92252     29.058825   -29.20136\n",
      "  -30.922783   -30.905813    30.908472    -0.48276007  30.80075\n",
      "  -30.59395    -30.840816    29.318111    29.554508    30.863316\n",
      "   30.401226   -30.80162     30.82344    -30.77844     30.996662\n",
      "   -0.19382358  29.787024   -29.705547    -0.73816     30.966558\n",
      "  -30.766426    30.792685   -30.88098     -0.8422816   30.988386\n",
      "    0.04804334 -30.354603   -30.605795    30.821037   -30.905436\n",
      "    0.4518513   -0.9490111   30.80631    -30.716608    30.827803  ]]\n",
      "T 12\n",
      "P 12\n",
      "T [-0.98610088]\n",
      "P [[-0.88403237]]\n",
      "[[-31.875673   -31.709486    31.591688   -31.787205   -31.618391\n",
      "   30.185585    31.901236    30.37682    -30.228477   -31.945116\n",
      "   31.850231     0.9999812   31.608208    31.776003   -30.447823\n",
      "  -31.546606    30.663403    31.901794    -0.85828847  31.957474\n",
      "  -31.953098    30.976032    31.587666   -31.715225   -31.896353\n",
      "   31.905685    30.260387    30.406185    31.975647   -31.901266\n",
      "  -31.68886    -31.932356     0.9911348   31.823381   -30.892061\n",
      "   31.726986    31.46636    -31.75598     31.323843    30.405222\n",
      "  -31.367123     0.99999887  31.311434   -31.633802   -30.115225\n",
      "   31.905216   -31.80941     31.727154   -31.680504    -1.2798052\n",
      "   31.625486    31.449266   -31.876726    31.763172    -0.7523246\n",
      "   31.673513    31.847698    30.22574     31.9985      31.760141\n",
      "  -30.51951    -30.458714    31.92252     30.058825   -30.201355\n",
      "  -31.922783   -31.905813    31.908472     0.28085738  31.80075\n",
      "  -31.59395    -31.840805    30.318111    30.554506    31.863316\n",
      "   31.401222   -31.80162     31.823439   -31.77844     31.996662\n",
      "   -0.45759577  30.786917   -30.705547     0.9172363   31.966558\n",
      "  -31.766426    31.792685   -31.88098     -1.          31.988386\n",
      "    1.0355662  -31.354603   -31.605677    31.821035   -31.905373\n",
      "    1.217683     0.05098808  31.80631    -31.716608    31.827803  ]]\n",
      "T 1\n",
      "P 12\n",
      "T [-1.75730952]\n",
      "P [[-0.9383508]]\n",
      "[[-3.2875671e+01 -3.2709488e+01  3.2591690e+01 -3.2787205e+01\n",
      "  -3.2618389e+01  3.1185585e+01  3.2901237e+01  3.1376818e+01\n",
      "  -3.1228477e+01 -3.2945114e+01  3.2850231e+01 -1.0000000e+00\n",
      "   3.2608208e+01  3.2776001e+01 -3.1447821e+01 -3.2546608e+01\n",
      "   3.1663393e+01  3.2901791e+01  9.9986839e-01  3.2957474e+01\n",
      "  -3.2953098e+01  3.1976025e+01  3.2587666e+01 -3.2715225e+01\n",
      "  -3.2896355e+01  3.2905685e+01  3.1260387e+01  3.1406185e+01\n",
      "   3.2975647e+01 -3.2901268e+01 -3.2688858e+01 -3.2932358e+01\n",
      "  -4.0213615e-01  3.2823380e+01 -3.1892061e+01  3.2726986e+01\n",
      "   3.2466358e+01 -3.2755978e+01  3.2323845e+01  3.1405222e+01\n",
      "  -3.2367123e+01 -8.8803387e-01  3.2310978e+01 -3.2633804e+01\n",
      "  -3.1115225e+01  3.2905216e+01 -3.2809410e+01  3.2727154e+01\n",
      "  -3.2680504e+01  2.3353097e-04  3.2625488e+01  3.2449265e+01\n",
      "  -3.2876724e+01  3.2763172e+01  1.0000000e+00  3.2673512e+01\n",
      "   3.2847698e+01  3.1225740e+01  3.2998501e+01  3.2760139e+01\n",
      "  -3.1519510e+01 -3.1458714e+01  3.2922520e+01  3.1058825e+01\n",
      "  -3.1201355e+01 -3.2922783e+01 -3.2905815e+01  3.2908470e+01\n",
      "  -7.1914262e-01  3.2800751e+01 -3.2593948e+01 -3.2840805e+01\n",
      "   3.1318111e+01  3.1554506e+01  3.2863316e+01  3.2401222e+01\n",
      "  -3.2801620e+01  3.2823441e+01 -3.2778442e+01  3.2996662e+01\n",
      "  -1.3812270e+00  3.1786917e+01 -3.1705547e+01 -4.8253602e-01\n",
      "   3.2966560e+01 -3.2766426e+01  3.2792686e+01 -3.2880981e+01\n",
      "  -9.3523747e-01  3.2988388e+01 -8.4232628e-01 -3.2354603e+01\n",
      "  -3.2605675e+01  3.2821033e+01 -3.2905373e+01  1.9674292e+00\n",
      "   6.1977345e-01  3.2806313e+01 -3.2716606e+01  3.2827782e+01]]\n",
      "T 4\n",
      "P 4\n",
      "T [-1.3300907]\n",
      "P [[-1.0708178]]\n",
      "[[-33.875656   -33.709488    33.59169    -33.787178   -33.61839\n",
      "   32.185585    33.901237    32.376816   -32.228474   -33.945114\n",
      "   33.85023      0.9992431   33.608177    33.776      -32.447823\n",
      "  -33.546608    32.66339     33.90179     -0.6312997   33.957474\n",
      "  -33.9531      32.976025    33.58748    -33.71522    -33.896355\n",
      "   33.905685    32.260387    32.406185    33.975647   -33.901268\n",
      "  -33.688858   -33.932358     0.9336714   33.82338    -32.89206\n",
      "   33.726986    33.46636    -33.755978    33.323807    32.40522\n",
      "  -33.367123    -0.7506025   33.310978   -33.633804   -32.115227\n",
      "   33.905216   -33.80941     33.727154   -33.680504    -0.99976647\n",
      "   33.625484    33.449265   -33.876717    33.763172    -0.8182432\n",
      "   33.673508    33.8477      32.22574     33.9985      33.76014\n",
      "  -32.51949    -32.4587      33.92252     32.058823   -32.201355\n",
      "  -33.922783   -33.905815    33.90847      0.9818296   33.80075\n",
      "  -33.59395    -33.840744    32.31811     32.554497    33.863316\n",
      "   33.40122    -33.80162     33.82344    -33.778442    33.996662\n",
      "    0.19348752  32.78692    -32.705547     0.9419332   33.96656\n",
      "  -33.766426    33.792686   -33.88098     -1.1187667   33.988388\n",
      "    0.26750457 -33.354603   -33.60563     33.821033   -33.905357\n",
      "    0.45246863   1.6197734   33.806313   -33.716606    33.82778   ]]\n",
      "T 4\n",
      "P 4\n",
      "T [-0.22174503]\n",
      "P [[-0.8980626]]\n",
      "[[-3.4875656e+01 -3.4709488e+01  3.4591690e+01 -3.4787178e+01\n",
      "  -3.4618389e+01  3.3185585e+01  3.4901237e+01  3.3376816e+01\n",
      "  -3.3228474e+01 -3.4945114e+01  3.4850231e+01 -1.0000000e+00\n",
      "   3.4608177e+01  3.4776001e+01 -3.3447823e+01 -3.4546608e+01\n",
      "   3.3663387e+01  3.4901791e+01  9.9934113e-01  3.4957474e+01\n",
      "  -3.4953098e+01  3.3976025e+01  3.4587479e+01 -3.4715221e+01\n",
      "  -3.4896355e+01  3.4905685e+01  3.3260387e+01  3.3406185e+01\n",
      "   3.4975647e+01 -3.4901268e+01 -3.4688858e+01 -3.4932358e+01\n",
      "  -9.0754718e-01  3.4823380e+01 -3.3892059e+01  3.4726986e+01\n",
      "   3.4466358e+01 -3.4755978e+01  3.4323807e+01  3.3405220e+01\n",
      "  -3.4367123e+01 -1.0000000e+00  3.4310917e+01 -3.4633804e+01\n",
      "  -3.3115227e+01  3.4905216e+01 -3.4809410e+01  3.4727154e+01\n",
      "  -3.4680504e+01 -8.8898826e-01  3.4625484e+01  3.4449265e+01\n",
      "  -3.4876717e+01  3.4763172e+01  9.3310755e-01  3.4673508e+01\n",
      "   3.4847698e+01  3.3225739e+01  3.4998501e+01  3.4760139e+01\n",
      "  -3.3519489e+01 -3.3458698e+01  3.4922520e+01  3.3058823e+01\n",
      "  -3.3201355e+01 -3.4922783e+01 -3.4905815e+01  3.4908470e+01\n",
      "  -1.8170416e-02  3.4800751e+01 -3.4593945e+01 -3.4840744e+01\n",
      "   3.3318111e+01  3.3554497e+01  3.4863316e+01  3.4401218e+01\n",
      "  -3.4801620e+01  3.4823441e+01 -3.4778442e+01  3.4996662e+01\n",
      "  -8.0651248e-01  3.3786919e+01 -3.3705547e+01 -6.9154632e-01\n",
      "   3.4966560e+01 -3.4766426e+01  3.4792686e+01 -3.4880981e+01\n",
      "   2.2167210e-01  3.4988388e+01 -9.4827580e-01 -3.4354603e+01\n",
      "  -3.4605629e+01  3.4821033e+01 -3.4905357e+01  1.4524686e+00\n",
      "  -2.1620196e-01  3.4806313e+01 -3.4716606e+01  3.4827766e+01]]\n",
      "T 11\n",
      "P 4\n",
      "T [-0.02150348]\n",
      "P [[-0.90493405]]\n",
      "[[-35.875652   -35.709488    35.59169    -35.787178   -35.61839\n",
      "   34.185585    35.901237    34.3768     -34.228436   -35.945095\n",
      "   35.85023      0.9856302   35.60813     35.776      -34.447823\n",
      "  -35.546608    34.663376    35.90179     -0.6758269   35.957474\n",
      "  -35.9531      34.976025    35.587288   -35.715214   -35.896355\n",
      "   35.905685    34.260387    34.406185    35.975647   -35.901268\n",
      "  -35.688858   -35.932358    -0.83798313  35.82338    -34.89206\n",
      "   35.726986    35.46635    -35.755974    35.323627    34.40522\n",
      "  -35.367123     0.560648    35.310917   -35.633804   -34.115227\n",
      "   35.905216   -35.80941     35.727154   -35.680504    -1.8436803\n",
      "   35.62548     35.449265   -35.87671     35.763172    -0.51769024\n",
      "   35.673496    35.8477      34.22574     35.9985      35.76014\n",
      "  -34.519226   -34.4587      35.92252     34.058823   -34.201355\n",
      "  -35.922783   -35.905815    35.90847     -0.86338836  35.80075\n",
      "  -35.593945   -35.840714    34.31811     34.554485    35.863316\n",
      "   35.401215   -35.80162     35.82344    -35.778442    35.996662\n",
      "    0.4262442   34.78692    -34.705547     0.8963793   35.96656\n",
      "  -35.766426    35.792686   -35.88098     -0.962029    35.988388\n",
      "    0.7187927  -35.354595   -35.60553     35.821033   -35.9047\n",
      "    0.42987552   0.78379804  35.806313   -35.716606    35.827766  ]]\n",
      "T 2\n",
      "P 1\n",
      "T [-1.44544906]\n",
      "P [[-0.94391596]]\n",
      "[[-36.875652   -36.709488    36.59169    -36.787178   -36.61839\n",
      "   35.185585    36.901237    35.3768     -35.228436   -36.945095\n",
      "   36.85023     -1.          36.60813     36.776      -35.44782\n",
      "  -36.546608    35.663372    36.901783     0.9834006   36.957474\n",
      "  -36.9531      35.976025    36.587288   -36.715214   -36.896355\n",
      "   36.905685    35.260387    35.406185    36.975647   -36.901268\n",
      "  -36.688858   -36.932358    -1.5092008   36.82338    -35.89206\n",
      "   36.726986    36.46635    -36.75597     36.323627    35.40515\n",
      "  -36.367123    -0.830862    36.310917   -36.633804   -35.115227\n",
      "   36.905216   -36.80941     36.727154   -36.680504     0.8913155\n",
      "   36.62548     36.449265   -36.87671     36.763172     1.\n",
      "   36.673496    36.8477      35.22574     36.9985      36.76014\n",
      "  -35.519226   -35.4587      36.92252     35.058823   -35.201355\n",
      "  -36.922783   -36.905815    36.90847     -1.8633883   36.80075\n",
      "  -36.593945   -36.840714    35.31811     35.554485    36.863316\n",
      "   36.401215   -36.80162     36.82344    -36.778442    36.996662\n",
      "   -0.5737558   35.78692    -35.705547    -0.19683677  36.96656\n",
      "  -36.766426    36.792686   -36.88098      0.5575472   36.988388\n",
      "    0.15038352 -36.354595   -36.60553     36.821033   -36.9047\n",
      "    1.33404      0.76076674  36.806313   -36.716606    36.827747  ]]\n",
      "T 15\n",
      "P 4\n",
      "T [-1.86711124]\n",
      "P [[-0.89394414]]\n",
      "[[-37.875652   -37.709488    37.59169    -37.787178   -37.61839\n",
      "   36.185585    37.901237    36.3768     -36.228436   -37.945095\n",
      "   37.85023     -0.4159272   37.608097    37.776      -36.44782\n",
      "  -37.546608    36.663372    37.901783    -0.14544249  37.957474\n",
      "  -37.9531      36.976025    37.587105   -37.715176   -37.896355\n",
      "   37.905685    36.260387    36.406185    37.975647   -37.901268\n",
      "  -37.688858   -37.932358     0.66032875  37.82338    -36.89206\n",
      "   37.726986    37.466347   -37.75597     37.323517    36.40515\n",
      "  -37.367123     0.9999919   37.310917   -37.633804   -36.115227\n",
      "   37.905216   -37.80941     37.727154   -37.680504    -0.10868448\n",
      "   37.62548     37.449265   -37.876686    37.763172    -0.99829584\n",
      "   37.67347     37.8477      36.22574     37.9985      37.76014\n",
      "  -36.519226   -36.4587      37.92252     36.058823   -36.201355\n",
      "  -37.922783   -37.905815    37.90847      0.99480903  37.80075\n",
      "  -37.593945   -37.84071     36.31811     36.55442     37.863316\n",
      "   37.40119    -37.80162     37.82344    -37.778442    37.996662\n",
      "   -1.014853    36.78277    -36.705547     0.8097725   37.96656\n",
      "  -37.766426    37.792686   -37.88098     -0.63153505  37.988388\n",
      "    1.0364078  -37.354595   -37.60548     37.82103    -37.90441\n",
      "    1.9531829    1.7607667   37.806313   -37.716606    37.827747  ]]\n",
      "T 2\n",
      "P 2\n",
      "T [100.00115863]\n",
      "P [[101.64949]]\n",
      "[[-3.8875652e+01 -3.8709488e+01  3.8591690e+01 -3.8787178e+01\n",
      "  -3.8618389e+01  3.7185585e+01  3.8901237e+01  3.7376801e+01\n",
      "  -3.7228436e+01 -3.8945095e+01  3.8850231e+01 -1.0767769e+00\n",
      "   3.8608097e+01  3.8776001e+01 -3.7447819e+01 -3.8546608e+01\n",
      "   3.7663372e+01  3.8901783e+01 -8.7820202e-02  3.8957474e+01\n",
      "  -3.8953098e+01  3.7976025e+01  3.8587105e+01 -3.8715176e+01\n",
      "  -3.8896355e+01  3.8905685e+01  3.7260387e+01  3.7406185e+01\n",
      "   3.8975647e+01 -3.8901268e+01 -3.8688858e+01 -3.8932358e+01\n",
      "  -8.9302230e-01  3.8823376e+01 -3.7892059e+01  3.8726986e+01\n",
      "   3.8466347e+01 -3.8755970e+01  3.8323517e+01  3.7405151e+01\n",
      "  -3.8367123e+01 -1.0000000e+00  3.8310917e+01 -3.8633804e+01\n",
      "  -3.7115227e+01  3.8905216e+01 -3.8809410e+01  3.8727154e+01\n",
      "  -3.8680504e+01 -9.9720913e-01  3.8625481e+01  3.8449265e+01\n",
      "  -3.8876686e+01  3.8763172e+01  1.0000000e+00  3.8673470e+01\n",
      "   3.8847698e+01  3.7225739e+01  3.8998501e+01  3.8760139e+01\n",
      "  -3.7519226e+01 -3.7458698e+01  3.8922520e+01  3.7058823e+01\n",
      "  -3.7201355e+01 -3.8922783e+01 -3.8905815e+01  3.8908470e+01\n",
      "  -5.1909685e-03  3.8800751e+01 -3.8593941e+01 -3.8840710e+01\n",
      "   3.7318111e+01  3.7554420e+01  3.8863316e+01  3.8401192e+01\n",
      "  -3.8801620e+01  3.8823441e+01 -3.8778442e+01  3.8996662e+01\n",
      "  -1.9891105e+00  3.7782768e+01 -3.7705547e+01  1.7653997e+00\n",
      "   3.8966560e+01 -3.8766426e+01  3.8792686e+01 -3.8880981e+01\n",
      "   6.7670012e-01  3.8988388e+01  5.8460569e-01 -3.8354595e+01\n",
      "  -3.8605480e+01  3.8821030e+01 -3.8904411e+01  2.4928269e+00\n",
      "   8.8731140e-01  3.8806313e+01 -3.8716606e+01  3.8827740e+01]]\n",
      "T 6\n",
      "P 8\n",
      "T [-0.11367241]\n",
      "P [[-0.87216055]]\n",
      "[[-39.875652   -39.709488    39.59169    -39.787178   -39.61839\n",
      "   38.185585    39.901237    38.3768     -38.228436   -39.945095\n",
      "   39.85023      0.93615437  39.608097    39.776      -38.44782\n",
      "  -39.546608    38.663372    39.901783    -1.018425    39.957474\n",
      "  -39.9531      38.976025    39.58709    -39.71517    -39.896355\n",
      "   39.905685    38.260387    38.406185    39.975647   -39.901268\n",
      "  -39.688858   -39.932358     0.7001701   39.823376   -38.89206\n",
      "   39.726986    39.466347   -39.75597     39.323517    38.40515\n",
      "  -39.367123    -0.9583475   39.310917   -39.633804   -38.115227\n",
      "   39.905216   -39.80941     39.727154   -39.680504    -1.8541393\n",
      "   39.62548     39.449265   -39.876686    39.763172    -0.9998991\n",
      "   39.673462    39.8477      38.22574     39.9985      39.76014\n",
      "  -38.519226   -38.4587      39.92252     38.058823   -38.201355\n",
      "  -39.922783   -39.905815    39.90847     -1.0022645   39.80075\n",
      "  -39.59394    -39.84071     38.31811     38.554417    39.863316\n",
      "   39.401188   -39.80162     39.82344    -39.778442    39.996662\n",
      "   -2.1848736   38.78277    -38.705547     1.          39.96656\n",
      "  -39.766426    39.792686   -39.88098     -0.62745273  39.988388\n",
      "    1.3084742  -39.354595   -39.605476    39.82103    -39.904385\n",
      "    2.269763     1.887311    39.806313   -39.716606    39.82774   ]]\n",
      "T 12\n",
      "P 12\n",
      "T [-1.49337206]\n",
      "P [[-0.922197]]\n",
      "[[-40.875652   -40.709488    40.59169    -40.787178   -40.61839\n",
      "   39.185585    40.901237    39.3768     -39.228436   -40.945095\n",
      "   40.85023     -1.          40.608097    40.776      -39.44782\n",
      "  -40.546608    39.663372    40.901783     0.9991182   40.957474\n",
      "  -40.9531      39.976025    40.58709    -40.71517    -40.896355\n",
      "   40.905685    39.260387    39.406185    40.975647   -40.901268\n",
      "  -40.688858   -40.932358    -0.58249617  40.823376   -39.89206\n",
      "   40.726986    40.466347   -40.75597     40.323517    39.40515\n",
      "  -40.367123    -1.          40.310917   -40.633804   -39.115227\n",
      "   40.905216   -40.80941     40.727154   -40.680504    -0.9497903\n",
      "   40.62548     40.449265   -40.876686    40.763172     1.\n",
      "   40.673462    40.8477      39.22574     40.9985      40.76014\n",
      "  -39.519226   -39.4587      40.92252     39.058823   -39.201355\n",
      "  -40.922783   -40.905815    40.90847     -2.0022645   40.80075\n",
      "  -40.59394    -40.84071     39.31811     39.554417    40.863316\n",
      "   40.401188   -40.80162     40.82344    -40.778442    40.996662\n",
      "   -1.3071179   39.78277    -39.705547     1.2781065   40.96656\n",
      "  -40.766426    40.792686   -40.88098     -0.67998105  40.988388\n",
      "   -0.4428642  -40.354595   -40.605476    40.82103    -40.904385\n",
      "    2.8563519   -0.99986887  40.806313   -40.716606    40.827736  ]]\n",
      "T 12\n",
      "P 12\n",
      "T [-1.75543112]\n",
      "P [[-0.941713]]\n",
      "[[-4.1875652e+01 -4.1709488e+01  4.1591690e+01 -4.1787178e+01\n",
      "  -4.1618389e+01  4.0185585e+01  4.1901237e+01  4.0376801e+01\n",
      "  -4.0228436e+01 -4.1945076e+01  4.1850231e+01  9.9999350e-01\n",
      "   4.1608093e+01  4.1776001e+01 -4.0447819e+01 -4.1546608e+01\n",
      "   4.0663368e+01  4.1901783e+01 -4.1845155e-01  4.1957474e+01\n",
      "  -4.1953098e+01  4.0976025e+01  4.1587090e+01 -4.1715172e+01\n",
      "  -4.1896355e+01  4.1905685e+01  4.0260387e+01  4.0406185e+01\n",
      "   4.1975647e+01 -4.1901268e+01 -4.1688858e+01 -4.1932358e+01\n",
      "   3.3991855e-01  4.1823376e+01 -4.0892059e+01  4.1726986e+01\n",
      "   4.1466347e+01 -4.1755970e+01  4.1323517e+01  4.0405151e+01\n",
      "  -4.1367123e+01  9.9997127e-01  4.1310917e+01 -4.1633804e+01\n",
      "  -4.0115227e+01  4.1905216e+01 -4.1809410e+01  4.1727154e+01\n",
      "  -4.1680504e+01 -1.9497902e+00  4.1625481e+01  4.1449265e+01\n",
      "  -4.1876667e+01  4.1763172e+01  8.3063143e-01  4.1673462e+01\n",
      "   4.1847698e+01  4.0225739e+01  4.1998501e+01  4.1760139e+01\n",
      "  -4.0519226e+01 -4.0458549e+01  4.1922520e+01  4.0058823e+01\n",
      "  -4.0201351e+01 -4.1922783e+01 -4.1905815e+01  4.1908470e+01\n",
      "   9.9986213e-01  4.1800751e+01 -4.1593941e+01 -4.1840702e+01\n",
      "   4.0318111e+01  4.0554417e+01  4.1863316e+01  4.1401188e+01\n",
      "  -4.1801620e+01  4.1823441e+01 -4.1778442e+01  4.1996662e+01\n",
      "   3.3703369e-01  4.0782761e+01 -4.0705547e+01  1.7018001e+00\n",
      "   4.1966560e+01 -4.1766426e+01  4.1792686e+01 -4.1880981e+01\n",
      "  -1.0913038e+00  4.1988388e+01  8.4982008e-01 -4.1354595e+01\n",
      "  -4.1605473e+01  4.1821030e+01 -4.1904362e+01  8.1437677e-01\n",
      "   1.3113022e-04  4.1806313e+01 -4.1716606e+01  4.1827736e+01]]\n",
      "T 3\n",
      "P 3\n",
      "T [-1.5677602]\n",
      "P [[-0.9166812]]\n",
      "[[-4.2875652e+01 -4.2709488e+01  4.2591690e+01 -4.2787178e+01\n",
      "  -4.2618389e+01  4.1185585e+01  4.2901237e+01  4.1376797e+01\n",
      "  -4.1228413e+01 -4.2945076e+01  4.2850231e+01 -9.5672208e-01\n",
      "   4.2608089e+01  4.2776001e+01 -4.1447819e+01 -4.2546608e+01\n",
      "   4.1663364e+01  4.2901775e+01 -4.0856621e-01  4.2957474e+01\n",
      "  -4.2953098e+01  4.1976025e+01  4.2587082e+01 -4.2715172e+01\n",
      "  -4.2896355e+01  4.2905685e+01  4.1260387e+01  4.1406185e+01\n",
      "   4.2975647e+01 -4.2901268e+01 -4.2688858e+01 -4.2932358e+01\n",
      "  -7.5967693e-01  4.2823376e+01 -4.1892059e+01  4.2726986e+01\n",
      "   4.2466347e+01 -4.2755966e+01  4.2323517e+01  4.1405151e+01\n",
      "  -4.2367115e+01 -1.0000000e+00  4.2310917e+01 -4.2633804e+01\n",
      "  -4.1115227e+01  4.2905209e+01 -4.2809410e+01  4.2727154e+01\n",
      "  -4.2680504e+01  7.8996199e-01  4.2625481e+01  4.2449265e+01\n",
      "  -4.2876667e+01  4.2763172e+01  1.0000000e+00  4.2673462e+01\n",
      "   4.2847698e+01  4.1225739e+01  4.2998501e+01  4.2760139e+01\n",
      "  -4.1519226e+01 -4.1458549e+01  4.2922520e+01  4.1058823e+01\n",
      "  -4.1201351e+01 -4.2922783e+01 -4.2905815e+01  4.2908470e+01\n",
      "  -1.3786554e-04  4.2800751e+01 -4.2593941e+01 -4.2840702e+01\n",
      "   4.1318111e+01  4.1554417e+01  4.2863316e+01  4.2401188e+01\n",
      "  -4.2801620e+01  4.2823441e+01 -4.2778442e+01  4.2996662e+01\n",
      "  -6.6296631e-01  4.1782761e+01 -4.1705547e+01  2.0304292e-01\n",
      "   4.2966560e+01 -4.2766426e+01  4.2792686e+01 -4.2880981e+01\n",
      "  -5.5572289e-01  4.2988388e+01 -1.5707909e-01 -4.2354595e+01\n",
      "  -4.2605469e+01  4.2821030e+01 -4.2904362e+01  1.5784826e+00\n",
      "  -9.9951273e-01  4.2806313e+01 -4.2716606e+01  4.2827728e+01]]\n",
      "T 10\n",
      "P 3\n",
      "T [-1.25482428]\n",
      "P [[-1.1670173]]\n",
      "[[-4.3875648e+01 -4.3709488e+01  4.3591690e+01 -4.3787174e+01\n",
      "  -4.3618389e+01  4.2185585e+01  4.3901237e+01  4.2376797e+01\n",
      "  -4.2228409e+01 -4.3945076e+01  4.3850231e+01  9.0054423e-01\n",
      "   4.3608074e+01  4.3776001e+01 -4.2447819e+01 -4.3546608e+01\n",
      "   4.2663364e+01  4.3901775e+01 -1.1748142e+00  4.3957474e+01\n",
      "  -4.3953098e+01  4.2976025e+01  4.3587078e+01 -4.3715172e+01\n",
      "  -4.3896355e+01  4.3905685e+01  4.2260387e+01  4.2406185e+01\n",
      "   4.3975647e+01 -4.3901268e+01 -4.3688858e+01 -4.3932358e+01\n",
      "  -2.6251942e-01  4.3823372e+01 -4.2892059e+01  4.3726986e+01\n",
      "   4.3466343e+01 -4.3755966e+01  4.3323494e+01  4.2405151e+01\n",
      "  -4.3367115e+01  9.9999297e-01  4.3310917e+01 -4.3633804e+01\n",
      "  -4.2115227e+01  4.3905209e+01 -4.3809410e+01  4.3727154e+01\n",
      "  -4.3680504e+01 -3.9786035e-01  4.3625473e+01  4.3449265e+01\n",
      "  -4.3876663e+01  4.3763172e+01 -9.8223931e-01  4.3673458e+01\n",
      "   4.3847698e+01  4.2225739e+01  4.3998501e+01  4.3760139e+01\n",
      "  -4.2519218e+01 -4.2458546e+01  4.3922520e+01  4.2058823e+01\n",
      "  -4.2201340e+01 -4.3922783e+01 -4.3905815e+01  4.3908470e+01\n",
      "  -6.3685799e-01  4.3800751e+01 -4.3593941e+01 -4.3840633e+01\n",
      "   4.2318111e+01  4.2554401e+01  4.3863316e+01  4.3401188e+01\n",
      "  -4.3801620e+01  4.3823441e+01 -4.3778442e+01  4.3996662e+01\n",
      "  -1.0356416e+00  4.2782761e+01 -4.2705547e+01  1.1336977e+00\n",
      "   4.3966560e+01 -4.3766426e+01  4.3792686e+01 -4.3880981e+01\n",
      "  -1.0962695e+00  4.3988388e+01  8.8775122e-01 -4.3354595e+01\n",
      "  -4.3605461e+01  4.3821030e+01 -4.3904350e+01  2.9484826e-01\n",
      "   4.8726797e-04  4.3806313e+01 -4.3716606e+01  4.3827728e+01]]\n",
      "T 4\n",
      "P 10\n",
      "T [-1.05918824]\n",
      "P [[-1.5812291]]\n",
      "[[-44.87565    -44.709488    44.59169    -44.787174   -44.61839\n",
      "   43.185585    44.901237    43.376797   -43.22841    -44.945076\n",
      "   44.85023     -1.          44.608074    44.776      -43.44782\n",
      "  -44.546608    43.663364    44.901775     0.78169847  44.957474\n",
      "  -44.9531      43.976025    44.58708    -44.71517    -44.896355\n",
      "   44.905685    43.260387    43.406185    44.975647   -44.901268\n",
      "  -44.688858   -44.932358    -1.032483    44.82337    -43.89206\n",
      "   44.726986    44.466343   -44.755966    44.323494    43.40515\n",
      "  -44.367115    -0.9535614   44.310917   -44.633804   -43.115227\n",
      "   44.90521    -44.80941     44.727154   -44.680504    -0.9984156\n",
      "   44.625473    44.449265   -44.876663    44.763172     1.\n",
      "   44.67346     44.8477      43.22574     44.9985      44.76014\n",
      "  -43.51922    -43.458546    44.92252     43.058823   -43.20134\n",
      "  -44.922783   -44.905815    44.90847     -1.636858    44.80075\n",
      "  -44.59394    -44.840633    43.31811     43.5544      44.863316\n",
      "   44.401188   -44.80162     44.82344    -44.778442    44.996662\n",
      "   -2.0356417   43.78276    -43.705547     0.35053748  44.96656\n",
      "  -44.766426    44.792686   -44.88098     -0.45336574  44.988388\n",
      "   -0.8099108  -44.354595   -44.60546     44.82103    -44.90435\n",
      "    1.2948482    0.9780298   44.806313   -44.716606    44.827713  ]]\n",
      "T 4\n",
      "P 4\n",
      "T [-0.51303436]\n",
      "P [[-0.89448726]]\n",
      "[[-45.875633   -45.709488    45.59169    -45.787174   -45.61839\n",
      "   44.185585    45.901237    44.376797   -44.2284     -45.945076\n",
      "   45.85023      0.81504583  45.60806     45.776      -44.44782\n",
      "  -45.546608    44.663364    45.901775    -0.96933144  45.957474\n",
      "  -45.9531      44.976025    45.58688    -45.71517    -45.896355\n",
      "   45.905685    44.260387    44.406185    45.975647   -45.901268\n",
      "  -45.688858   -45.932358     0.19598636  45.82337    -44.89206\n",
      "   45.726986    45.466343   -45.755966    45.323425    44.40515\n",
      "  -45.367115    -1.3924944   45.310917   -45.633804   -44.115227\n",
      "   45.90521    -45.80941     45.727154   -45.680504    -1.9984156\n",
      "   45.625473    45.449265   -45.87666     45.763172    -0.49636257\n",
      "   45.673454    45.8477      44.22574     45.9985      45.76014\n",
      "  -44.51912    -44.458538    45.92252     44.058823   -44.20134\n",
      "  -45.922783   -45.905815    45.90847      0.61228365  45.80075\n",
      "  -45.59394    -45.840633    44.31811     44.55439     45.863316\n",
      "   45.40118    -45.80162     45.82344    -45.778442    45.996662\n",
      "   -0.7999672   44.78276    -44.705547     1.          45.96656\n",
      "  -45.766426    45.792686   -45.88098     -1.          45.988388\n",
      "    0.29050338 -45.354595   -45.605385    45.82103    -45.904278\n",
      "    0.13341314   1.9780297   45.806313   -45.716606    45.827713  ]]\n",
      "T 6\n",
      "P 4\n",
      "T [-2.22353075]\n",
      "P [[-0.8975495]]\n",
      "[[-46.875633   -46.709488    46.59169    -46.787174   -46.61839\n",
      "   45.185585    46.901237    45.376774   -45.2284     -46.945076\n",
      "   46.85023     -1.          46.60806     46.776      -45.44782\n",
      "  -46.546608    45.663364    46.901775     0.9960107   46.957474\n",
      "  -46.9531      45.976025    46.58688    -46.71517    -46.896355\n",
      "   46.905685    45.260387    45.406185    46.975647   -46.901268\n",
      "  -46.688858   -46.932358    -0.893351    46.82337    -45.89206\n",
      "   46.726986    46.466343   -46.755966    46.323425    45.40515\n",
      "  -46.367107    -1.8113735   46.310913   -46.633804   -45.115227\n",
      "   46.90521    -46.80941     46.727154   -46.680504     0.98857707\n",
      "   46.625473    46.449265   -46.87666     46.763172     0.9542215\n",
      "   46.673454    46.8477      45.22574     46.9985      46.76014\n",
      "  -45.51912    -45.458538    46.92252     45.058823   -45.20134\n",
      "  -46.922783   -46.905815    46.90847     -0.38771635  46.80075\n",
      "  -46.59394    -46.840633    45.31811     45.55439     46.863316\n",
      "   46.40118    -46.80162     46.82344    -46.778442    46.996662\n",
      "   -1.7999673   45.78276    -45.705547    -0.78396887  46.96656\n",
      "  -46.766426    46.792686   -46.88098     -0.32884055  46.988388\n",
      "   -0.8355064  -46.354595   -46.605385    46.82103    -46.904278\n",
      "    1.0852722   -0.90641564  46.806313   -46.716606    46.827698  ]]\n",
      "T 2\n",
      "P 7\n",
      "T [-0.87244846]\n",
      "P [[-1.0428332]]\n",
      "[[-4.7875610e+01 -4.7709488e+01  4.7591690e+01 -4.7784237e+01\n",
      "  -4.7618389e+01  4.6185585e+01  4.7901237e+01  4.6376774e+01\n",
      "  -4.6228397e+01 -4.7945076e+01  4.7850231e+01  1.0000000e+00\n",
      "   4.7607998e+01  4.7776001e+01 -4.6447819e+01 -4.7546608e+01\n",
      "   4.6663364e+01  4.7901775e+01 -3.9892793e-03  4.7957474e+01\n",
      "  -4.7953098e+01  4.6976025e+01  4.7586708e+01 -4.7715141e+01\n",
      "  -4.7896355e+01  4.7905685e+01  4.6260387e+01  4.6406185e+01\n",
      "   4.7975647e+01 -4.7901268e+01 -4.7688858e+01 -4.7932358e+01\n",
      "   9.9883085e-01  4.7823353e+01 -4.6892059e+01  4.7726986e+01\n",
      "   4.7466343e+01 -4.7755966e+01  4.7323364e+01  4.6405151e+01\n",
      "  -4.7367107e+01  4.0219712e-01  4.7310913e+01 -4.7633804e+01\n",
      "  -4.6115227e+01  4.7905209e+01 -4.7809410e+01  4.7727154e+01\n",
      "  -4.7680504e+01 -1.1422932e-02  4.7624699e+01  4.7449265e+01\n",
      "  -4.7876659e+01  4.7763172e+01 -9.9789393e-01  4.7673443e+01\n",
      "   4.7847698e+01  4.6225739e+01  4.7998501e+01  4.7760139e+01\n",
      "  -4.6519115e+01 -4.6458534e+01  4.7922520e+01  4.6058823e+01\n",
      "  -4.6201340e+01 -4.7922783e+01 -4.7905815e+01  4.7908470e+01\n",
      "   9.9999440e-01  4.7800751e+01 -4.7593941e+01 -4.7839424e+01\n",
      "   4.6318111e+01  4.6554321e+01  4.7863316e+01  4.7401169e+01\n",
      "  -4.7801620e+01  4.7823441e+01 -4.7778442e+01  4.7996662e+01\n",
      "   2.6350462e-01  4.6782761e+01 -4.6705547e+01  8.3477217e-01\n",
      "   4.7966560e+01 -4.7766426e+01  4.7792686e+01 -4.7880981e+01\n",
      "  -1.0000000e+00  4.7988388e+01  1.6449362e-01 -4.7354595e+01\n",
      "  -4.7605358e+01  4.7821030e+01 -4.7904243e+01 -3.6794913e-01\n",
      "   9.3584359e-02  4.7806313e+01 -4.7716606e+01  4.7827698e+01]]\n",
      "T 10\n",
      "P 7\n",
      "T [-1.008979]\n",
      "P [[-1.0705687]]\n",
      "[[-4.8875610e+01 -4.8709488e+01  4.8591690e+01 -4.8784237e+01\n",
      "  -4.8618389e+01  4.7185585e+01  4.8901237e+01  4.7376728e+01\n",
      "  -4.7228394e+01 -4.8945076e+01  4.8850231e+01 -6.4417195e-01\n",
      "   4.8607998e+01  4.8776001e+01 -4.7447819e+01 -4.8546608e+01\n",
      "   4.7663338e+01  4.8901775e+01  9.9674726e-01  4.8957474e+01\n",
      "  -4.8953098e+01  4.7976013e+01  4.8586708e+01 -4.8715141e+01\n",
      "  -4.8896355e+01  4.8905685e+01  4.7260387e+01  4.7406185e+01\n",
      "   4.8975647e+01 -4.8901268e+01 -4.8688858e+01 -4.8932358e+01\n",
      "  -9.3082982e-01  4.8823349e+01 -4.7892059e+01  4.8726986e+01\n",
      "   4.8466343e+01 -4.8755962e+01  4.8323364e+01  4.7405090e+01\n",
      "  -4.8367100e+01 -9.2910367e-01  4.8310898e+01 -4.8633804e+01\n",
      "  -4.7115227e+01  4.8905209e+01 -4.8809410e+01  4.8727154e+01\n",
      "  -4.8680500e+01  9.5101285e-01  4.8624699e+01  4.8449265e+01\n",
      "  -4.8876659e+01  4.8763172e+01  1.0000000e+00  4.8673443e+01\n",
      "   4.8847698e+01  4.7225739e+01  4.8998501e+01  4.8760139e+01\n",
      "  -4.7519115e+01 -4.7458534e+01  4.8922520e+01  4.7058723e+01\n",
      "  -4.7201340e+01 -4.8922783e+01 -4.8905815e+01  4.8908470e+01\n",
      "  -5.6028366e-06  4.8800751e+01 -4.8593933e+01 -4.8839420e+01\n",
      "   4.7318111e+01  4.7554310e+01  4.8863316e+01  4.8401169e+01\n",
      "  -4.8801620e+01  4.8823441e+01 -4.8778442e+01  4.8996662e+01\n",
      "  -7.3649538e-01  4.7782761e+01 -4.7705547e+01  1.0442921e+00\n",
      "   4.8966560e+01 -4.8766426e+01  4.8792686e+01 -4.8880981e+01\n",
      "  -2.6075266e-02  4.8988388e+01  5.9376115e-01 -4.8354595e+01\n",
      "  -4.8605358e+01  4.8821030e+01 -4.8904243e+01  6.3205087e-01\n",
      "   9.7585386e-01  4.8806313e+01 -4.8716606e+01  4.8827660e+01]]\n",
      "T 8\n",
      "P 15\n",
      "T [-0.49375141]\n",
      "P [[-0.89663184]]\n",
      "[[-49.87561    -49.709488    49.591686   -49.784237   -49.61839\n",
      "   48.185585    49.901237    48.376728   -48.22838    -49.94507\n",
      "   49.85023      0.9996361   49.60798     49.776      -48.44782\n",
      "  -49.546608    48.663338    49.90177     -0.86357903  49.957474\n",
      "  -49.9531      48.976013    49.58666    -49.71513    -49.896355\n",
      "   49.905685    48.260387    48.406185    49.975647   -49.901268\n",
      "  -49.688858   -49.932358    -0.10423641  49.82335    -48.892056\n",
      "   49.726986    49.466343   -49.75596     49.32328     48.40509\n",
      "  -49.3671       0.6874347   49.310898   -49.633804   -48.115227\n",
      "   49.90521    -49.80941     49.727154   -49.6805      -0.18879741\n",
      "   49.6247      49.449265   -49.876656    49.763172    -0.9958282\n",
      "   49.673412    49.8477      48.22574     49.9985      49.76014\n",
      "  -48.51908    -48.458534    49.92252     48.058723   -48.20134\n",
      "  -49.922783   -49.905815    49.90847     -0.9998943   49.80075\n",
      "  -49.593933   -49.839417    48.31811     48.55427     49.863316\n",
      "   49.40117    -49.80162     49.82344    -49.778442    49.996662\n",
      "   -1.2259611   48.78276    -48.705547     1.          49.96656\n",
      "  -49.766426    49.792686   -49.88098     -1.0031612   49.988388\n",
      "    1.5937612  -49.35459    -49.604755    49.82103    -49.903164\n",
      "    1.5577829    1.9758539   49.806313   -49.716606    49.82766   ]]\n",
      "T 15\n",
      "P 3\n",
      "T [-0.24693167]\n",
      "P [[-1.054042]]\n",
      "[[-50.87561    -50.709488    50.591686   -50.784237   -50.61839\n",
      "   49.18553     50.901237    49.376728   -49.22838    -50.94507\n",
      "   50.85023     -0.7906717   50.607975    50.776      -49.44782\n",
      "  -50.546608    49.663338    50.90177      0.9999989   50.957474\n",
      "  -50.9531      49.976013    50.58666    -50.71513    -50.896355\n",
      "   50.905685    49.260387    49.406174    50.975647   -50.901268\n",
      "  -50.688858   -50.932358    -1.0178905   50.82335    -49.892056\n",
      "   50.726986    50.466343   -50.75596     50.32328     49.40509\n",
      "  -50.36708     -1.          50.310898   -50.633804   -49.115227\n",
      "   50.90521    -50.80941     50.727154   -50.680496     0.99740666\n",
      "   50.6247      50.449265   -50.876656    50.763172     0.79588616\n",
      "   50.673412    50.8477      49.22574     50.9985      50.76014\n",
      "  -49.51908    -49.458534    50.92252     49.058723   -49.20134\n",
      "  -50.922783   -50.905815    50.90847     -1.9998944   50.80075\n",
      "  -50.593933   -50.839417    49.31811     49.554256    50.863316\n",
      "   50.40117    -50.80162     50.82344    -50.778442    50.996662\n",
      "   -1.7796755   49.78276    -49.705547     1.7016121   50.96656\n",
      "  -50.766426    50.792686   -50.88098      0.7896425   50.988388\n",
      "   -0.86117214 -50.35459    -50.604755    50.82103    -50.903164\n",
      "    2.557783    -0.9183142   50.806313   -50.716606    50.82766   ]]\n",
      "T 2\n",
      "P 2\n",
      "T [100.91643487]\n",
      "P [[101.47567]]\n",
      "[[-5.1875607e+01 -5.1709488e+01  5.1591686e+01 -5.1781879e+01\n",
      "  -5.1618389e+01  5.0185532e+01  5.1901237e+01  5.0376728e+01\n",
      "  -5.0228378e+01 -5.1945068e+01  5.1850231e+01  9.9999994e-01\n",
      "   5.1607960e+01  5.1776001e+01 -5.0447819e+01 -5.1546608e+01\n",
      "   5.0663338e+01  5.1901772e+01 -1.0728836e-06  5.1957474e+01\n",
      "  -5.1953098e+01  5.0976013e+01  5.1586601e+01 -5.1715111e+01\n",
      "  -5.1896355e+01  5.1905685e+01  5.0260387e+01  5.0406174e+01\n",
      "   5.1975647e+01 -5.1901268e+01 -5.1688858e+01 -5.1932358e+01\n",
      "   9.7723770e-01  5.1823345e+01 -5.0892056e+01  5.1726986e+01\n",
      "   5.1466343e+01 -5.1755959e+01  5.1323265e+01  5.0405090e+01\n",
      "  -5.1367081e+01  6.4572668e-01  5.1310898e+01 -5.1633804e+01\n",
      "  -5.0115227e+01  5.1905209e+01 -5.1809410e+01  5.1727154e+01\n",
      "  -5.1680496e+01 -2.5933385e-03  5.1624645e+01  5.1449265e+01\n",
      "  -5.1876656e+01  5.1763172e+01 -9.9757016e-01  5.1673409e+01\n",
      "   5.1847698e+01  5.0225739e+01  5.1998501e+01  5.1760139e+01\n",
      "  -5.0519081e+01 -5.0458534e+01  5.1922520e+01  5.0058723e+01\n",
      "  -5.0201340e+01 -5.1922783e+01 -5.1905815e+01  5.1908470e+01\n",
      "   9.9998587e-01  5.1800751e+01 -5.1593933e+01 -5.1839352e+01\n",
      "   5.0318111e+01  5.0554218e+01  5.1863316e+01  5.1401161e+01\n",
      "  -5.1801620e+01  5.1823441e+01 -5.1778442e+01  5.1996662e+01\n",
      "   8.2515478e-01  5.0782761e+01 -5.0705547e+01  9.2294061e-01\n",
      "   5.1966560e+01 -5.1766426e+01  5.1792686e+01 -5.1880981e+01\n",
      "  -6.2408328e-01  5.1988388e+01  1.3882786e-01 -5.1354591e+01\n",
      "  -5.1604752e+01  5.1821030e+01 -5.1903156e+01  1.1179576e+00\n",
      "   8.1685781e-02  5.1806313e+01 -5.1716606e+01  5.1827660e+01]]\n",
      "T 7\n",
      "P 7\n",
      "T [-0.21319151]\n",
      "P [[18.544247]]\n",
      "[[-5.2875607e+01 -5.2709488e+01  5.2591686e+01 -5.2781879e+01\n",
      "  -5.2618389e+01  5.1185520e+01  5.2901237e+01  5.1376728e+01\n",
      "  -5.1228378e+01 -5.2945068e+01  5.2850231e+01 -5.6568873e-01\n",
      "   5.2607960e+01  5.2776001e+01 -5.1447819e+01 -5.2546608e+01\n",
      "   5.1663197e+01  5.2901772e+01  9.8006827e-01  5.2957474e+01\n",
      "  -5.2953098e+01  5.1975929e+01  5.2586601e+01 -5.2715111e+01\n",
      "  -5.2896355e+01  5.2905685e+01  5.1260387e+01  5.1406174e+01\n",
      "   5.2975647e+01 -5.2901268e+01 -5.2688858e+01 -5.2932358e+01\n",
      "  -1.0000000e+00  5.2823341e+01 -5.1892056e+01  5.2726986e+01\n",
      "   5.2466343e+01 -5.2755959e+01  5.2323265e+01  5.1405087e+01\n",
      "  -5.2367081e+01 -1.0000000e+00  5.2310898e+01 -5.2633804e+01\n",
      "  -5.1115227e+01  5.2905209e+01 -5.2809410e+01  5.2727154e+01\n",
      "  -5.2680492e+01 -9.9957699e-01  5.2624645e+01  5.2449265e+01\n",
      "  -5.2876656e+01  5.2763172e+01  1.0000000e+00  5.2673409e+01\n",
      "   5.2847698e+01  5.1225636e+01  5.2998501e+01  5.2760139e+01\n",
      "  -5.1519081e+01 -5.1458534e+01  5.2922520e+01  5.1058723e+01\n",
      "  -5.1201340e+01 -5.2922783e+01 -5.2905815e+01  5.2908470e+01\n",
      "  -1.4126301e-05  5.2800751e+01 -5.2593922e+01 -5.2839352e+01\n",
      "   5.1318111e+01  5.1554218e+01  5.2863316e+01  5.2401161e+01\n",
      "  -5.2801620e+01  5.2823441e+01 -5.2778442e+01  5.2996662e+01\n",
      "  -1.7484522e-01  5.1782761e+01 -5.1705547e+01  1.9227958e+00\n",
      "   5.2966560e+01 -5.2766426e+01  5.2792686e+01 -5.2880981e+01\n",
      "  -2.7490316e-02  5.2988388e+01 -3.9796114e-01 -5.2354591e+01\n",
      "  -5.2604752e+01  5.2821030e+01 -5.2903156e+01  1.9629080e+00\n",
      "   8.3989537e-01  5.2806313e+01 -5.2716606e+01  5.2827625e+01]]\n",
      "T 6\n",
      "P 4\n",
      "T [-2.09273078]\n",
      "P [[-0.8701416]]\n",
      "[[-53.875607   -53.709488    53.591686   -53.78188    -53.61839\n",
      "   52.18552     53.901237    52.376728   -52.22838    -53.945065\n",
      "   53.85023     -0.484069    53.60796     53.776      -52.44782\n",
      "  -53.546608    52.663197    53.90177     -0.60647476  53.957474\n",
      "  -53.9531      52.97593     53.58659    -53.71511    -53.896355\n",
      "   53.905685    52.260387    52.406174    53.975647   -53.901268\n",
      "  -53.688858   -53.932358     0.93987596  53.82334    -52.892056\n",
      "   53.726986    53.466343   -53.75596     53.323265    52.405087\n",
      "  -53.36708      0.41490775  53.310898   -53.633804   -52.115227\n",
      "   53.90521    -53.80941     53.727154   -53.680492    -1.999577\n",
      "   53.624645    53.449265   -53.876656    53.763172    -0.99520314\n",
      "   53.6734      53.8477      52.225636    53.9985      53.76014\n",
      "  -52.51908    -52.458534    53.92252     52.058723   -52.201336\n",
      "  -53.922783   -53.905815    53.90847     -0.9886191   53.80075\n",
      "  -53.59392    -53.839348    52.31811     52.554214    53.863316\n",
      "   53.40116    -53.80162     53.82344    -53.778442    53.996662\n",
      "   -1.1747923   52.78276    -52.705547     1.7075076   53.96656\n",
      "  -53.766426    53.792686   -53.88098     -1.0195202   53.988388\n",
      "    0.9707887  -53.35459    -53.604733    53.82103    -53.903126\n",
      "    1.4228464    1.6496384   53.806313   -53.716606    53.827625  ]]\n",
      "T 3\n",
      "P 3\n",
      "T [-1.67689365]\n",
      "P [[30.92473]]\n",
      "[[-54.875607   -54.709488    54.591686   -54.78188    -54.61839\n",
      "   53.18552     54.901237    53.376728   -53.22838    -54.945065\n",
      "   54.85023     -1.0259864   54.60796     54.776      -53.44782\n",
      "  -54.546608    53.663197    54.90177     -0.7214071   54.957474\n",
      "  -54.9531      53.97593     54.586586   -54.71511    -54.896355\n",
      "   54.905685    53.260387    53.406174    54.975647   -54.901268\n",
      "  -54.688858   -54.932358    -0.06012404  54.82334    -53.892056\n",
      "   54.726986    54.466343   -54.75596     54.323265    53.405087\n",
      "  -54.367077    -1.          54.310898   -54.633804   -53.115227\n",
      "   54.90521    -54.80941     54.727154   -54.680492     0.19371492\n",
      "   54.624645    54.449265   -54.876656    54.763172     1.\n",
      "   54.6734      54.8477      53.225636    54.9985      54.76014\n",
      "  -53.51908    -53.458534    54.92252     53.058723   -53.201336\n",
      "  -54.922783   -54.905815    54.90847     -1.9886191   54.80075\n",
      "  -54.59392    -54.839348    53.31811     53.554214    54.863316\n",
      "   54.40116    -54.80162     54.82344    -54.778442    54.996662\n",
      "   -2.1747923   53.78276    -53.705547     0.35227     54.96656\n",
      "  -54.766426    54.792686   -54.88098     -0.884161    54.988388\n",
      "    0.92664325 -54.35459    -54.604733    54.82103    -54.903126\n",
      "    2.214396    -0.90410316  54.806313   -54.716606    54.82762   ]]\n",
      "T 5\n",
      "P 3\n",
      "T [-2.06076827]\n",
      "P [[-0.9010929]]\n",
      "[[-55.875603   -55.709488    55.591686   -55.78188    -55.61839\n",
      "   54.18552     55.901237    54.376724   -54.228134   -55.945065\n",
      "   55.85023     -0.37475094  55.60795     55.776      -54.44782\n",
      "  -55.546608    54.663197    55.90177     -1.          55.957474\n",
      "  -55.9531      54.97593     55.58657    -55.71511    -55.896355\n",
      "   55.905685    54.260387    54.406174    55.975647   -55.901268\n",
      "  -55.688858   -55.932358    -0.996301    55.82334    -54.892056\n",
      "   55.726986    55.466343   -55.75596     55.32326     54.405087\n",
      "  -55.367077    -0.28843236  55.310898   -55.633804   -54.115227\n",
      "   55.90521    -55.80941     55.727154   -55.680492    -0.8062851\n",
      "   55.624645    55.449265   -55.876648    55.763172    -0.9946281\n",
      "   55.673397    55.8477      54.225636    55.9985      55.76014\n",
      "  -54.518906   -54.45852     55.92252     54.058723   -54.201336\n",
      "  -55.922768   -55.905815    55.90847     -1.46137     55.80075\n",
      "  -55.59392    -55.839348    54.31811     54.554203    55.863316\n",
      "   55.401123   -55.80162     55.82344    -55.778442    55.996662\n",
      "   -0.7380266   54.78276    -54.705547     0.9999975   55.96656\n",
      "  -55.766426    55.792686   -55.88098     -1.          55.988388\n",
      "    1.3991077  -55.35459    -55.60473     55.82103    -55.903088\n",
      "    0.9828232    0.09589684  55.806313   -55.716606    55.82762   ]]\n",
      "T 12\n",
      "P 12\n",
      "T [-1.78163994]\n",
      "P [[-0.90693724]]\n",
      "[[-56.875603   -56.709488    56.591686   -56.78188    -56.61839\n",
      "   55.18552     56.901237    55.376724   -55.228134   -56.945065\n",
      "   56.85023     -0.9999998   56.60795     56.776      -55.44782\n",
      "  -56.546608    55.663193    56.90177     -0.9990935   56.957474\n",
      "  -56.9531      55.97592     56.58657    -56.71511    -56.896355\n",
      "   56.905685    55.260387    55.40617     56.975647   -56.901268\n",
      "  -56.688858   -56.932358    -1.3350139   56.82334    -55.892056\n",
      "   56.726986    56.466343   -56.75596     56.32326     55.405083\n",
      "  -56.367077    -1.          56.310898   -56.633804   -55.115227\n",
      "   56.90521    -56.80941     56.727154   -56.680492    -0.99972874\n",
      "   56.624645    56.449265   -56.876648    56.763172     1.\n",
      "   56.673397    56.8477      55.22554     56.9985      56.76014\n",
      "  -55.518906   -55.45852     56.92252     55.058723   -55.201336\n",
      "  -56.922768   -56.905815    56.90847     -1.929934    56.80075\n",
      "  -56.593918   -56.839348    55.31811     55.554203    56.863316\n",
      "   56.401123   -56.80162     56.82344    -56.778442    56.996662\n",
      "   -1.5958592   55.78276    -55.705547     1.9999948   56.96656\n",
      "  -56.766426    56.792686   -56.88098     -0.7407374   56.988388\n",
      "    0.83463037 -56.35459    -56.60473     56.82103    -56.903088\n",
      "    1.430171     0.99549115  56.806313   -56.716606    56.827618  ]]\n",
      "T 3\n",
      "P 3\n",
      "T [-0.38490665]\n",
      "P [[-0.88329065]]\n",
      "[[-57.875603   -57.709488    57.591686   -57.78188    -57.61839\n",
      "   56.18552     57.901237    56.376724   -56.228134   -57.945065\n",
      "   57.85023      0.9929696   57.60794     57.776      -56.44782\n",
      "  -57.546608    56.663193    57.90177     -1.1842496   57.957474\n",
      "  -57.9531      56.97592     57.586536   -57.71511    -57.896355\n",
      "   57.905685    56.260387    56.40617     57.975647   -57.901268\n",
      "  -57.688858   -57.932358    -0.32867208  57.82334    -56.892056\n",
      "   57.726986    57.466343   -57.75596     57.32326     56.405083\n",
      "  -57.367077    -1.3928139   57.310898   -57.633804   -56.115227\n",
      "   57.90521    -57.80941     57.727154   -57.680492    -1.3106639\n",
      "   57.624645    57.449265   -57.876648    57.763172     0.1906684\n",
      "   57.673393    57.8477      56.22554     57.9985      57.76014\n",
      "  -56.518906   -56.45852     57.92252     56.058723   -56.201336\n",
      "  -57.922768   -57.905815    57.90847     -1.2428118   57.80075\n",
      "  -57.593918   -57.839348    56.31811     56.5542      57.863316\n",
      "   57.401123   -57.80162     57.82344    -57.778442    57.996662\n",
      "   -1.5873847   56.78276    -56.705547     0.99999994  57.96656\n",
      "  -57.766426    57.792686   -57.88098     -1.1661546   57.988388\n",
      "    1.7468259  -57.35459    -57.60472     57.82103    -57.903084\n",
      "    1.5845693    1.4139857   57.806313   -57.716606    57.827618  ]]\n",
      "T 7\n",
      "P 12\n",
      "T [-1.18090302]\n",
      "P [[-0.90342414]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-58.875603   -58.709488    58.591686   -58.78188    -58.61839\n",
      "   57.18552     58.901237    57.376724   -57.228134   -58.945065\n",
      "   58.85023     -0.9999979   58.607937    58.776      -57.44782\n",
      "  -58.546608    57.663147    58.901756    -0.43974048  58.957474\n",
      "  -58.9531      57.97592     58.586536   -58.71511    -58.896355\n",
      "   58.905685    57.260387    57.40617     58.975647   -58.901268\n",
      "  -58.688858   -58.932358    -1.          58.823326   -57.892056\n",
      "   58.726986    58.466343   -58.755955    58.32326     57.405083\n",
      "  -58.367077    -1.3138965   58.310898   -58.633804   -57.115227\n",
      "   58.90521    -58.80941     58.727154   -58.68049     -1.1723241\n",
      "   58.624645    58.449265   -58.876648    58.763172     1.\n",
      "   58.673393    58.8477      57.22554     58.9985      58.76014\n",
      "  -57.518906   -57.45852     58.92252     57.058723   -57.201336\n",
      "  -58.922768   -58.905815    58.90847     -2.2428095   58.80075\n",
      "  -58.593914   -58.839348    57.31811     57.5542      58.863316\n",
      "   58.401123   -58.80162     58.82344    -58.778442    58.996662\n",
      "   -1.2851188   57.78276    -57.705547     1.8062304   58.96656\n",
      "  -58.766426    58.792686   -58.88098     -0.99986535  58.988388\n",
      "    1.5013711  -58.35459    -58.60472     58.82103    -58.903084\n",
      "    2.584569     0.8416716   58.806313   -58.716606    58.827614  ]]\n",
      "T 3\n",
      "P 3\n",
      "T [-0.33259667]\n",
      "P [[-0.86595666]]\n",
      "[[-59.875603   -59.709488    59.591686   -59.78188    -59.61839\n",
      "   58.18552     59.901237    58.376724   -58.228123   -59.945065\n",
      "   59.85023      0.83503586  59.607933    59.776      -58.44782\n",
      "  -59.546608    58.663147    59.901752    -1.1687409   59.957474\n",
      "  -59.9531      58.97592     59.58641    -59.71511    -59.896355\n",
      "   59.905685    58.260387    58.40617     59.975647   -59.901268\n",
      "  -59.688858   -59.932358    -0.79090416  59.823326   -58.892056\n",
      "   59.726986    59.466343   -59.75595     59.323254    58.405083\n",
      "  -59.367077    -1.7635832   59.310898   -59.633804   -58.115227\n",
      "   59.90521    -59.80941     59.727154   -59.68049     -1.5296535\n",
      "   59.624645    59.449265   -59.876648    59.763172     0.9609739\n",
      "   59.67339     59.8477      58.22554     59.9985      59.76014\n",
      "  -58.51889    -58.45852     59.92252     58.058723   -58.201336\n",
      "  -59.922768   -59.905815    59.90847     -2.7268436   59.80075\n",
      "  -59.593914   -59.839348    58.31811     58.554195    59.863316\n",
      "   59.401123   -59.80162     59.82344    -59.778442    59.996662\n",
      "   -1.8382246   58.78276    -58.705547     0.99999803  59.96656\n",
      "  -59.766426    59.792686   -59.88098     -1.          59.988388\n",
      "    2.501371   -59.354588   -59.604664    59.82103    -59.903065\n",
      "    2.7811263    1.4192843   59.806313   -59.716606    59.827614  ]]\n",
      "T 6\n",
      "P 12\n",
      "T [-0.93772802]\n",
      "P [[-0.874858]]\n",
      "[[-6.0875603e+01 -6.0709488e+01  6.0591686e+01 -6.0781879e+01\n",
      "  -6.0618389e+01  5.9185520e+01  6.0901237e+01  5.9376724e+01\n",
      "  -5.9228123e+01 -6.0945065e+01  6.0850231e+01 -1.0000000e+00\n",
      "   6.0607933e+01  6.0776001e+01 -5.9447819e+01 -6.0546608e+01\n",
      "   5.9663147e+01  6.0901752e+01  4.0372640e-02  6.0957474e+01\n",
      "  -6.0953098e+01  5.9975922e+01  6.0586411e+01 -6.0715111e+01\n",
      "  -6.0896355e+01  6.0905685e+01  5.9260387e+01  5.9406170e+01\n",
      "   6.0975647e+01 -6.0901268e+01 -6.0688858e+01 -6.0932358e+01\n",
      "  -1.4496406e+00  6.0823326e+01 -5.9892056e+01  6.0726986e+01\n",
      "   6.0466343e+01 -6.0755951e+01  6.0323254e+01  5.9405083e+01\n",
      "  -6.0367077e+01 -1.7435920e+00  6.0310898e+01 -6.0633804e+01\n",
      "  -5.9115227e+01  6.0905209e+01 -6.0809410e+01  6.0727154e+01\n",
      "  -6.0680489e+01 -9.9204344e-01  6.0624645e+01  6.0449265e+01\n",
      "  -6.0876648e+01  6.0763172e+01  9.9844903e-01  6.0673389e+01\n",
      "   6.0847698e+01  5.9225540e+01  6.0998501e+01  6.0760139e+01\n",
      "  -5.9518890e+01 -5.9458519e+01  6.0922520e+01  5.9058723e+01\n",
      "  -5.9201336e+01 -6.0922768e+01 -6.0905815e+01  6.0908470e+01\n",
      "  -3.7268436e+00  6.0800751e+01 -6.0593914e+01 -6.0839348e+01\n",
      "   5.9318111e+01  5.9554195e+01  6.0863316e+01  6.0401123e+01\n",
      "  -6.0801620e+01  6.0823441e+01 -6.0778442e+01  6.0996662e+01\n",
      "  -1.6802446e+00  5.9782761e+01 -5.9705547e+01  5.9994727e-01\n",
      "   6.0966560e+01 -6.0766426e+01  6.0792686e+01 -6.0880981e+01\n",
      "  -9.2698032e-01  6.0988388e+01 -9.1723418e-01 -6.0354588e+01\n",
      "  -6.0604664e+01  6.0821030e+01 -6.0903065e+01  2.8874104e+00\n",
      "   9.5626771e-01  6.0806313e+01 -6.0716606e+01  6.0827614e+01]]\n",
      "T 7\n",
      "P 14\n",
      "T [-0.60143798]\n",
      "P [[-0.9630133]]\n",
      "[[-61.875603   -61.709488    61.591686   -61.78188    -61.61839\n",
      "   60.18552     61.901237    60.376724   -60.228123   -61.94506\n",
      "   61.85023      0.99529517  61.607872    61.776      -60.44782\n",
      "  -61.546608    60.663124    61.90175     -0.9902243   61.957474\n",
      "  -61.9531      60.97592     61.58625    -61.715107   -61.896355\n",
      "   61.905685    60.260387    60.40617     61.975647   -61.901268\n",
      "  -61.688858   -61.932358    -0.45609006  61.82329    -60.892056\n",
      "   61.726986    61.466335   -61.755943    61.32325     60.405083\n",
      "  -61.367077    -2.1637506   61.310898   -61.633804   -60.115227\n",
      "   61.90521    -61.80941     61.727154   -61.680485    -1.9920435\n",
      "   61.624645    61.449265   -61.876644    61.763172     0.11165645\n",
      "   61.673378    61.847694    60.22554     61.9985      61.76014\n",
      "  -60.518887   -60.45851     61.92252     60.058723   -60.201336\n",
      "  -61.922768   -61.905815    61.90847      0.9943106   61.80075\n",
      "  -61.593914   -61.8388      60.31811     60.554184    61.863316\n",
      "   61.401123   -61.80162     61.82344    -61.778442    61.996662\n",
      "   -1.6315725   60.78276    -60.705547     1.3884238   61.96656\n",
      "  -61.766426    61.792686   -61.88098     -1.          61.988388\n",
      "    0.34174836 -61.354588   -61.60465     61.821026   -61.903065\n",
      "    1.8129916    1.3411162   61.806313   -61.716606    61.827602  ]]\n",
      "T 9\n",
      "P 3\n",
      "T [0.28373422]\n",
      "P [[-13.343292]]\n",
      "[[-6.2875603e+01 -6.2709488e+01  6.2591686e+01 -6.2781879e+01\n",
      "  -6.2618389e+01  6.1185520e+01  6.2901237e+01  6.1376717e+01\n",
      "  -6.1228123e+01 -6.2945061e+01  6.2850231e+01 -1.0000000e+00\n",
      "   6.2607872e+01  6.2776001e+01 -6.1447819e+01 -6.2546608e+01\n",
      "   6.1663120e+01  6.2901493e+01  7.4095035e-01  6.2957474e+01\n",
      "  -6.2953098e+01  6.1975922e+01  6.2586243e+01 -6.2715107e+01\n",
      "  -6.2896355e+01  6.2905685e+01  6.1260387e+01  6.1406170e+01\n",
      "   6.2975647e+01 -6.2901268e+01 -6.2688858e+01 -6.2932358e+01\n",
      "  -1.0368495e+00  6.2823292e+01 -6.1892056e+01  6.2726986e+01\n",
      "   6.2466335e+01 -6.2755917e+01  6.2323250e+01  6.1405083e+01\n",
      "  -6.2367077e+01 -2.0961003e+00  6.2310898e+01 -6.2633804e+01\n",
      "  -6.1115150e+01  6.2905209e+01 -6.2809410e+01  6.2727154e+01\n",
      "  -6.2680485e+01 -2.5854537e-01  6.2624645e+01  6.2449265e+01\n",
      "  -6.2876640e+01  6.2763172e+01  1.0000000e+00  6.2673378e+01\n",
      "   6.2847694e+01  6.1225540e+01  6.2998501e+01  6.2760139e+01\n",
      "  -6.1518879e+01 -6.1458511e+01  6.2922520e+01  6.1058723e+01\n",
      "  -6.1201336e+01 -6.2922768e+01 -6.2905815e+01  6.2908470e+01\n",
      "  -5.6893826e-03  6.2800751e+01 -6.2593914e+01 -6.2838799e+01\n",
      "   6.1318111e+01  6.1554184e+01  6.2863316e+01  6.2401123e+01\n",
      "  -6.2801620e+01  6.2823437e+01 -6.2778442e+01  6.2996662e+01\n",
      "  -1.9962913e+00  6.1782761e+01 -6.1705547e+01 -4.7881281e-01\n",
      "   6.2966560e+01 -6.2766426e+01  6.2792686e+01 -6.2880981e+01\n",
      "  -8.2171327e-01  6.2988388e+01 -9.4003814e-01 -6.2354588e+01\n",
      "  -6.2604645e+01  6.2821026e+01 -6.2903061e+01  2.3821805e+00\n",
      "   9.0843616e-03  6.2806313e+01 -6.2716606e+01  6.2827560e+01]]\n",
      "T 14\n",
      "P 4\n",
      "T [-68.58160795]\n",
      "P [[-69.922386]]\n",
      "[[-63.87558    -63.709488    63.591686   -63.78188    -63.61839\n",
      "   62.18552     63.901237    62.376717   -62.22812    -63.945057\n",
      "   63.85023      0.9976108   63.607773    63.776      -62.44782\n",
      "  -63.546608    62.66308     63.901493    -0.49878693  63.957474\n",
      "  -63.9531      62.97592     63.586098   -63.715084   -63.896355\n",
      "   63.905685    62.260387    62.40617     63.975647   -63.901268\n",
      "  -63.688858   -63.932358     0.17105463  63.823284   -62.892056\n",
      "   63.726982    63.466267   -63.75589     63.323185    62.405083\n",
      "  -63.367077     0.51110065  63.30169    -63.633804   -62.11515\n",
      "   63.90521    -63.80941     63.727154   -63.68048     -1.2262319\n",
      "   63.624645    63.449265   -63.87662     63.763172    -0.6158221\n",
      "   63.673374    63.84769     62.22554     63.9985      63.76014\n",
      "  -62.518875   -62.45851     63.92252     62.058723   -62.201336\n",
      "  -63.922768   -63.905815    63.90847      0.99105924  63.80075\n",
      "  -63.593914   -63.83362     62.31811     62.55417     63.863316\n",
      "   63.401123   -63.80162     63.823433   -63.778442    63.996662\n",
      "   -0.42753136  62.78276    -62.705547     0.63486636  63.96656\n",
      "  -63.766426    63.792686   -63.88098     -1.          63.988388\n",
      "    0.25015402 -63.354588   -63.60456     63.82101    -63.903053\n",
      "    1.1377233    1.0060713   63.806313   -63.716606    63.827557  ]]\n",
      "T 4\n",
      "P 4\n",
      "T [-0.03132631]\n",
      "P [[-0.82591426]]\n",
      "[[-6.4875580e+01 -6.4709488e+01  6.4591690e+01 -6.4781876e+01\n",
      "  -6.4618393e+01  6.3185520e+01  6.4901237e+01  6.3376717e+01\n",
      "  -6.3228119e+01 -6.4945053e+01  6.4850235e+01 -1.0000000e+00\n",
      "   6.4607773e+01  6.4776001e+01 -6.3447819e+01 -6.4546608e+01\n",
      "   6.3663078e+01  6.4901489e+01  9.9996477e-01  6.4957474e+01\n",
      "  -6.4953094e+01  6.3975922e+01  6.4586098e+01 -6.4715088e+01\n",
      "  -6.4896355e+01  6.4905685e+01  6.3260387e+01  6.3406170e+01\n",
      "   6.4975647e+01 -6.4901268e+01 -6.4688858e+01 -6.4932358e+01\n",
      "  -9.2714733e-01  6.4823288e+01 -6.3892056e+01  6.4726982e+01\n",
      "   6.4466263e+01 -6.4755890e+01  6.4323181e+01  6.3405083e+01\n",
      "  -6.4367073e+01 -1.0000000e+00  6.4301689e+01 -6.4633804e+01\n",
      "  -6.3115147e+01  6.4905212e+01 -6.4809410e+01  6.4727158e+01\n",
      "  -6.4680481e+01 -7.9249895e-01  6.4624649e+01  6.4449265e+01\n",
      "  -6.4876617e+01  6.4763168e+01  1.0000000e+00  6.4673370e+01\n",
      "   6.4847687e+01  6.3225540e+01  6.4998505e+01  6.4760139e+01\n",
      "  -6.3518875e+01 -6.3458511e+01  6.4922516e+01  6.3058723e+01\n",
      "  -6.3201336e+01 -6.4922768e+01 -6.4905815e+01  6.4908470e+01\n",
      "  -8.9407563e-03  6.4800751e+01 -6.4593910e+01 -6.4833618e+01\n",
      "   6.3318111e+01  6.3554169e+01  6.4863312e+01  6.4401123e+01\n",
      "  -6.4801620e+01  6.4823433e+01 -6.4778442e+01  6.4996658e+01\n",
      "  -1.4263082e+00  6.3782761e+01 -6.3705547e+01 -2.6006830e-01\n",
      "   6.4966560e+01 -6.4766426e+01  6.4792686e+01 -6.4880981e+01\n",
      "   3.9055353e-01  6.4988388e+01 -8.0853558e-01 -6.4354584e+01\n",
      "  -6.4604561e+01  6.4821014e+01 -6.4903053e+01  2.1377234e+00\n",
      "  -7.3415595e-01  6.4806313e+01 -6.4716606e+01  6.4827545e+01]]\n",
      "T 9\n",
      "P 11\n",
      "T [-0.06228149]\n",
      "P [[0.30149066]]\n",
      "[[-6.5875504e+01 -6.5709488e+01  6.5591690e+01 -6.5781174e+01\n",
      "  -6.5618393e+01  6.4185516e+01  6.5901237e+01  6.4376717e+01\n",
      "  -6.4228119e+01 -6.5945038e+01  6.5850235e+01  9.9999774e-01\n",
      "   6.5607765e+01  6.5776001e+01 -6.4447815e+01 -6.5546608e+01\n",
      "   6.4663078e+01  6.5901489e+01 -3.5226345e-05  6.5957474e+01\n",
      "  -6.5953094e+01  6.4975922e+01  6.5586014e+01 -6.5715088e+01\n",
      "  -6.5896355e+01  6.5905685e+01  6.4260391e+01  6.4406174e+01\n",
      "   6.5975647e+01 -6.5901268e+01 -6.5688858e+01 -6.5932358e+01\n",
      "   1.8229339e-01  6.5823288e+01 -6.4892052e+01  6.5726982e+01\n",
      "   6.5466263e+01 -6.5755890e+01  6.5323174e+01  6.4405083e+01\n",
      "  -6.5367073e+01 -1.3702897e+00  6.5301689e+01 -6.5633804e+01\n",
      "  -6.4115143e+01  6.5905212e+01 -6.5809410e+01  6.5727158e+01\n",
      "  -6.5680481e+01 -1.7924989e+00  6.5624588e+01  6.5449265e+01\n",
      "  -6.5876610e+01  6.5763168e+01  3.6134425e-01  6.5673370e+01\n",
      "   6.5847687e+01  6.4225540e+01  6.5998505e+01  6.5760139e+01\n",
      "  -6.4518852e+01 -6.4458420e+01  6.5922516e+01  6.4058723e+01\n",
      "  -6.4201340e+01 -6.5922768e+01 -6.5905815e+01  6.5908470e+01\n",
      "   9.8115098e-01  6.5800751e+01 -6.5593910e+01 -6.5833618e+01\n",
      "   6.4318115e+01  6.4554161e+01  6.5863312e+01  6.5401108e+01\n",
      "  -6.5801620e+01  6.5823433e+01 -6.5778442e+01  6.5996658e+01\n",
      "  -3.6636335e-01  6.4782761e+01 -6.4705551e+01  1.0000000e+00\n",
      "   6.5966560e+01 -6.5766426e+01  6.5792686e+01 -6.5880981e+01\n",
      "  -9.2950165e-01  6.5988388e+01  2.2914606e-01 -6.5354584e+01\n",
      "  -6.5604515e+01  6.5821014e+01 -6.5902878e+01  4.2299807e-02\n",
      "   2.6584405e-01  6.5806313e+01 -6.5716606e+01  6.5827545e+01]]\n",
      "T 12\n",
      "P 12\n",
      "T [-70.73160293]\n",
      "P [[-69.83006]]\n",
      "[[-6.6875504e+01 -6.6709488e+01  6.6591690e+01 -6.6781174e+01\n",
      "  -6.6618393e+01  6.5185516e+01  6.6901237e+01  6.5376717e+01\n",
      "  -6.5228119e+01 -6.6945038e+01  6.6850235e+01 -9.6543533e-01\n",
      "   6.6607765e+01  6.6776001e+01 -6.5447815e+01 -6.6546608e+01\n",
      "   6.5663040e+01  6.6901466e+01 -3.7335005e-01  6.6957474e+01\n",
      "  -6.6953094e+01  6.5975922e+01  6.6586014e+01 -6.6715088e+01\n",
      "  -6.6896355e+01  6.6905685e+01  6.5260391e+01  6.5406174e+01\n",
      "   6.6975647e+01 -6.6901268e+01 -6.6688858e+01 -6.6932358e+01\n",
      "  -1.0000000e+00  6.6823288e+01 -6.5892052e+01  6.6726982e+01\n",
      "   6.6466263e+01 -6.6755890e+01  6.6323174e+01  6.5405075e+01\n",
      "  -6.6367073e+01 -1.0000000e+00  6.6301689e+01 -6.6633804e+01\n",
      "  -6.5115143e+01  6.6905212e+01 -6.6809410e+01  6.6727158e+01\n",
      "  -6.6680481e+01 -9.0561473e-01  6.6624588e+01  6.6449265e+01\n",
      "  -6.6876610e+01  6.6763168e+01  1.0000000e+00  6.6673370e+01\n",
      "   6.6847687e+01  6.5225540e+01  6.6998505e+01  6.6760139e+01\n",
      "  -6.5518852e+01 -6.5458420e+01  6.6922516e+01  6.5058723e+01\n",
      "  -6.5201340e+01 -6.6922768e+01 -6.6905815e+01  6.6908470e+01\n",
      "  -1.8849015e-02  6.6800751e+01 -6.6593895e+01 -6.6833618e+01\n",
      "   6.5318115e+01  6.5554161e+01  6.6863312e+01  6.6401108e+01\n",
      "  -6.6801620e+01  6.6823433e+01 -6.6778442e+01  6.6996658e+01\n",
      "  -1.3663633e+00  6.5782761e+01 -6.5705551e+01  1.2151864e+00\n",
      "   6.6966560e+01 -6.6766426e+01  6.6792686e+01 -6.6880981e+01\n",
      "  -4.8334104e-01  6.6988388e+01  7.4436164e-01 -6.6354584e+01\n",
      "  -6.6604515e+01  6.6821014e+01 -6.6902878e+01  1.0422997e+00\n",
      "   1.9108053e-01  6.6806313e+01 -6.6716606e+01  6.6827530e+01]]\n",
      "T 2\n",
      "P 10\n",
      "T [-1.68392849]\n",
      "P [[-0.8743681]]\n",
      "[[-67.8755     -67.70949     67.59169    -67.78117    -67.61839\n",
      "   66.18552     67.90124     66.37672    -66.22811    -67.94504\n",
      "   67.850235     0.8571459   67.607765    67.776      -66.447815\n",
      "  -67.54661     66.66304     67.90147     -1.          67.95747\n",
      "  -67.953094    66.97592     67.58598    -67.71508    -67.896355\n",
      "   67.905685    66.26039     66.40617     67.97565    -67.90127\n",
      "  -67.68886    -67.93236      0.17809178  67.82329    -66.89205\n",
      "   67.72698     67.46626    -67.75588     67.32315     66.405075\n",
      "  -67.36707      0.83506894  67.30169    -67.633804   -66.11514\n",
      "   67.90521    -67.80941     67.72716    -67.68048     -1.6145033\n",
      "   67.62459     67.449265   -67.87661     67.76317     -0.41854337\n",
      "   67.67336     67.84769     66.22554     67.998505    67.76014\n",
      "  -66.51885    -66.45842     67.922516    66.05872    -66.20133\n",
      "  -67.92277    -67.905815    67.90847     -0.70173305  67.80075\n",
      "  -67.593895   -67.83361     66.318115    66.55415     67.86331\n",
      "   67.40111    -67.80162     67.82343    -67.77844     67.99666\n",
      "   -1.2366282   66.78276    -66.70555      1.          67.96656\n",
      "  -67.766426    67.79269    -67.88098     -1.          67.98839\n",
      "    1.4890465  -67.35458    -67.60448     67.821014   -67.90288\n",
      "    1.4069737    1.1904209   67.80631    -67.716606    67.82753   ]]\n",
      "T 3\n",
      "P 13\n",
      "T [0.65825721]\n",
      "P [[-0.9369165]]\n",
      "[[-68.8755     -68.70949     68.59169    -68.78117    -68.61839\n",
      "   67.18552     68.90124     67.37672    -67.22811    -68.94504\n",
      "   68.850235    -1.          68.607765    68.776      -67.447815\n",
      "  -68.54661     67.66304     68.90147     -0.7843283   68.95747\n",
      "  -68.953094    67.97592     68.58598    -68.71508    -68.896355\n",
      "   68.905685    67.26039     67.40617     68.97565    -68.90127\n",
      "  -68.68886    -68.93236     -0.8219081   68.82329    -67.89205\n",
      "   68.72698     68.46626    -68.75588     68.32315     67.405075\n",
      "  -68.36707     -1.          68.30169    -68.633804   -67.11514\n",
      "   68.90521    -68.80941     68.72716    -68.68048     -0.17974663\n",
      "   68.62459     68.449265   -68.87661     68.76317      1.\n",
      "   68.67336     68.84769     67.22554     68.998505    68.76014\n",
      "  -67.51885    -67.45842     68.922516    67.05872    -67.20133\n",
      "  -68.92277    -68.905815    68.90847     -1.7017331   68.80075\n",
      "  -68.593895   -68.83361     67.318115    67.55415     68.86331\n",
      "   68.40111    -68.80162     68.82343    -68.77844     68.99666\n",
      "   -1.4125167   67.78276    -67.70555      1.0105151   68.96656\n",
      "  -68.766426    68.79269    -68.88098     -0.78213876  68.98839\n",
      "    0.94527394 -68.35458    -68.60448     68.821014   -68.90288\n",
      "    2.0524936   -0.555058    68.80631    -68.716606    68.82753   ]]\n",
      "T 7\n",
      "P 3\n",
      "T [0.19104078]\n",
      "P [[-0.8803972]]\n",
      "[[-6.9875496e+01 -6.9709488e+01  6.9591690e+01 -6.9781174e+01\n",
      "  -6.9618393e+01  6.8185516e+01  6.9901237e+01  6.8376717e+01\n",
      "  -6.8228111e+01 -6.9945038e+01  6.9850235e+01  9.5660162e-01\n",
      "   6.9607758e+01  6.9776001e+01 -6.8447815e+01 -6.9546608e+01\n",
      "   6.8663040e+01  6.9901466e+01 -1.0103987e+00  6.9957474e+01\n",
      "  -6.9953094e+01  6.8975922e+01  6.9585976e+01 -6.9715080e+01\n",
      "  -6.9896355e+01  6.9905685e+01  6.8260391e+01  6.8406174e+01\n",
      "   6.9975647e+01 -6.9901268e+01 -6.9688858e+01 -6.9932358e+01\n",
      "  -5.0507911e-02  6.9823288e+01 -6.8892052e+01  6.9726982e+01\n",
      "   6.9466263e+01 -6.9755882e+01  6.9323151e+01  6.8405075e+01\n",
      "  -6.9367073e+01  3.3642012e-01  6.9301689e+01 -6.9633804e+01\n",
      "  -6.8115143e+01  6.9905212e+01 -6.9809410e+01  6.9727158e+01\n",
      "  -6.9680481e+01 -1.1750628e+00  6.9624588e+01  6.9449265e+01\n",
      "  -6.9876610e+01  6.9763168e+01 -2.3213993e-01  6.9673363e+01\n",
      "   6.9847687e+01  6.8225540e+01  6.9998505e+01  6.9760139e+01\n",
      "  -6.8518852e+01 -6.8458397e+01  6.9922516e+01  6.8058723e+01\n",
      "  -6.8201332e+01 -6.9922768e+01 -6.9905815e+01  6.9908470e+01\n",
      "   6.5141726e-01  6.9800751e+01 -6.9593895e+01 -6.9833603e+01\n",
      "   6.8318115e+01  6.8554153e+01  6.9863312e+01  6.9401108e+01\n",
      "  -6.9801620e+01  6.9823433e+01 -6.9778442e+01  6.9996658e+01\n",
      "   1.3617346e-01  6.8782761e+01 -6.8705551e+01  1.1517552e+00\n",
      "   6.9966560e+01 -6.9766426e+01  6.9792686e+01 -6.9880981e+01\n",
      "  -1.0000000e+00  6.9988388e+01  1.5055153e+00 -6.9354584e+01\n",
      "  -6.9604477e+01  6.9821014e+01 -6.9902878e+01  1.9785192e+00\n",
      "   4.4488168e-01  6.9806313e+01 -6.9716606e+01  6.9827530e+01]]\n",
      "T 4\n",
      "P 12\n",
      "T [-1.24223839]\n",
      "P [[-1.494994]]\n",
      "[[-7.0875496e+01 -7.0709488e+01  7.0591690e+01 -7.0781174e+01\n",
      "  -7.0618393e+01  6.9185516e+01  7.0901237e+01  6.9376701e+01\n",
      "  -6.9228111e+01 -7.0945038e+01  7.0850235e+01 -1.0000000e+00\n",
      "   7.0607758e+01  7.0776001e+01 -6.9447815e+01 -7.0546608e+01\n",
      "   6.9663040e+01  7.0901466e+01  9.9510419e-01  7.0957474e+01\n",
      "  -7.0953094e+01  6.9975922e+01  7.0585976e+01 -7.0715080e+01\n",
      "  -7.0896355e+01  7.0905685e+01  6.9260391e+01  6.9406174e+01\n",
      "   7.0975647e+01 -7.0901268e+01 -7.0688858e+01 -7.0932358e+01\n",
      "  -1.0283009e+00  7.0823288e+01 -6.9892052e+01  7.0726982e+01\n",
      "   7.0466263e+01 -7.0755882e+01  7.0323151e+01  6.9405075e+01\n",
      "  -7.0367073e+01 -9.8229623e-01  7.0301689e+01 -7.0633804e+01\n",
      "  -6.9115120e+01  7.0905212e+01 -7.0809410e+01  7.0727158e+01\n",
      "  -7.0680481e+01 -8.4460241e-01  7.0624588e+01  7.0449265e+01\n",
      "  -7.0876610e+01  7.0763168e+01  1.0000000e+00  7.0673363e+01\n",
      "   7.0847687e+01  6.9225540e+01  7.0998505e+01  7.0760139e+01\n",
      "  -6.9518852e+01 -6.9458397e+01  7.0922516e+01  6.9058723e+01\n",
      "  -6.9201332e+01 -7.0922768e+01 -7.0905815e+01  7.0908470e+01\n",
      "  -3.4858274e-01  7.0800751e+01 -7.0593895e+01 -7.0833603e+01\n",
      "   6.9318115e+01  6.9554153e+01  7.0863312e+01  7.0401108e+01\n",
      "  -7.0801620e+01  7.0823433e+01 -7.0778442e+01  7.0996658e+01\n",
      "  -8.6382651e-01  6.9782761e+01 -6.9705551e+01 -2.9456007e-01\n",
      "   7.0966560e+01 -7.0766426e+01  7.0792686e+01 -7.0880981e+01\n",
      "   4.9604636e-02  7.0988388e+01 -8.5481513e-01 -7.0354584e+01\n",
      "  -7.0604477e+01  7.0821014e+01 -7.0902878e+01  2.6561036e+00\n",
      "   1.1324780e+00  7.0806313e+01 -7.0716606e+01  7.0827515e+01]]\n",
      "T 14\n",
      "P 14\n",
      "T [-1.20409116]\n",
      "P [[-0.94223845]]\n",
      "[[-71.875465   -71.70949     71.59169    -71.78117    -71.61839\n",
      "   70.18552     71.90124     70.3767     -70.22811    -71.94504\n",
      "   71.850235    -0.94179803  71.60775     71.776      -70.447815\n",
      "  -71.54661     70.66302     71.90147     -0.9590736   71.95747\n",
      "  -71.953094    70.97592     71.58585    -71.71507    -71.896355\n",
      "   71.905685    70.26039     70.40617     71.97565    -71.90127\n",
      "  -71.68886    -71.93236     -1.3010722   71.82329    -70.89205\n",
      "   71.726974    71.46622    -71.755875    71.32311     70.405075\n",
      "  -71.36707      0.613685    71.30169    -71.633804   -70.11512\n",
      "   71.90521    -71.80941     71.72716    -71.68048     -1.7571809\n",
      "   71.62459     71.449265   -71.87655     71.76317     -0.1894609\n",
      "   71.673355    71.84769     70.22554     71.998505    71.76014\n",
      "  -70.518845   -70.4584      71.922516    70.05872    -70.20133\n",
      "  -71.92277    -71.905815    71.90847      0.98049027  71.80075\n",
      "  -71.593895   -71.833374    70.318115    70.55415     71.86331\n",
      "   71.40111    -71.80162     71.82343    -71.77844     71.99666\n",
      "    0.17563093  70.782745   -70.70555      0.75202847  71.96656\n",
      "  -71.766426    71.79269    -71.88098     -1.          71.98839\n",
      "    0.90779674 -71.354576   -71.60442     71.82101    -71.90287\n",
      "    1.583284     2.0082242   71.80631    -71.716606    71.827515  ]]\n",
      "T 13\n",
      "P 13\n",
      "T [-1.05398216]\n",
      "P [[-1.066044]]\n",
      "[[-7.2875465e+01 -7.2709488e+01  7.2591690e+01 -7.2781174e+01\n",
      "  -7.2618393e+01  7.1185516e+01  7.2901237e+01  7.1376701e+01\n",
      "  -7.1228111e+01 -7.2945038e+01  7.2850235e+01 -1.0000000e+00\n",
      "   7.2607750e+01  7.2776001e+01 -7.1447815e+01 -7.2546608e+01\n",
      "   7.1663017e+01  7.2901428e+01  9.4823229e-01  7.2957474e+01\n",
      "  -7.2953094e+01  7.1975922e+01  7.2585854e+01 -7.2715073e+01\n",
      "  -7.2896355e+01  7.2905685e+01  7.1260391e+01  7.1406174e+01\n",
      "   7.2975647e+01 -7.2901268e+01 -7.2688858e+01 -7.2932358e+01\n",
      "  -1.5266469e+00  7.2823288e+01 -7.1892052e+01  7.2726974e+01\n",
      "   7.2466217e+01 -7.2755875e+01  7.2323112e+01  7.1405060e+01\n",
      "  -7.2367073e+01 -9.1650188e-01  7.2301689e+01 -7.2633804e+01\n",
      "  -7.1115120e+01  7.2905212e+01 -7.2809410e+01  7.2727158e+01\n",
      "  -7.2680481e+01 -4.1597453e-01  7.2624588e+01  7.2449265e+01\n",
      "  -7.2876549e+01  7.2763168e+01  1.0000000e+00  7.2673355e+01\n",
      "   7.2847687e+01  7.1225540e+01  7.2998505e+01  7.2760139e+01\n",
      "  -7.1518845e+01 -7.1458397e+01  7.2922516e+01  7.1058723e+01\n",
      "  -7.1201332e+01 -7.2922768e+01 -7.2905815e+01  7.2908470e+01\n",
      "  -1.9509733e-02  7.2800751e+01 -7.2593895e+01 -7.2833374e+01\n",
      "   7.1318115e+01  7.1554146e+01  7.2863312e+01  7.2401108e+01\n",
      "  -7.2801620e+01  7.2823433e+01 -7.2778442e+01  7.2996658e+01\n",
      "  -8.2436907e-01  7.1782745e+01 -7.1705551e+01 -3.7183863e-01\n",
      "   7.2966560e+01 -7.2766426e+01  7.2792686e+01 -7.2880981e+01\n",
      "  -6.5572059e-01  7.2988388e+01  1.0823992e+00 -7.2354576e+01\n",
      "  -7.2604424e+01  7.2821007e+01 -7.2902870e+01  2.2156138e+00\n",
      "   1.1714238e+00  7.2806313e+01 -7.2716606e+01  7.2827507e+01]]\n",
      "T 1\n",
      "P 1\n",
      "T [-2.88906585]\n",
      "P [[-7.944203]]\n",
      "[[-73.875465   -73.70949     73.59169    -73.78117    -73.61839\n",
      "   72.18552     73.90124     72.3767     -72.22811    -73.945\n",
      "   73.850235     0.9835896   73.60774     73.776      -72.447815\n",
      "  -73.54661     72.66302     73.90143     -1.          73.95747\n",
      "  -73.953094    72.97592     73.585846   -73.715065   -73.896355\n",
      "   73.905685    72.26039     72.40617     73.97565    -73.90127\n",
      "  -73.68886    -73.93236      0.7755419   73.82329    -72.89205\n",
      "   73.72697     73.4662     -73.75586     73.32311     72.40506\n",
      "  -73.36707      0.75390697  73.30169    -73.633804   -72.11512\n",
      "   73.90521    -73.80941     73.72716    -73.68048     -1.281832\n",
      "   73.62459     73.449265   -73.87651     73.76317     -0.9975185\n",
      "   73.67335     73.84769     72.22554     73.998505    73.76014\n",
      "  -72.518845   -72.4584      73.922516    72.05872    -72.20133\n",
      "  -73.92277    -73.905815    73.90847     -1.0091729   73.80075\n",
      "  -73.593895   -73.83335     72.318115    72.55414     73.86331\n",
      "   73.40109    -73.80162     73.823425   -73.77844     73.99666\n",
      "   -1.5217646   72.782745   -72.70555      0.7697629   73.96656\n",
      "  -73.766426    73.79269    -73.88098     -1.1725466   73.98839\n",
      "    1.5302439  -73.354576   -73.60439     73.821      -73.90283\n",
      "    1.7658873    2.1119921   73.80631    -73.716606    73.82751   ]]\n",
      "T 12\n",
      "P 12\n",
      "T [-1.71244015]\n",
      "P [[-1.1100513]]\n",
      "[[-74.875465   -74.70949     74.59169    -74.78117    -74.61839\n",
      "   73.18552     74.90124     73.3767     -73.22811    -74.945\n",
      "   74.850235    -1.          74.60774     74.776      -73.44781\n",
      "  -74.54661     73.66301     74.90143      0.9847112   74.95747\n",
      "  -74.953094    73.97592     74.585846   -74.715065   -74.896355\n",
      "   74.905685    73.26039     73.4061      74.97565    -74.90127\n",
      "  -74.68886    -74.93236     -0.54938877  74.82329    -73.89205\n",
      "   74.72697     74.4662     -74.75586     74.32311     73.40506\n",
      "  -74.36707     -1.          74.30169    -74.633804   -73.11512\n",
      "   74.90521    -74.80941     74.72716    -74.68048     -0.9390994\n",
      "   74.62459     74.449265   -74.87651     74.76317      0.9637744\n",
      "   74.67335     74.84769     73.22551     74.998505    74.76014\n",
      "  -73.518845   -73.4584      74.922516    73.05872    -73.20133\n",
      "  -74.92277    -74.905815    74.90847     -2.009173    74.80075\n",
      "  -74.593895   -74.83335     73.318115    73.55414     74.86331\n",
      "   74.40109    -74.80162     74.823425   -74.77844     74.99666\n",
      "   -1.6680995   73.782745   -73.70555      1.766109    74.96656\n",
      "  -74.766426    74.79269    -74.88098      0.8694225   74.98839\n",
      "   -0.8819221  -74.354576   -74.60439     74.821      -74.90283\n",
      "    2.3363724   -0.91179025  74.80631    -74.716606    74.8275    ]]\n",
      "T 4\n",
      "P 3\n",
      "T [0.53182731]\n",
      "P [[-0.8893534]]\n",
      "[[-7.5875458e+01 -7.5709488e+01  7.5591690e+01 -7.5780937e+01\n",
      "  -7.5618393e+01  7.4185516e+01  7.5901237e+01  7.4376701e+01\n",
      "  -7.4228111e+01 -7.5945000e+01  7.5850235e+01  9.9996942e-01\n",
      "   7.5607727e+01  7.5776001e+01 -7.4447807e+01 -7.5546608e+01\n",
      "   7.4663010e+01  7.5901428e+01 -4.3445420e-01  7.5957474e+01\n",
      "  -7.5953094e+01  7.4975922e+01  7.5585800e+01 -7.5715065e+01\n",
      "  -7.5896355e+01  7.5905685e+01  7.4260391e+01  7.4406097e+01\n",
      "   7.5975647e+01 -7.5901268e+01 -7.5688858e+01 -7.5932358e+01\n",
      "   9.7012627e-01  7.5823288e+01 -7.4892052e+01  7.5726967e+01\n",
      "   7.5466202e+01 -7.5755859e+01  7.5323112e+01  7.4405060e+01\n",
      "  -7.5367073e+01  6.2260404e-02  7.5301689e+01 -7.5633804e+01\n",
      "  -7.4115120e+01  7.5905212e+01 -7.5809410e+01  7.5727158e+01\n",
      "  -7.5680481e+01 -1.9390993e+00  7.5624557e+01  7.5449265e+01\n",
      "  -7.5876511e+01  7.5763168e+01 -9.6290386e-01  7.5673347e+01\n",
      "   7.5847687e+01  7.4225510e+01  7.5998505e+01  7.5760139e+01\n",
      "  -7.4518845e+01 -7.4458351e+01  7.5922516e+01  7.4058723e+01\n",
      "  -7.4201332e+01 -7.5922768e+01 -7.5905815e+01  7.5908470e+01\n",
      "   9.9795461e-01  7.5800751e+01 -7.5593895e+01 -7.5833344e+01\n",
      "   7.4318115e+01  7.4554131e+01  7.5863312e+01  7.5401093e+01\n",
      "  -7.5801620e+01  7.5823425e+01 -7.5778442e+01  7.5996658e+01\n",
      "   3.9938635e-01  7.4782745e+01 -7.4705551e+01  1.0000000e+00\n",
      "   7.5966560e+01 -7.5766426e+01  7.5792686e+01 -7.5880981e+01\n",
      "  -4.7849905e-01  7.5988388e+01  3.0234742e-01 -7.5354576e+01\n",
      "  -7.5604385e+01  7.5820999e+01 -7.5902817e+01  5.7838738e-02\n",
      "   8.8209748e-02  7.5806313e+01 -7.5716606e+01  7.5827499e+01]]\n",
      "T 5\n",
      "P 4\n",
      "T [-0.69034083]\n",
      "P [[-0.88926613]]\n",
      "[[-7.6875458e+01 -7.6709488e+01  7.6591690e+01 -7.6780937e+01\n",
      "  -7.6618393e+01  7.5185516e+01  7.6901237e+01  7.5376610e+01\n",
      "  -7.5228104e+01 -7.6945000e+01  7.6850235e+01 -1.0000000e+00\n",
      "   7.6607727e+01  7.6776001e+01 -7.5447807e+01 -7.6546608e+01\n",
      "   7.5663010e+01  7.6901428e+01  9.9955422e-01  7.6957474e+01\n",
      "  -7.6953094e+01  7.5975922e+01  7.6585800e+01 -7.6715065e+01\n",
      "  -7.6896355e+01  7.6905685e+01  7.5260391e+01  7.5406097e+01\n",
      "   7.6975647e+01 -7.6901268e+01 -7.6688858e+01 -7.6932358e+01\n",
      "  -6.8410873e-01  7.6823288e+01 -7.5892052e+01  7.6726967e+01\n",
      "   7.6466202e+01 -7.6755859e+01  7.6323112e+01  7.5405045e+01\n",
      "  -7.6367073e+01 -9.9535638e-01  7.6298546e+01 -7.6633804e+01\n",
      "  -7.5115112e+01  7.6905212e+01 -7.6809410e+01  7.6727158e+01\n",
      "  -7.6680481e+01  2.5127763e-01  7.6624557e+01  7.6449265e+01\n",
      "  -7.6876511e+01  7.6763168e+01  1.0000000e+00  7.6673347e+01\n",
      "   7.6847687e+01  7.5225510e+01  7.6998505e+01  7.6760139e+01\n",
      "  -7.5518845e+01 -7.5458351e+01  7.6922516e+01  7.5058723e+01\n",
      "  -7.5201332e+01 -7.6922768e+01 -7.6905815e+01  7.6908470e+01\n",
      "  -2.0453930e-03  7.6800751e+01 -7.6593895e+01 -7.6833344e+01\n",
      "   7.5318115e+01  7.5554131e+01  7.6863312e+01  7.6401093e+01\n",
      "  -7.6801620e+01  7.6823425e+01 -7.6778442e+01  7.6996658e+01\n",
      "  -6.0061365e-01  7.5782745e+01 -7.5705551e+01 -3.4829301e-01\n",
      "   7.6966560e+01 -7.6766426e+01  7.6792686e+01 -7.6880981e+01\n",
      "   5.8553666e-02  7.6988388e+01 -8.2937694e-01 -7.6354576e+01\n",
      "  -7.6604385e+01  7.6820999e+01 -7.6902817e+01  1.0542210e+00\n",
      "   7.9499429e-01  7.6806313e+01 -7.6716606e+01  7.6827469e+01]]\n",
      "T 5\n",
      "P 12\n",
      "T [-0.43303818]\n",
      "P [[-0.89188564]]\n",
      "[[-77.87546    -77.70949     77.59169    -77.78094    -77.61839\n",
      "   76.18552     77.90124     76.37661    -76.22772    -77.94499\n",
      "   77.850235     0.9951945   77.60772     77.776      -76.44781\n",
      "  -77.54661     76.66301     77.90143     -0.66936654  77.95747\n",
      "  -77.953094    76.97592     77.58568    -77.71506    -77.896355\n",
      "   77.905685    76.26039     76.4061      77.97565    -77.90127\n",
      "  -77.68886    -77.93236      0.9768941   77.82329    -76.89205\n",
      "   77.72697     77.4662     -77.75586     77.3231      76.405045\n",
      "  -77.36707      0.52207106  77.298546   -77.633804   -76.11511\n",
      "   77.90521    -77.80941     77.72716    -77.68048     -0.7487224\n",
      "   77.624504    77.449265   -77.87648     77.76317     -0.999511\n",
      "   77.67334     77.84769     76.22551     77.998505    77.76014\n",
      "  -76.51877    -76.45834     77.922516    76.05872    -76.20133\n",
      "  -77.92277    -77.905815    77.90847     -0.70739174  77.80075\n",
      "  -77.593895   -77.8333      76.318115    76.55411     77.86331\n",
      "   77.40089    -77.80162     77.82342    -77.77844     77.99666\n",
      "    0.40716577  76.78274    -76.70555      0.73763     77.96656\n",
      "  -77.766426    77.79269    -77.88098     -1.          77.98839\n",
      "    0.7302582  -77.354576   -77.60429     77.821      -77.90279\n",
      "   -0.46891993   1.7949944   77.80631    -77.716606    77.82747   ]]\n",
      "T 0\n",
      "P 0\n",
      "T [-0.08237483]\n",
      "P [[-0.99392855]]\n",
      "[[-7.8875458e+01 -7.8709488e+01  7.8591690e+01 -7.8780937e+01\n",
      "  -7.8618393e+01  7.7185295e+01  7.8901237e+01  7.7376602e+01\n",
      "  -7.7227722e+01 -7.8944992e+01  7.8850235e+01 -1.0000000e+00\n",
      "   7.8607719e+01  7.8776001e+01 -7.7447807e+01 -7.8546608e+01\n",
      "   7.7662979e+01  7.8901428e+01  5.9657209e-02  7.8957474e+01\n",
      "  -7.8953094e+01  7.7975922e+01  7.8585678e+01 -7.8715057e+01\n",
      "  -7.8896355e+01  7.8905685e+01  7.7260391e+01  7.7406097e+01\n",
      "   7.8975647e+01 -7.8901268e+01 -7.8688858e+01 -7.8932358e+01\n",
      "  -4.3288147e-01  7.8823288e+01 -7.7892052e+01  7.8726967e+01\n",
      "   7.8466202e+01 -7.8755859e+01  7.8323097e+01  7.7403427e+01\n",
      "  -7.8367073e+01 -1.0000000e+00  7.8298538e+01 -7.8633804e+01\n",
      "  -7.7115082e+01  7.8905212e+01 -7.8809410e+01  7.8727158e+01\n",
      "  -7.8680481e+01  9.9999481e-01  7.8624504e+01  7.8449265e+01\n",
      "  -7.8876480e+01  7.8763168e+01  1.0000000e+00  7.8673340e+01\n",
      "   7.8847687e+01  7.7225510e+01  7.8998505e+01  7.8760139e+01\n",
      "  -7.7518768e+01 -7.7458344e+01  7.8922516e+01  7.6981400e+01\n",
      "  -7.7201332e+01 -7.8922768e+01 -7.8905815e+01  7.8908470e+01\n",
      "  -1.7073917e+00  7.8800751e+01 -7.8593895e+01 -7.8833298e+01\n",
      "   7.7318115e+01  7.7554108e+01  7.8863312e+01  7.8400887e+01\n",
      "  -7.8801620e+01  7.8823418e+01 -7.8778442e+01  7.8996658e+01\n",
      "  -5.9283423e-01  7.7782738e+01 -7.7705551e+01 -5.5172986e-01\n",
      "   7.8966560e+01 -7.8766426e+01  7.8792686e+01 -7.8880981e+01\n",
      "   7.3169321e-01  7.8988388e+01 -8.1975168e-01 -7.8354576e+01\n",
      "  -7.8604286e+01  7.8820999e+01 -7.8902786e+01  5.8806884e-01\n",
      "  -7.8820652e-01  7.8806313e+01 -7.8716606e+01  7.8827469e+01]]\n",
      "T 6\n",
      "P 6\n",
      "T [-1.28112306]\n",
      "P [[-0.88512146]]\n",
      "[[-7.9875458e+01 -7.9709488e+01  7.9591682e+01 -7.9780914e+01\n",
      "  -7.9618393e+01  7.8185295e+01  7.9901237e+01  7.8376602e+01\n",
      "  -7.8227455e+01 -7.9944931e+01  7.9850235e+01  9.9994034e-01\n",
      "   7.9607712e+01  7.9776001e+01 -7.8447807e+01 -7.9546608e+01\n",
      "   7.8662979e+01  7.9901428e+01 -9.5486408e-01  7.9957474e+01\n",
      "  -7.9953094e+01  7.8975922e+01  7.9585510e+01 -7.9714996e+01\n",
      "  -7.9896355e+01  7.9905685e+01  7.8260391e+01  7.8406097e+01\n",
      "   7.9975647e+01 -7.9901268e+01 -7.9688858e+01 -7.9932358e+01\n",
      "   8.7956566e-01  7.9823288e+01 -7.8892052e+01  7.9726967e+01\n",
      "   7.9466202e+01 -7.9755859e+01  7.9323059e+01  7.8403427e+01\n",
      "  -7.9367065e+01  7.4253011e-01  7.9298538e+01 -7.9633804e+01\n",
      "  -7.8115082e+01  7.9905205e+01 -7.9809410e+01  7.9727158e+01\n",
      "  -7.9680481e+01 -5.1856041e-06  7.9624496e+01  7.9449265e+01\n",
      "  -7.9876480e+01  7.9763168e+01 -9.9999881e-01  7.9673332e+01\n",
      "   7.9847687e+01  7.8225510e+01  7.9998505e+01  7.9760139e+01\n",
      "  -7.8518768e+01 -7.8458344e+01  7.9922516e+01  7.7981400e+01\n",
      "  -7.8200829e+01 -7.9922714e+01 -7.9905815e+01  7.9908470e+01\n",
      "  -7.2277808e-01  7.9800751e+01 -7.9593895e+01 -7.9831703e+01\n",
      "   7.8318115e+01  7.8554077e+01  7.9863312e+01  7.9400154e+01\n",
      "  -7.9801605e+01  7.9823410e+01 -7.9778442e+01  7.9996658e+01\n",
      "  -1.1723089e+00  7.8744240e+01 -7.8705551e+01  9.2535239e-01\n",
      "   7.9966560e+01 -7.9766426e+01  7.9792686e+01 -7.9880981e+01\n",
      "  -5.6062698e-01  7.9988388e+01  5.5232453e-01 -7.9354576e+01\n",
      "  -7.9604210e+01  7.9820999e+01 -7.9902718e+01 -6.7908132e-01\n",
      "   2.1179336e-01  7.9806313e+01 -7.9716606e+01  7.9827469e+01]]\n",
      "T 11\n",
      "P 11\n",
      "T [-0.25529143]\n",
      "P [[-1.0280472]]\n",
      "[[-80.87546    -80.70949     80.59168    -80.780914   -80.61839\n",
      "   79.185295    80.90124     79.37659    -79.227455   -80.94493\n",
      "   80.850235    -1.          80.60771     80.776      -79.44781\n",
      "  -80.54661     79.66297     80.90143      0.9998048   80.95747\n",
      "  -80.953094    79.97592     80.58551    -80.715      -80.896355\n",
      "   80.905685    79.26039     79.4061      80.97565    -80.90127\n",
      "  -80.68886    -80.93236     -0.37597722  80.82329    -79.89205\n",
      "   80.72697     80.4662     -80.75586     80.32306     79.40342\n",
      "  -80.367065    -0.9522268   80.29854    -80.633804   -79.11508\n",
      "   80.905205   -80.80941     80.72716    -80.68048      0.9998292\n",
      "   80.6245      80.449265   -80.87648     80.76317      1.\n",
      "   80.67333     80.84769     79.22551     80.998505    80.76014\n",
      "  -79.51877    -79.45834     80.922516    78.981384   -79.20083\n",
      "  -80.922714   -80.905815    80.90847     -1.7227781   80.80075\n",
      "  -80.593895   -80.8317      79.318115    79.55408     80.86331\n",
      "   80.400154   -80.801605    80.82341    -80.77844     80.99666\n",
      "   -2.0544004   79.74424    -79.70555     -0.5258794   80.96656\n",
      "  -80.766426    80.79269    -80.88098      0.9233357   80.98839\n",
      "   -0.891394   -80.354576   -80.60421     80.821      -80.90272\n",
      "    0.33973724   0.6305474   80.80631    -80.716606    80.82747   ]]\n",
      "T 1\n",
      "P 6\n",
      "T [-2.37611601]\n",
      "P [[-0.87707865]]\n",
      "[[-8.1875458e+01 -8.1709488e+01  8.1591675e+01 -8.1757477e+01\n",
      "  -8.1618393e+01  8.0185295e+01  8.1901237e+01  8.0376587e+01\n",
      "  -8.0227455e+01 -8.1944138e+01  8.1850235e+01  1.0000000e+00\n",
      "   8.1607666e+01  8.1776001e+01 -8.0447807e+01 -8.1546608e+01\n",
      "   8.0662964e+01  8.1901428e+01 -2.5106961e-01  8.1957474e+01\n",
      "  -8.1953094e+01  8.0975914e+01  8.1585426e+01 -8.1714951e+01\n",
      "  -8.1896355e+01  8.1905685e+01  8.0260391e+01  8.0406097e+01\n",
      "   8.1975647e+01 -8.1901268e+01 -8.1688858e+01 -8.1932358e+01\n",
      "   9.9839538e-01  8.1823288e+01 -8.0892036e+01  8.1726967e+01\n",
      "   8.1466202e+01 -8.1755859e+01  8.1323051e+01  8.0403419e+01\n",
      "  -8.1367065e+01  7.8547746e-01  8.1298538e+01 -8.1633804e+01\n",
      "  -8.0115082e+01  8.1905205e+01 -8.1809410e+01  8.1727158e+01\n",
      "  -8.1680481e+01 -1.7082691e-04  8.1624496e+01  8.1449265e+01\n",
      "  -8.1876457e+01  8.1763168e+01 -9.9999487e-01  8.1673317e+01\n",
      "   8.1847687e+01  8.0225510e+01  8.1998505e+01  8.1760139e+01\n",
      "  -8.0518700e+01 -8.0458336e+01  8.1922516e+01  7.9981384e+01\n",
      "  -8.0200829e+01 -8.1922714e+01 -8.1905815e+01  8.1908470e+01\n",
      "   8.3980000e-01  8.1800751e+01 -8.1593895e+01 -8.1831490e+01\n",
      "   8.0318115e+01  8.0554054e+01  8.1863312e+01  8.1400040e+01\n",
      "  -8.1801605e+01  8.1823402e+01 -8.1778442e+01  8.1996658e+01\n",
      "   4.3922156e-01  8.0744240e+01 -8.0705551e+01  7.9258758e-01\n",
      "   8.1966560e+01 -8.1766426e+01  8.1792686e+01 -8.1880981e+01\n",
      "  -7.6664329e-02  8.1988388e+01  1.4846122e-01 -8.1354576e+01\n",
      "  -8.1604172e+01  8.1820999e+01 -8.1902344e+01 -7.8824723e-01\n",
      "   1.6305474e+00  8.1806313e+01 -8.1716606e+01  8.1827469e+01]]\n",
      "T 2\n",
      "P 12\n",
      "T [-1.1969603]\n",
      "P [[-0.89728105]]\n",
      "[[-8.2875458e+01 -8.2709488e+01  8.2591675e+01 -8.2757477e+01\n",
      "  -8.2618393e+01  8.1117996e+01  8.2901237e+01  8.1376587e+01\n",
      "  -8.1227455e+01 -8.2944138e+01  8.2850235e+01 -9.2614943e-01\n",
      "   8.2607666e+01  8.2776001e+01 -8.1447807e+01 -8.2546608e+01\n",
      "   8.1662964e+01  8.2901428e+01  9.9383640e-01  8.2957474e+01\n",
      "  -8.2953094e+01  8.1975914e+01  8.2585426e+01 -8.2714951e+01\n",
      "  -8.2896355e+01  8.2905685e+01  8.1260391e+01  8.1406075e+01\n",
      "   8.2975647e+01 -8.2901268e+01 -8.2688858e+01 -8.2932358e+01\n",
      "  -8.0789804e-01  8.2823288e+01 -8.1892036e+01  8.2726967e+01\n",
      "   8.2466202e+01 -8.2755859e+01  8.2323051e+01  8.1403320e+01\n",
      "  -8.2367065e+01 -1.0000000e+00  8.2298538e+01 -8.2633804e+01\n",
      "  -8.1115082e+01  8.2905205e+01 -8.2809410e+01  8.2727158e+01\n",
      "  -8.2680481e+01  7.7205157e-01  8.2624496e+01  8.2449265e+01\n",
      "  -8.2876457e+01  8.2763168e+01  6.3328981e-01  8.2673317e+01\n",
      "   8.2847687e+01  8.1225510e+01  8.2998505e+01  8.2760139e+01\n",
      "  -8.1518700e+01 -8.1458336e+01  8.2922516e+01  8.0981384e+01\n",
      "  -8.1200829e+01 -8.2922714e+01 -8.2905815e+01  8.2908470e+01\n",
      "  -1.6020000e-01  8.2800751e+01 -8.2593887e+01 -8.2831490e+01\n",
      "   8.1318115e+01  8.1554054e+01  8.2863312e+01  8.2400040e+01\n",
      "  -8.2801605e+01  8.2823402e+01 -8.2778442e+01  8.2996658e+01\n",
      "  -5.6077844e-01  8.1744240e+01 -8.1705551e+01 -5.3074956e-02\n",
      "   8.2966560e+01 -8.2766426e+01  8.2792686e+01 -8.2880981e+01\n",
      "   7.4401248e-01  8.2988388e+01 -5.7770282e-01 -8.2354576e+01\n",
      "  -8.2604172e+01  8.2820999e+01 -8.2902344e+01  4.3103433e-01\n",
      "  -9.7232860e-01  8.2806313e+01 -8.2716606e+01  8.2827461e+01]]\n",
      "T 8\n",
      "P 8\n",
      "T [-0.66791527]\n",
      "P [[-0.9375006]]\n",
      "[[-8.3875458e+01 -8.3709488e+01  8.3591675e+01 -8.3757477e+01\n",
      "  -8.3618393e+01  8.2117996e+01  8.3901237e+01  8.2376587e+01\n",
      "  -8.2227448e+01 -8.3944046e+01  8.3850235e+01  9.9999803e-01\n",
      "   8.3607658e+01  8.3776001e+01 -8.2447807e+01 -8.3546608e+01\n",
      "   8.2662964e+01  8.3901428e+01 -3.0944216e-01  8.3957474e+01\n",
      "  -8.3953094e+01  8.2975914e+01  8.3585419e+01 -8.3714943e+01\n",
      "  -8.3896355e+01  8.3905685e+01  8.2260391e+01  8.2406075e+01\n",
      "   8.3975647e+01 -8.3901268e+01 -8.3688858e+01 -8.3932358e+01\n",
      "   9.2948496e-01  8.3823288e+01 -8.2892036e+01  8.3726967e+01\n",
      "   8.3466202e+01 -8.3755859e+01  8.3323044e+01  8.2403320e+01\n",
      "  -8.3367065e+01  9.9999988e-01  8.3298538e+01 -8.3633804e+01\n",
      "  -8.2115082e+01  8.3905205e+01 -8.3809410e+01  8.3727158e+01\n",
      "  -8.3680481e+01 -2.2794843e-01  8.3624496e+01  8.3449265e+01\n",
      "  -8.3876450e+01  8.3763168e+01 -9.8807311e-01  8.3673302e+01\n",
      "   8.3847687e+01  8.2225510e+01  8.3998505e+01  8.3760139e+01\n",
      "  -8.2518700e+01 -8.2458336e+01  8.3922516e+01  8.1981384e+01\n",
      "  -8.2200829e+01 -8.3922714e+01 -8.3905815e+01  8.3908470e+01\n",
      "   6.9405037e-01  8.3800751e+01 -8.3593887e+01 -8.3831429e+01\n",
      "   8.2318115e+01  8.2554039e+01  8.3863312e+01  8.3400040e+01\n",
      "  -8.3801605e+01  8.3823402e+01 -8.3778442e+01  8.3996658e+01\n",
      "   7.3599416e-01  8.2744141e+01 -8.2705551e+01  9.0519482e-01\n",
      "   8.3966560e+01 -8.3766426e+01  8.3792686e+01 -8.3880981e+01\n",
      "  -3.6411268e-01  8.3988388e+01  4.4083786e-01 -8.3354576e+01\n",
      "  -8.3604019e+01  8.3820999e+01 -8.3901863e+01  9.7606200e-01\n",
      "   2.7671397e-02  8.3806313e+01 -8.3716606e+01  8.3827461e+01]]\n",
      "T 1\n",
      "P 1\n",
      "T [-0.04520754]\n",
      "P [[1.4274098]]\n",
      "[[-8.4875458e+01 -8.4709488e+01  8.4591675e+01 -8.4757477e+01\n",
      "  -8.4618393e+01  8.3117996e+01  8.4901237e+01  8.3376587e+01\n",
      "  -8.3227448e+01 -8.4944046e+01  8.4850235e+01 -5.1225120e-01\n",
      "   8.4607658e+01  8.4776001e+01 -8.3447807e+01 -8.4546608e+01\n",
      "   8.3662949e+01  8.4901421e+01  9.9989462e-01  8.4957474e+01\n",
      "  -8.4953094e+01  8.3975800e+01  8.4585419e+01 -8.4714943e+01\n",
      "  -8.4896355e+01  8.4905685e+01  8.3260391e+01  8.3406075e+01\n",
      "   8.4975647e+01 -8.4901268e+01 -8.4688858e+01 -8.4932358e+01\n",
      "  -5.1279473e-01  8.4823288e+01 -8.3892036e+01  8.4726967e+01\n",
      "   8.4466202e+01 -8.4755859e+01  8.4323044e+01  8.3403320e+01\n",
      "  -8.4367065e+01 -1.0000000e+00  8.4298500e+01 -8.4633804e+01\n",
      "  -8.3115082e+01  8.4905205e+01 -8.4809410e+01  8.4727158e+01\n",
      "  -8.4680481e+01 -3.9591938e-01  8.4624496e+01  8.4449265e+01\n",
      "  -8.4876450e+01  8.4763168e+01  1.0000000e+00  8.4673302e+01\n",
      "   8.4847687e+01  8.3225510e+01  8.4998505e+01  8.4760139e+01\n",
      "  -8.3518700e+01 -8.3458336e+01  8.4922516e+01  8.2981384e+01\n",
      "  -8.3200829e+01 -8.4922714e+01 -8.4905815e+01  8.4908470e+01\n",
      "  -3.0594963e-01  8.4800751e+01 -8.4593887e+01 -8.4831429e+01\n",
      "   8.3318115e+01  8.3554039e+01  8.4863312e+01  8.4400040e+01\n",
      "  -8.4801605e+01  8.4823402e+01 -8.4778442e+01  8.4996658e+01\n",
      "  -2.6400584e-01  8.3744141e+01 -8.3705551e+01  1.0217786e-02\n",
      "   8.4966560e+01 -8.4766426e+01  8.4792686e+01 -8.4880981e+01\n",
      "  -8.6145544e-01  8.4988388e+01  5.6743604e-01 -8.4354576e+01\n",
      "  -8.4604019e+01  8.4820999e+01 -8.4901863e+01  1.8170636e+00\n",
      "  -9.9202526e-01  8.4806313e+01 -8.4716606e+01  8.4827454e+01]]\n",
      "T 2\n",
      "P 12\n",
      "T [-1.63611092]\n",
      "P [[-0.9960078]]\n",
      "[[-8.5875450e+01 -8.5709488e+01  8.5591675e+01 -8.5757477e+01\n",
      "  -8.5618393e+01  8.4117996e+01  8.5901237e+01  8.4376587e+01\n",
      "  -8.4227448e+01 -8.5944046e+01  8.5850235e+01  9.9905103e-01\n",
      "   8.5607658e+01  8.5776001e+01 -8.4447807e+01 -8.5546608e+01\n",
      "   8.4662949e+01  8.5901421e+01 -7.8137910e-01  8.5957474e+01\n",
      "  -8.5953094e+01  8.4975800e+01  8.5585411e+01 -8.5714935e+01\n",
      "  -8.5896355e+01  8.5905685e+01  8.4260391e+01  8.4406075e+01\n",
      "   8.5975647e+01 -8.5901268e+01 -8.5688858e+01 -8.5932358e+01\n",
      "   9.7243410e-01  8.5823288e+01 -8.4892036e+01  8.5726967e+01\n",
      "   8.5466202e+01 -8.5755859e+01  8.5323029e+01  8.4403320e+01\n",
      "  -8.5367065e+01  9.9811602e-01  8.5298500e+01 -8.5633804e+01\n",
      "  -8.4115082e+01  8.5905205e+01 -8.5809410e+01  8.5727158e+01\n",
      "  -8.5680481e+01 -1.3959193e+00  8.5624496e+01  8.5449265e+01\n",
      "  -8.5876450e+01  8.5763168e+01 -8.8270694e-01  8.5673302e+01\n",
      "   8.5847687e+01  8.4225510e+01  8.5998505e+01  8.5760139e+01\n",
      "  -8.4518700e+01 -8.4458336e+01  8.5922516e+01  8.3981384e+01\n",
      "  -8.4200821e+01 -8.5922714e+01 -8.5905815e+01  8.5908470e+01\n",
      "   9.4918221e-01  8.5800751e+01 -8.5593887e+01 -8.5831398e+01\n",
      "   8.4318115e+01  8.4554039e+01  8.5863312e+01  8.5400040e+01\n",
      "  -8.5801605e+01  8.5823402e+01 -8.5778442e+01  8.5996658e+01\n",
      "  -9.7911865e-01  8.4744141e+01 -8.4705551e+01  1.0000000e+00\n",
      "   8.5966560e+01 -8.5766426e+01  8.5792686e+01 -8.5880981e+01\n",
      "  -1.0000000e+00  8.5988388e+01  1.4864963e+00 -8.5354576e+01\n",
      "  -8.5604012e+01  8.5820999e+01 -8.5901863e+01  1.9933960e+00\n",
      "   7.9745054e-03  8.5806313e+01 -8.5716606e+01  8.5827454e+01]]\n",
      "T 13\n",
      "P 13\n",
      "T [0.2183545]\n",
      "P [[-1.0438172]]\n",
      "[[-8.6875450e+01 -8.6709488e+01  8.6591675e+01 -8.6757477e+01\n",
      "  -8.6618393e+01  8.5117996e+01  8.6901237e+01  8.5376549e+01\n",
      "  -8.5227386e+01 -8.6944046e+01  8.6850235e+01 -1.0000000e+00\n",
      "   8.6607658e+01  8.6776001e+01 -8.5447807e+01 -8.6546608e+01\n",
      "   8.5662949e+01  8.6901405e+01  9.9986982e-01  8.6957474e+01\n",
      "  -8.6953094e+01  8.5975792e+01  8.6585411e+01 -8.6714935e+01\n",
      "  -8.6896355e+01  8.6905685e+01  8.5260391e+01  8.5406075e+01\n",
      "   8.6975647e+01 -8.6901268e+01 -8.6688858e+01 -8.6932358e+01\n",
      "  -4.6234602e-01  8.6823288e+01 -8.5892036e+01  8.6726967e+01\n",
      "   8.6466202e+01 -8.6755859e+01  8.6323029e+01  8.5403320e+01\n",
      "  -8.6367065e+01 -1.0000000e+00  8.6298500e+01 -8.6633804e+01\n",
      "  -8.5115082e+01  8.6905205e+01 -8.6809410e+01  8.6727158e+01\n",
      "  -8.6680481e+01 -7.7058536e-01  8.6624496e+01  8.6449265e+01\n",
      "  -8.6876450e+01  8.6763168e+01  1.0000000e+00  8.6673302e+01\n",
      "   8.6847687e+01  8.5225510e+01  8.6998505e+01  8.6760139e+01\n",
      "  -8.5518700e+01 -8.5458336e+01  8.6922516e+01  8.4981384e+01\n",
      "  -8.5200821e+01 -8.6922714e+01 -8.6905815e+01  8.6908470e+01\n",
      "  -5.0817788e-02  8.6800751e+01 -8.6593887e+01 -8.6831398e+01\n",
      "   8.5318115e+01  8.5554039e+01  8.6863312e+01  8.6400040e+01\n",
      "  -8.6801605e+01  8.6823402e+01 -8.6778442e+01  8.6996658e+01\n",
      "  -1.3747317e+00  8.5744141e+01 -8.5705551e+01 -5.6776071e-01\n",
      "   8.6966560e+01 -8.6766426e+01  8.6792686e+01 -8.6880981e+01\n",
      "  -5.1141340e-01  8.6988388e+01  9.7019300e-02 -8.6354576e+01\n",
      "  -8.6604012e+01  8.6820999e+01 -8.6901863e+01  2.3655574e+00\n",
      "  -2.7531600e-01  8.6806313e+01 -8.6716606e+01  8.6827446e+01]]\n",
      "T 0\n",
      "P 15\n",
      "T [-0.98671531]\n",
      "P [[-0.9169966]]\n",
      "[[-87.87545    -87.70949     87.591675   -87.75748    -87.61839\n",
      "   86.118       87.90124     86.37655    -86.22739    -87.944046\n",
      "   87.850235     0.976852    87.60765     87.776      -86.44781\n",
      "  -87.54661     86.66295     87.901405    -0.20210785  87.95747\n",
      "  -87.953094    86.97579     87.585396   -87.714935   -87.896355\n",
      "   87.905685    86.26039     86.406075    87.97565    -87.90127\n",
      "  -87.68886    -87.93236      0.52142215  87.82329    -86.89204\n",
      "   87.72697     87.4662     -87.75586     87.323006    86.40332\n",
      "  -87.367065     0.99970347  87.2985     -87.633804   -86.11508\n",
      "   87.905205   -87.80941     87.72716    -87.68048     -1.5040307\n",
      "   87.6245      87.449265   -87.87645     87.76317      0.9995688\n",
      "   87.6733      87.84769     86.22551     87.998505    87.76014\n",
      "  -86.5186     -86.45833     87.922516    85.981384   -86.20081\n",
      "  -87.922714   -87.905815    87.90847     -0.98835963  87.80075\n",
      "  -87.59389    -87.8314      86.318115    86.55404     87.86331\n",
      "   87.40004    -87.801605    87.8234     -87.77844     87.99666\n",
      "   -2.1771686   86.74414    -86.70555      0.9549624   87.96656\n",
      "  -87.766426    87.79269    -87.88098     -1.0969077   87.98839\n",
      "    1.0154234  -87.354576   -87.60398     87.821      -87.90186\n",
      "    1.1559476    0.724684    87.80631    -87.716606    87.827446  ]]\n",
      "T 10\n",
      "P 10\n",
      "T [-1.62489163]\n",
      "P [[-1.0277315]]\n",
      "[[-88.87545    -88.70949     88.591675   -88.75748    -88.61839\n",
      "   87.118       88.90124     87.37653    -87.22739    -88.944046\n",
      "   88.850235    -1.          88.60765     88.776      -87.44781\n",
      "  -88.54661     87.66295     88.901405     0.9893951   88.95747\n",
      "  -88.953094    87.97579     88.585396   -88.714935   -88.896355\n",
      "   88.905685    87.26039     87.406075    88.97565    -88.90127\n",
      "  -88.68886    -88.93236     -0.9520091   88.82329    -87.89204\n",
      "   88.72697     88.4662     -88.75586     88.323006    87.40332\n",
      "  -88.36705     -1.          88.2985     -88.633804   -87.11508\n",
      "   88.905205   -88.80941     88.72716    -88.68048      0.75001556\n",
      "   88.6245      88.449265   -88.87645     88.76317      1.\n",
      "   88.6733      88.84769     87.22551     88.998505    88.76014\n",
      "  -87.5186     -87.45833     88.922516    86.981384   -87.20081\n",
      "  -88.922714   -88.905815    88.90847     -1.9883597   88.80075\n",
      "  -88.59389    -88.8314      87.318115    87.55404     88.86331\n",
      "   88.40004    -88.801605    88.8234     -88.77844     88.99666\n",
      "   -2.807867    87.74414    -87.70555      1.9548734   88.96656\n",
      "  -88.766426    88.79269    -88.88098      0.8260099   88.98839\n",
      "   -0.7179443  -88.354576   -88.60398     88.821      -88.90186\n",
      "    2.1559477    1.21952     88.80631    -88.716606    88.82744   ]]\n",
      "T 11\n",
      "P 10\n",
      "T [-1.8868307]\n",
      "P [[-1.3129562]]\n",
      "[[-89.87545    -89.70949     89.591675   -89.75748    -89.61839\n",
      "   88.118       89.90124     88.37653    -88.22739    -89.944046\n",
      "   89.850235     0.6493745   89.607635    89.776      -88.44781\n",
      "  -89.54661     88.66295     89.901405    -1.          89.95747\n",
      "  -89.953094    88.97579     89.58521    -89.71491    -89.896355\n",
      "   89.905685    88.26039     88.406075    89.97565    -89.90127\n",
      "  -89.68886    -89.93236     -0.99764526  89.82329    -88.89204\n",
      "   89.72697     89.4662     -89.75586     89.3229      88.40332\n",
      "  -89.36705      0.90899193  89.2985     -89.633804   -88.11508\n",
      "   89.905205   -89.80941     89.72716    -89.68048     -0.27608532\n",
      "   89.6245      89.449265   -89.87644     89.76317     -0.9273029\n",
      "   89.673256    89.84769     88.22551     89.998505    89.76014\n",
      "  -88.51849    -88.45833     89.922516    87.981384   -88.20081\n",
      "  -89.922714   -89.905815    89.90847     -0.9965247   89.80075\n",
      "  -89.59389    -89.8314      88.318115    88.55403     89.86331\n",
      "   89.40003    -89.801605    89.8234     -89.77844     89.99666\n",
      "   -0.618653    88.74414    -88.70555      0.9844519   89.96656\n",
      "  -89.766426    89.79269    -89.88098     -0.35822117  89.98839\n",
      "    0.8723134  -89.354576   -89.60397     89.821      -89.90177\n",
      "    1.7832389    2.21952     89.80631    -89.716606    89.82744   ]]\n",
      "T 6\n",
      "P 1\n",
      "T [-1.00997454]\n",
      "P [[-1.1994303]]\n",
      "[[-90.87545    -90.70949     90.591675   -90.75748    -90.61839\n",
      "   89.118       90.90124     89.37653    -89.22739    -90.944046\n",
      "   90.850235    -1.          90.607635    90.776      -89.44781\n",
      "  -90.54661     89.66295     90.901405     0.5470557   90.95747\n",
      "  -90.953094    89.97579     90.58521    -90.71491    -90.896355\n",
      "   90.905685    89.26039     89.406075    90.97565    -90.90127\n",
      "  -90.68886    -90.93236     -1.8014727   90.82329    -89.89204\n",
      "   90.72697     90.4662     -90.75586     90.3229      89.40332\n",
      "  -90.36705     -0.57318187  90.2985     -90.633804   -89.11508\n",
      "   90.905205   -90.80941     90.72716    -90.68048     -0.7334849\n",
      "   90.6245      90.449265   -90.87644     90.76317      1.\n",
      "   90.673256    90.84769     89.22551     90.998505    90.76014\n",
      "  -89.51849    -89.45833     90.922516    88.981384   -89.20081\n",
      "  -90.922714   -90.905815    90.90847     -1.9965247   90.80075\n",
      "  -90.59389    -90.8314      89.318115    89.55402     90.86331\n",
      "   90.40003    -90.801605    90.8234     -90.77844     90.99666\n",
      "   -1.618653    89.74414    -89.70555     -0.32229763  90.96656\n",
      "  -90.766426    90.79269    -90.88098     -0.9959349   90.98839\n",
      "    0.965034   -90.354576   -90.60397     90.821      -90.90177\n",
      "    2.6403637   -0.808181    90.80631    -90.716606    90.82744   ]]\n",
      "T 8\n",
      "P 12\n",
      "T [-1.4397241]\n",
      "P [[-0.8701829]]\n",
      "[[-91.87545    -91.70949     91.591675   -91.75748    -91.61839\n",
      "   90.118       91.90124     90.376526   -90.227325   -91.944016\n",
      "   91.850235     0.85761863  91.607605    91.776      -90.44781\n",
      "  -91.54661     90.66295     91.901405    -1.          91.95747\n",
      "  -91.953094    90.97579     91.585205   -91.71491    -91.896355\n",
      "   91.905685    90.26039     90.406075    91.97565    -91.90127\n",
      "  -91.68886    -91.93236     -1.0935423   91.82329    -90.89204\n",
      "   91.72697     91.4662     -91.75586     91.32288     90.40332\n",
      "  -91.36705      0.6586951   91.2985     -91.633804   -90.11508\n",
      "   91.905205   -91.80941     91.72716    -91.68048     -1.5027092\n",
      "   91.6245      91.449265   -91.87642     91.76317     -0.99402225\n",
      "   91.67325     91.84769     90.22551     91.998505    91.76014\n",
      "  -90.51845    -90.45833     91.922516    89.981384   -90.20081\n",
      "  -91.922714   -91.905815    91.90847     -1.3371862   91.80075\n",
      "  -91.59389    -91.83139     90.318115    90.554016    91.86331\n",
      "   91.40003    -91.801605    91.8234     -91.77844     91.99666\n",
      "    0.17773649  90.74414    -90.70555      1.          91.96656\n",
      "  -91.766426    91.79269    -91.88098     -1.          91.98839\n",
      "    1.8582089  -91.354576   -91.603935    91.821      -91.90115\n",
      "    2.1906602    0.19181901  91.80631    -91.716606    91.82744   ]]\n",
      "T 2\n",
      "P 2\n",
      "T [-2.55762875]\n",
      "P [[-1.1081146]]\n",
      "[[-92.87545    -92.70949     92.591675   -92.75748    -92.61839\n",
      "   91.118       92.90124     91.376526   -91.227325   -92.944016\n",
      "   92.850235    -1.          92.607605    92.776      -91.44781\n",
      "  -92.54661     91.66294     92.901375    -0.9211784   92.95747\n",
      "  -92.953094    91.97579     92.585205   -92.71491    -92.896355\n",
      "   92.905685    91.26039     91.406075    92.97565    -92.90127\n",
      "  -92.68886    -92.93236     -1.5882149   92.82327    -91.89204\n",
      "   92.72697     92.4662     -92.75585     92.32288     91.40321\n",
      "  -92.36705     -0.7514454   92.2985     -92.633804   -91.11508\n",
      "   92.905205   -92.80941     92.72716    -92.68048     -0.96360886\n",
      "   92.6245      92.449265   -92.87642     92.76317      1.\n",
      "   92.67325     92.84769     91.22551     92.998505    92.76014\n",
      "  -91.51845    -91.45833     92.922516    90.981384   -91.20081\n",
      "  -92.922714   -92.905815    92.90847     -2.3371863   92.80075\n",
      "  -92.59388    -92.83139     91.318115    91.55401     92.86331\n",
      "   92.40003    -92.801605    92.8234     -92.77844     92.99666\n",
      "   -0.8222635   91.74414    -91.70555      1.4203656   92.96656\n",
      "  -92.766426    92.79269    -92.88098     -0.45253354  92.98839\n",
      "    1.3851526  -92.354576   -92.603935    92.821      -92.90115\n",
      "    2.6373546    0.8184172   92.80631    -92.716606    92.827415  ]]\n",
      "T 16\n",
      "P 7\n",
      "T [-2.4527493]\n",
      "P [[-0.86777437]]\n",
      "[[-9.3875450e+01 -9.3709488e+01  9.3591675e+01 -9.3757477e+01\n",
      "  -9.3618393e+01  9.2117996e+01  9.3901237e+01  9.2376526e+01\n",
      "  -9.2227325e+01 -9.3944016e+01  9.3850235e+01 -5.0116241e-02\n",
      "   9.3607597e+01  9.3776001e+01 -9.2447807e+01 -9.3546608e+01\n",
      "   9.2662941e+01  9.3901375e+01 -1.0000000e+00  9.3957474e+01\n",
      "  -9.3953094e+01  9.2975792e+01  9.3585190e+01 -9.3714912e+01\n",
      "  -9.3896355e+01  9.3905685e+01  9.2260391e+01  9.2406075e+01\n",
      "   9.3975647e+01 -9.3901268e+01 -9.3688858e+01 -9.3932358e+01\n",
      "  -8.2454580e-01  9.3823273e+01 -9.2892036e+01  9.3726967e+01\n",
      "   9.3466202e+01 -9.3755852e+01  9.3322876e+01  9.2403214e+01\n",
      "  -9.3367050e+01  8.4685969e-01  9.3298500e+01 -9.3633804e+01\n",
      "  -9.2115082e+01  9.3905205e+01 -9.3809410e+01  9.3727158e+01\n",
      "  -9.3680481e+01 -1.9358754e+00  9.3624496e+01  9.3449265e+01\n",
      "  -9.3876419e+01  9.3763168e+01 -9.9044597e-01  9.3673241e+01\n",
      "   9.3847687e+01  9.2225510e+01  9.3998505e+01  9.3760139e+01\n",
      "  -9.2518448e+01 -9.2458328e+01  9.3922516e+01  9.1981384e+01\n",
      "  -9.2200813e+01 -9.3922714e+01 -9.3905815e+01  9.3908470e+01\n",
      "  -4.5881435e-02  9.3800751e+01 -9.3593880e+01 -9.3831390e+01\n",
      "   9.2318115e+01  9.2554008e+01  9.3863312e+01  9.3400032e+01\n",
      "  -9.3801605e+01  9.3823402e+01 -9.3778442e+01  9.3996658e+01\n",
      "   1.2160146e-01  9.2744141e+01 -9.2705551e+01  1.5674007e+00\n",
      "   9.3966560e+01 -9.3766426e+01  9.3792686e+01 -9.3880981e+01\n",
      "  -1.2498693e+00  9.3988388e+01  1.4881122e+00 -9.3354576e+01\n",
      "  -9.3603912e+01  9.3820999e+01 -9.3901131e+01  2.0493624e+00\n",
      "   1.7954013e+00  9.3806313e+01 -9.3716606e+01  9.3827415e+01]]\n",
      "T 4\n",
      "P 4\n",
      "T [1.42916069]\n",
      "P [[-0.90208924]]\n",
      "[[-94.87545    -94.70949     94.591675   -94.75748    -94.61839\n",
      "   93.118       94.90124     93.376526   -93.227325   -94.944016\n",
      "   94.850235    -1.          94.6076      94.776      -93.44781\n",
      "  -94.54661     93.66294     94.901375     0.9995029   94.95747\n",
      "  -94.953094    93.97579     94.58519    -94.71491    -94.896355\n",
      "   94.905685    93.26039     93.406075    94.97565    -94.90127\n",
      "  -94.68886    -94.93236     -1.4640995   94.82327    -93.89204\n",
      "   94.72697     94.4662     -94.75585     94.322876    93.40321\n",
      "  -94.36705     -1.          94.2985     -94.633804   -93.115074\n",
      "   94.905205   -94.80941     94.72716    -94.68048     -0.81230795\n",
      "   94.6245      94.449265   -94.87642     94.76317      1.\n",
      "   94.67324     94.84769     93.22551     94.998505    94.76014\n",
      "  -93.51845    -93.45833     94.922516    92.981384   -93.20081\n",
      "  -94.922714   -94.905815    94.90847     -1.0458814   94.80075\n",
      "  -94.59388    -94.83139     93.318115    93.55401     94.86331\n",
      "   94.40003    -94.801605    94.8234     -94.77844     94.99666\n",
      "   -0.87839854  93.74414    -93.70555      1.0263525   94.96656\n",
      "  -94.766426    94.79269    -94.88098      0.298951    94.98839\n",
      "   -0.86485606 -94.354576   -94.60391     94.821      -94.90113\n",
      "    2.9998765   -0.511787    94.80631    -94.716606    94.82741   ]]\n",
      "T 11\n",
      "P 11\n",
      "T [-1.67479438]\n",
      "P [[-1.0503088]]\n",
      "[[-9.5875450e+01 -9.5709488e+01  9.5591675e+01 -9.5757477e+01\n",
      "  -9.5618393e+01  9.4117996e+01  9.5901237e+01  9.4376526e+01\n",
      "  -9.4227234e+01 -9.5944016e+01  9.5850235e+01  9.9974197e-01\n",
      "   9.5607590e+01  9.5776001e+01 -9.4447807e+01 -9.5546608e+01\n",
      "   9.4662941e+01  9.5901375e+01 -6.4909500e-01  9.5957474e+01\n",
      "  -9.5953094e+01  9.4975792e+01  9.5585144e+01 -9.5714912e+01\n",
      "  -9.5896355e+01  9.5905685e+01  9.4260391e+01  9.4406075e+01\n",
      "   9.5975647e+01 -9.5901268e+01 -9.5688858e+01 -9.5932358e+01\n",
      "   7.5273311e-01  9.5823273e+01 -9.4892036e+01  9.5726967e+01\n",
      "   9.5466194e+01 -9.5755852e+01  9.5322838e+01  9.4403214e+01\n",
      "  -9.5367050e+01  9.9942327e-01  9.5298500e+01 -9.5633804e+01\n",
      "  -9.4115074e+01  9.5905205e+01 -9.5809410e+01  9.5727158e+01\n",
      "  -9.5680481e+01 -1.6412280e+00  9.5624435e+01  9.5449265e+01\n",
      "  -9.5876419e+01  9.5763168e+01 -2.9498455e-01  9.5673241e+01\n",
      "   9.5847687e+01  9.4225510e+01  9.5998505e+01  9.5760139e+01\n",
      "  -9.4518448e+01 -9.4458328e+01  9.5922516e+01  9.3981384e+01\n",
      "  -9.4200790e+01 -9.5922714e+01 -9.5905815e+01  9.5908470e+01\n",
      "  -1.6574055e-02  9.5800751e+01 -9.5593880e+01 -9.5831177e+01\n",
      "   9.4318115e+01  9.4553993e+01  9.5863312e+01  9.5400032e+01\n",
      "  -9.5801605e+01  9.5823402e+01 -9.5778442e+01  9.5996658e+01\n",
      "  -1.3501865e+00  9.4744141e+01 -9.4705551e+01  9.8285061e-01\n",
      "   9.5966560e+01 -9.5766426e+01  9.5792686e+01 -9.5880981e+01\n",
      "  -9.2005116e-01  9.5988388e+01  8.1847906e-01 -9.5354576e+01\n",
      "  -9.5603882e+01  9.5820999e+01 -9.5901108e+01  2.0873399e+00\n",
      "   4.8821300e-01  9.5806313e+01 -9.5716606e+01  9.5827408e+01]]\n",
      "T 13\n",
      "P 13\n",
      "T [-0.98410713]\n",
      "P [[-1.3471843]]\n",
      "[[-96.87545    -96.70949     96.591675   -96.75748    -96.61839\n",
      "   95.118       96.90124     95.376526   -95.227234   -96.944016\n",
      "   96.850235    -1.          96.60759     96.776      -95.44781\n",
      "  -96.54661     95.66294     96.90137      0.9999932   96.95747\n",
      "  -96.953094    95.97579     96.585144   -96.71491    -96.896355\n",
      "   96.905685    95.26039     95.406075    96.97565    -96.90127\n",
      "  -96.68886    -96.93236     -0.37888372  96.82327    -95.89204\n",
      "   96.72697     96.466194   -96.75585     96.32284     95.40321\n",
      "  -96.36705     -1.          96.2985     -96.633804   -95.115074\n",
      "   96.905205   -96.80941     96.72716    -96.68048      0.14173904\n",
      "   96.624435    96.449265   -96.87642     96.76317      1.\n",
      "   96.67324     96.84769     95.22551     96.998505    96.76014\n",
      "  -95.51845    -95.45833     96.922516    94.981384   -95.20079\n",
      "  -96.922714   -96.905815    96.90847     -1.016574    96.80075\n",
      "  -96.59388    -96.83118     95.318115    95.55399     96.86331\n",
      "   96.40003    -96.801605    96.8234     -96.77844     96.99666\n",
      "   -1.6846503   95.74414    -95.70555     -0.6498195   96.96656\n",
      "  -96.766426    96.79269    -96.88098     -0.26651537  96.98839\n",
      "    0.12966879 -96.354576   -96.60388     96.821      -96.90111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2.7899308   -0.70673573  96.80631    -96.716606    96.82741   ]]\n",
      "T 15\n",
      "P 7\n",
      "T [0.08296338]\n",
      "P [[-1.0687009]]\n",
      "[[-97.87544    -97.70949     97.591675   -97.75748    -97.61839\n",
      "   96.118       97.90124     96.376526   -96.227234   -97.944016\n",
      "   97.850235    -0.93208146  97.60757     97.776      -96.44781\n",
      "  -97.54661     96.66294     97.90137     -0.32393998  97.95747\n",
      "  -97.953094    96.97579     97.58512    -97.714905   -97.896355\n",
      "   97.905685    96.26039     96.406075    97.97565    -97.90127\n",
      "  -97.68886    -97.93236     -0.96680546  97.82327    -96.89204\n",
      "   97.72697     97.466194   -97.75585     97.32282     96.40321\n",
      "  -97.36705      0.99993867  97.2985     -97.633804   -96.115074\n",
      "   97.905205   -97.80941     97.72716    -97.68048     -0.858261\n",
      "   97.624435    97.449265   -97.87636     97.76317     -0.9665876\n",
      "   97.67324     97.84769     96.22551     97.998505    97.76014\n",
      "  -96.51845    -96.45833     97.922516    95.981384   -96.20079\n",
      "  -97.922714   -97.905815    97.90847      0.9695008   97.80075\n",
      "  -97.59388    -97.83118     96.318115    96.55398     97.86331\n",
      "   97.400024   -97.801605    97.8234     -97.77844     97.99666\n",
      "   -1.9565611   96.74403    -96.70555      0.95423496  97.96656\n",
      "  -97.766426    97.79269    -97.88098     -1.0063732   97.98839\n",
      "    1.046993   -97.354576   -97.603874    97.82099    -97.90096\n",
      "    3.2108352    0.29326427  97.80631    -97.716606    97.82741   ]]\n",
      "T 11\n",
      "P 2\n",
      "T [100.53188323]\n",
      "P [[101.227455]]\n",
      "[[-9.8875443e+01 -9.8709488e+01  9.8591675e+01 -9.8757477e+01\n",
      "  -9.8618393e+01  9.7117996e+01  9.8901237e+01  9.7376518e+01\n",
      "  -9.7227234e+01 -9.8944016e+01  9.8850235e+01 -1.0000000e+00\n",
      "   9.8607567e+01  9.8776001e+01 -9.7447807e+01 -9.8546608e+01\n",
      "   9.7662933e+01  9.8901367e+01 -8.8033956e-01  9.8957474e+01\n",
      "  -9.8953094e+01  9.7975792e+01  9.8585121e+01 -9.8714905e+01\n",
      "  -9.8896355e+01  9.8905685e+01  9.7260391e+01  9.7406075e+01\n",
      "   9.8975647e+01 -9.8901268e+01 -9.8688858e+01 -9.8932358e+01\n",
      "  -1.0859901e+00  9.8823273e+01 -9.7892036e+01  9.8726967e+01\n",
      "   9.8466194e+01 -9.8755852e+01  9.8322823e+01  9.7403206e+01\n",
      "  -9.8367050e+01 -8.6665040e-01  9.8298500e+01 -9.8633804e+01\n",
      "  -9.7115074e+01  9.8905205e+01 -9.8809410e+01  9.8727158e+01\n",
      "  -9.8680481e+01  7.9195923e-01  9.8624435e+01  9.8449265e+01\n",
      "  -9.8876358e+01  9.8763168e+01  8.2217610e-01  9.8673241e+01\n",
      "   9.8847687e+01  9.7225510e+01  9.8998505e+01  9.8760139e+01\n",
      "  -9.7518448e+01 -9.7458328e+01  9.8922516e+01  9.6981384e+01\n",
      "  -9.7200790e+01 -9.8922714e+01 -9.8905815e+01  9.8908470e+01\n",
      "  -3.0499220e-02  9.8800751e+01 -9.8593872e+01 -9.8831177e+01\n",
      "   9.7318115e+01  9.7553970e+01  9.8863312e+01  9.8400024e+01\n",
      "  -9.8801605e+01  9.8823402e+01 -9.8778442e+01  9.8996658e+01\n",
      "  -2.8034794e+00  9.7744034e+01 -9.7705551e+01  1.9518871e+00\n",
      "   9.8966560e+01 -9.8766426e+01  9.8792686e+01 -9.8880981e+01\n",
      "   7.8015351e-01  9.8988388e+01  4.3901050e-01 -9.8354576e+01\n",
      "  -9.8603874e+01  9.8820992e+01 -9.8900963e+01  3.2594118e+00\n",
      "   1.0924263e+00  9.8806313e+01 -9.8716606e+01  9.8827400e+01]]\n",
      "T 10\n",
      "P 10\n",
      "T [-1.27473255]\n",
      "P [[-0.8953291]]\n",
      "49 48\n"
     ]
    }
   ],
   "source": [
    "srlearn=SRL(100,17,4,mdp,np.random.normal)\n",
    "srlearn.SRLearn(100,1,1,1000,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-rDDxUlk0R2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oURjZORok0R4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "from keras.layers import Input, LSTM, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical as to_cat\n",
    "tf.reset_default_graph()\n",
    "gc.collect()\n",
    "gpu_fraction = 0.5\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "class memory:\n",
    "    def __init__(self,memory_size,belief_size,state_size,action_size):\n",
    "        self.size=0\n",
    "        self.memory_size=memory_size\n",
    "        self.belief_size=belief_size\n",
    "        self.state_size=state_size\n",
    "        self.action_size=action_size\n",
    "        self.mem_belief=np.empty([memory_size,self.belief_size])\n",
    "        self.mem_state=np.empty([memory_size,self.state_size])\n",
    "        self.mem_action=np.empty([memory_size,self.action_size])\n",
    "        self.mem_reward=np.empty([memory_size,1])\n",
    "\n",
    "    def push(self,belief,state,action,reward):\n",
    "        if(self.size < self.memory_size):\n",
    "            self.mem_belief[self.size]=belief\n",
    "            self.mem_state[self.size]=state\n",
    "            self.mem_action[self.size]=action\n",
    "            self.mem_reward[self.size]=reward\n",
    "            self.size+=1\n",
    "        else:\n",
    "            self.size=0\n",
    "            self.mem_belief[self.size]=self.mem_belief[-1]\n",
    "            self.mem_state[self.size]=self.mem_state[-1]\n",
    "            self.mem_action[self.size]=self.mem_action[-1]\n",
    "            self.mem_reward[self.size]=self.mem_reward[-1]\n",
    "            self.size+=1\n",
    "          \n",
    "class SRL:\n",
    "\n",
    "    def __init__(self,\n",
    "                 belief_size,\n",
    "                 state_size,\n",
    "                 action_size,\n",
    "                 mdp,\n",
    "                 sampleReward):\n",
    "        self.belief_size=belief_size\n",
    "        self.state_size=state_size\n",
    "        self.action_size=action_size\n",
    "        self.mdp = mdp\n",
    "        self.sampleReward = sampleReward\n",
    "        \n",
    "    def sampleRewardAndNextState(self,state,action):\n",
    "        '''Procedure to sample a reward and the next state\n",
    "        reward ~ Pr(r)\n",
    "        nextState ~ Pr(s'|s,a)\n",
    "\n",
    "        Inputs:\n",
    "        state -- current state\n",
    "        action -- action to be executed\n",
    "\n",
    "        Outputs: \n",
    "        reward -- sampled reward\n",
    "        nextState -- sampled next state\n",
    "        '''\n",
    "\n",
    "        reward = self.sampleReward(self.mdp.R[action,state])\n",
    "        cumProb = np.cumsum(self.mdp.T[action,state,:])\n",
    "        nextState = np.where(cumProb >= np.random.rand(1))[0][0]\n",
    "        return [reward,nextState]\n",
    "\n",
    "    def sampleAction(self,q):\n",
    "        a = q - np.max(q)\n",
    "        a = np.exp(a) / np.sum(np.exp(a))\n",
    "        return np.where(np.cumsum(a) >= np.random.rand(1))[0][0]\n",
    "\n",
    "    def sampleSoftmaxPolicy(self,policyParams,state):\n",
    "        '''Procedure to sample an action from stochastic policy\n",
    "        pi(a|s) = exp(policyParams(a,s))/[sum_a' exp(policyParams(a',s))])\n",
    "        This function should be called by reinforce() to selection actions\n",
    "\n",
    "        Inputs:\n",
    "        policyParams -- parameters of a softmax policy (|A|x|S| array)\n",
    "        state -- current state\n",
    "\n",
    "        Outputs: \n",
    "        action -- sampled action\n",
    "        '''\n",
    "\n",
    "        # temporary value to ensure that the code compiles until this\n",
    "        # function is coded\n",
    "        pi = policyParams[:,state]\n",
    "        pi = pi - np.max(pi)\n",
    "        pi = np.exp(pi) / np.sum(np.exp(pi))\n",
    "        action = np.where(np.cumsum(pi) >= np.random.rand(1))[0][0]\n",
    "                          \n",
    "        return action\n",
    "    def build_model(self,\n",
    "                    prefix,\n",
    "                    batch_size,\n",
    "                    RNN_type,\n",
    "                    Dense_num_units,\n",
    "                    Dropout_rate,\n",
    "                    weight_state,\n",
    "                    weight_reward,\n",
    "                    Dense_num_units2,\n",
    "                    Dropout_rate2,\n",
    "                    weight_real):\n",
    "        \n",
    "        # build_Bayes_model\n",
    "        Bayes_input_state = Input(shape=(1,self.state_size),\n",
    "                                  batch_shape=(batch_size,1,self.state_size),\n",
    "                                  dtype='float32',name=prefix+'Bayes_input_state')\n",
    "        Bayes_input_action = Input(shape=(1,self.action_size),\n",
    "                                   batch_shape=(batch_size,1,self.action_size),\n",
    "                                   dtype='float32',name=prefix+'Bayes_input_action')\n",
    "        Bayes_input = keras.layers.concatenate([Bayes_input_state,\n",
    "                                                Bayes_input_action],axis=-1)\n",
    "        if(RNN_type is LSTM):\n",
    "            rnn = RNN_type(self.belief_size,\n",
    "                           activity_regularizer=keras.regularizers.l2(-0.000001),\n",
    "                           return_state=True,\n",
    "                           stateful=True,\n",
    "                           name=prefix+'LSTM')\n",
    "            nnreset = getattr(rnn, 'reset_states')\n",
    "            [state_reward,_,belief]=rnn(Bayes_input)\n",
    "            x_state = Dense(Dense_num_units,activation='tanh',\n",
    "                            name=prefix+'LstmDenseState1B')(state_reward)\n",
    "            x_state = Dropout(Dropout_rate,\n",
    "                              name=prefix+'LstmDropoutState1B')(x_state)\n",
    "            x_state = Dense(Dense_num_units,activation='tanh',\n",
    "                            name=prefix+'LstmDenseState2B')(x_state)\n",
    "            Bayes_output_state = Dense(self.state_size,activation='softmax',\n",
    "                                       name=prefix+'Bayes_output_state')(x_state)\n",
    "            \n",
    "            x_reward = Dense(Dense_num_units,activation='tanh',\n",
    "                             name=prefix+'LstmDenseReward1B')(state_reward)\n",
    "            x_reward = Dropout(Dropout_rate,\n",
    "                               name=prefix+'LstmDropoutReward1B')(x_reward)\n",
    "            x_reward = Dense(Dense_num_units,activation='tanh',\n",
    "                             name=prefix+'LstmDenseReward2B')(x_reward)\n",
    "            Bayes_output_reward = Dense(1,activation='linear',\n",
    "                                        name=prefix+'Bayes_output_reward')(x_reward)\n",
    "\n",
    "        Bayes_model = Model(inputs=[Bayes_input_state,\n",
    "                                    Bayes_input_action],\n",
    "                            outputs=[belief,\n",
    "                                     Bayes_output_state,\n",
    "                                     Bayes_output_reward])\n",
    "        Bayes_model.compile(optimizer='rmsprop',\n",
    "                           loss={prefix+'Bayes_output_state' : 'categorical_crossentropy',\n",
    "                                 prefix+'Bayes_output_reward' : 'mean_squared_error'},\n",
    "                           loss_weights={prefix+'Bayes_output_state' : weight_state,\n",
    "                                         prefix+'Bayes_output_reward' : weight_reward},\n",
    "                           metrics={prefix+'Bayes_output_state' : 'categorical_accuracy',\n",
    "                                   prefix+'Bayes_output_reward' : 'mae'}\n",
    "                           )\n",
    "    \n",
    "        # build_RL_model\n",
    "        RL_input_belief = Input(shape=(self.belief_size,),\n",
    "                                batch_shape=(batch_size,self.belief_size),\n",
    "                                dtype='float32',name=prefix+'RL_input_belief')\n",
    "        RL_input_state = Input(shape=(self.state_size,),\n",
    "                               batch_shape=(batch_size,self.state_size),\n",
    "                               dtype='float32',name=prefix+'RL_input_state')\n",
    "        RL_input = keras.layers.concatenate([RL_input_belief,RL_input_state],axis=-1)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense1')(RL_input)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense2')(x)\n",
    "        x = Dropout(Dropout_rate2,\n",
    "                    name=prefix+'RL_Dropout1')(x)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense3')(x)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense4')(x)\n",
    "        x = Dropout(Dropout_rate2,\n",
    "                    name=prefix+'RL_Dropout2')(x)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense5')(x)\n",
    "        x = Dense(Dense_num_units2,activation='tanh',\n",
    "                  name=prefix+'RL_Dense6')(x)\n",
    "        x = Dropout(Dropout_rate2,\n",
    "                    name=prefix+'RL_Dropout3')(x)\n",
    "        RL_Output = Dense(self.action_size,activation='softmax',\n",
    "                          name=prefix+'RL_output_action')(x)\n",
    "        RL_Model = Model(inputs=[RL_input_belief,RL_input_state],\n",
    "                         outputs=RL_Output,name=prefix+\"RL_Output\")\n",
    "        \n",
    "        RL_model = Model(inputs=[RL_input_belief,\n",
    "                                 RL_input_state],\n",
    "                         outputs=RL_Model([RL_input_belief,RL_input_state]))\n",
    "        RL_model.compile(optimizer='Adam',\n",
    "                         loss=lambda y_true,y_pred : y_true)\n",
    "        \n",
    "        SRL_output = RL_Model([belief,RL_input_state])\n",
    "        SRL_model = Model(inputs=[Bayes_input_state,\n",
    "                                  Bayes_input_action,\n",
    "                                  RL_input_state],\n",
    "                         outputs=[SRL_output,\n",
    "                                  belief,\n",
    "                                  Bayes_output_state,\n",
    "                                  Bayes_output_reward])\n",
    "        SRL_model.compile(optimizer='rmsprop',\n",
    "                          loss={prefix+'RL_Output' :\n",
    "                                lambda y_true,y_pred : y_true,\n",
    "                                prefix+'Bayes_output_state' : 'categorical_crossentropy',\n",
    "                                prefix+'Bayes_output_reward' : 'mean_squared_error'},\n",
    "                          loss_weights={\n",
    "                              prefix+'RL_Output' : \n",
    "                              weight_real,\n",
    "                              prefix+'Bayes_output_state' : \n",
    "                              weight_state/(1-weight_real),\n",
    "                              prefix+'Bayes_output_reward' : \n",
    "                              weight_reward/(1-weight_real)},\n",
    "                          )\n",
    "        \n",
    "        return [Bayes_model,RL_model,SRL_model,nnreset]\n",
    "    \n",
    "    # shuffle = False\n",
    "        \n",
    "    def SRLearn(self,memory_size,s0,nEpisodes,nSteps,\n",
    "                boot_epochs,boot_steps,update_steps):\n",
    "        assert(boot_steps>=update_steps)\n",
    "        args=[1,LSTM,50,0.1,0.999,0.001,100,0.1,0.8]\n",
    "        [bayes,rl,srl,nnreset]=self.build_model('main_',*args)\n",
    "        [bayes_t,rl_t,srl_t,nnreset_t]=self.build_model('target_',*args)\n",
    "        iterEp=0\n",
    "        # bootstrap\n",
    "        init_belief=np.zeros([1,self.belief_size])\n",
    "        init_state_reward=np.zeros([1,self.belief_size])\n",
    "        init_h = [init_belief,init_state_reward]\n",
    "        boot_mem=memory(boot_steps,self.belief_size,self.state_size,self.action_size)\n",
    "        for it in range(boot_steps):\n",
    "            s=np.random.randint(self.state_size)\n",
    "            action=np.random.randint(self.action_size)\n",
    "            [reward,s_next]=self.sampleRewardAndNextState(s,action)\n",
    "            s=to_cat(s,self.state_size)\n",
    "            action=to_cat(action,self.action_size)\n",
    "            reward=np.array([reward])\n",
    "            boot_mem.push(np.zeros(self.belief_size),s,action,reward)\n",
    "            s=s_next\n",
    "        for itEp in range(boot_epochs):\n",
    "            print('Boot_Epochs:\\t',itEp,'/',boot_epochs)\n",
    "            nnreset(init_h)\n",
    "            bayes.fit([boot_mem.mem_state[:-1].reshape([boot_steps-1,1,-1]),\n",
    "                      boot_mem.mem_action[:-1].reshape([boot_steps-1,1,-1])],\n",
    "                     [boot_mem.mem_state[1:].reshape([boot_steps-1,-1]),\n",
    "                      boot_mem.mem_reward[:-1].reshape([boot_steps-1,-1])],\n",
    "                      epochs=1,\n",
    "                      batch_size=1)\n",
    "        [boot_belief,boot_state_reward,_,_]=bayes.predict([boot_mem.mem_state[-1].reshape([1,1,-1]),\n",
    "                                                           boot_mem.mem_action[-1].reshape([1,1,-1])])\n",
    "        # Testing Bayes Model\n",
    "        nnreset([boot_belief,init_state_reward])\n",
    "        mem=boot_mem\n",
    "        bayes_t.set_weights(bayes.get_weights())\n",
    "        print(bayes_t.get_weights())\n",
    "        print(srl_t.get_weights())\n",
    "        while(iterEp < nEpisodes):\n",
    "            iterEp+=1\n",
    "            iterSt=0\n",
    "            s=s0\n",
    "            while(iterSt < nSteps):\n",
    "                iterSt+=1\n",
    "                Q=rl.predict([boot_belief,s])\n",
    "                action = self.sampleAction(Q.ravel())\n",
    "                [reward,s_next]=sampleRewardAndNextState(s,action)\n",
    "                \n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haobei/Program/anaconda3/envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:158: UserWarning: Output \"main_LSTM\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"main_LSTM\" during training.\n",
      "/home/haobei/Program/anaconda3/envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:217: UserWarning: Output \"main_LSTM\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"main_LSTM\" during training.\n",
      "/home/haobei/Program/anaconda3/envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:158: UserWarning: Output \"target_LSTM\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"target_LSTM\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boot_Epochs:\t 0 / 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haobei/Program/anaconda3/envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:217: UserWarning: Output \"target_LSTM\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"target_LSTM\" during training.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(1, 100), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Program/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1091\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1092\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3490\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3568\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3569\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3570\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder:0\", shape=(1, 100), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-1f08cbafee5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msrlearn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSRL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmdp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msrlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSRLearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-6e00d8ee2b53>\u001b[0m in \u001b[0;36mSRLearn\u001b[0;34m(self, memory_size, s0, nEpisodes, nSteps, boot_epochs, boot_steps, update_steps)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitEp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboot_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Boot_Epochs:\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitEp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboot_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mnnreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             bayes.fit([boot_mem.mem_state[:-1].reshape([boot_steps-1,1,-1]),\n\u001b[1;32m    249\u001b[0m                       boot_mem.mem_action[:-1].reshape([boot_steps-1,1,-1])],\n",
      "\u001b[0;32m~/Program/anaconda3/envs/AI/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m    720\u001b[0m                                      ', found shape=' + str(value.shape))\n\u001b[1;32m    721\u001b[0m                 \u001b[0;31m# TODO: consider batch calls to `set_value`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/anaconda3/envs/AI/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mset_value\u001b[0;34m(x, value)\u001b[0m\n\u001b[1;32m   2441\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2442\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2443\u001b[0;31m     \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1095\u001b[0;31m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(1, 100), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "srlearn=SRL(100,17,4,mdp,np.random.normal)\n",
    "srlearn.SRLearn(100,0,1,1,1000,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot("
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "abrl.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
